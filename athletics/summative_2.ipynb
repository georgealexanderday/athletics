{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athletics 100m next race time predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 17:25:19.326847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 17:25:19.481606: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-15 17:25:19.481630: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-15 17:25:19.507224: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-15 17:25:20.359147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-15 17:25:20.359358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-15 17:25:20.359383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import ResultSet\n",
    "import lxml\n",
    "import json\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import pickle\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import keras\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "\n",
    "## Scraper\n",
    "\n",
    "Here we use the requests lib and BeautifulSoup with a html parser to extract the athletes profile id for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14519911: trayvon-bromell\n",
      "14504382: fred-kerley\n",
      "14425680: marvin-bracy\n",
      "14541956: christian-coleman\n",
      "14417763: akani-simbine\n",
      "14453864: lamont-marcell-jacobs\n",
      "14737998: oblique-seville\n",
      "14201842: yohan-blake\n",
      "14747153: ferdinand-omanyala\n",
      "14366482: aaron-brown\n",
      "14638971: ackeem-blake\n",
      "14522622: reece-prescod\n",
      "14432013: elijah-hall\n",
      "14671546: abdul-hakim-sani-brown\n",
      "14536762: noah-lyles\n",
      "14466007: brandon-carnes\n",
      "14476000: kyree-king\n",
      "14414524: zharnel-hughes\n",
      "14715873: micah-williams\n",
      "14715661: yupun-abeykoon\n",
      "14636943: arthur-cisse\n",
      "14771648: jeremiah-azu\n",
      "14629201: cravont-charleston\n",
      "14465376: kendal-williams\n",
      "14888403: favour-oghene-tejiri-ashe\n",
      "14657140: felipe-bardi\n",
      "14883897: letsile-tebogo\n",
      "14375111: emmanuel-matadi\n",
      "14535607: andre-de-grasse\n",
      "14714099: raymond-ekevwo\n",
      "14873268: benjamin-azamati\n",
      "14702316: mouhamadou-fall\n",
      "14334964: jimmy-vicaut\n",
      "14654737: jerome-blake\n",
      "14249856: michael-rodgers\n",
      "14731617: jake-doran\n",
      "14413736: henricho-bruintjies\n",
      "14701305: chituru-ali\n",
      "14469945: cejhae-greene\n",
      "14417680: emile-erasmus\n",
      "14715244: kenneth-bednarek\n",
      "14803230: joseph-fahnbulleh\n",
      "14835237: shainer-rengifo-montoya\n",
      "14718734: erik-cardoso\n",
      "14574661: jelani-walker\n",
      "14629334: jerod-elcock\n",
      "14794034: lalu-muhammad-zohri\n",
      "14575440: rohan-browning\n",
      "14360879: isiah-young\n",
      "14761726: illas-garcia\n",
      "14547456: yoshihide-kiryu\n",
      "14835094: terrence-jones\n",
      "14511687: jan-volko\n",
      "14732744: edward-osei-nketia\n",
      "14576547: nigel-ellis\n",
      "14573866: joris-van-gool\n",
      "14812323: owen-ansah\n",
      "14852717: emmanuel-eseme\n",
      "14739360: rikkoi-brathwaite\n",
      "14451542: adam-thomas\n",
      "14705042: usheoritse-itsekiri\n",
      "14774788: matthew-boling\n",
      "14752176: abdullah-abkar-mohammed\n",
      "14807262: alaba-olukunle-akintola\n",
      "14771269: lucas-ansah-peprah\n",
      "14627434: julian-wagner\n",
      "14389351: meba-mickael-zeze\n",
      "14716704: davonte-burnett\n",
      "14630862: clarence-munyai\n",
      "14518308: reynier-mena\n",
      "14677801: karl-erik-nazarov\n",
      "14413552: nethaneel-mitchell-blake\n",
      "14489414: eric-harrison-jr\n",
      "14849101: ismael-kone\n",
      "14190619: andrew-robertson\n",
      "14496746: rodrigo-do-nascimento\n",
      "14509174: ojie-edoburun\n",
      "14434177: markus-fuchs\n",
      "14210243: kukyoung-kim\n",
      "14719540: ryuichiro-sakai\n",
      "14747754: emanuel-archibald\n",
      "14827151: israel-olatunde\n",
      "14897541: erriyon-knighton\n",
      "14201808: oshane-bailey\n",
      "14592146: josephus-lyles\n",
      "14456427: przemyslaw-slowikowski\n",
      "14774742: jovaughn-martin\n",
      "14888283: benjamin-richardson\n",
      "14820394: tiaan-whelpton\n",
      "14858024: gary-noa-jerrel-bibi\n",
      "14503562: christopher-belcher\n",
      "14367591: kemar-bailey-cole\n",
      "14579425: ebrahima-camara\n",
      "14547883: yuki-koike\n",
      "14782156: conroy-jones\n",
      "14813775: franco-florio\n",
      "14833270: damarcus-fleming\n",
      "14543976: dominik-kopec\n",
      "14860572: hiroki-yanagita\n",
      "14633823: amaury-golitin\n"
     ]
    }
   ],
   "source": [
    "def extract_hidden_table_rows(URL: str) -> ResultSet:\n",
    "    \"\"\"\n",
    "    Returns all html table rows that contain the class name 'table-row--hover' as its a clickable element not initially displayed.\n",
    "    This is to extract an athletes profile url.\n",
    "\n",
    "    Params:\n",
    "        URL: World athletics Men's 100m ranking page.\n",
    "\n",
    "    Returns:\n",
    "        results: All table rows containing data-athlete-url.\n",
    "    \"\"\"\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find_all(\"tr\", class_=\"table-row--hover\")\n",
    "    return results\n",
    "\n",
    "def extract_data_athlete_urls(results: ResultSet) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of all the extracted data-athlete-urls.\n",
    "\n",
    "    Params:\n",
    "        results: The parsed html results.\n",
    "\n",
    "    Returns:\n",
    "        data_athlete_urls: A list of data-athlete-urls.\n",
    "    \"\"\"\n",
    "    data_athlete_urls = []\n",
    "    for result in results:\n",
    "        attrs = result.attrs\n",
    "        data_athlete_url = attrs['data-athlete-url']\n",
    "        data_athlete_urls.append(data_athlete_url)\n",
    "    return data_athlete_urls\n",
    "\n",
    "def extract_athlete_name_and_id(data_athlete_url: str) -> Tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Returns the athlete name and unique identifiction.\n",
    "\n",
    "    Params:\n",
    "        data_athlete_url: The athletes profile page ~ /athletes/united-states/trayvon-bromell-14519911.\n",
    "    \n",
    "    Returns:\n",
    "        athlete_id, athlete_name: Athlete's name, id ~ 14633823, amaury-golitin.\n",
    "    \"\"\"\n",
    "    url_split = data_athlete_url.split('/')[-1].split('-')\n",
    "    athlete_id = int(url_split[-1])\n",
    "    athlete_name = '-'.join(url_split[:-1])\n",
    "    return athlete_id, athlete_name\n",
    "\n",
    "def create_athlete_id_to_athlete(data_athlete_urls: List[str]) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping an athletes id to their name.\n",
    "\n",
    "    Params:\n",
    "        data_athlete_urls: List of data-athlete-urls.\n",
    "\n",
    "    Returns:\n",
    "        athlete_id_to_name: dict of athlete id to name.\n",
    "    \"\"\"\n",
    "    athlete_id_to_name = {}\n",
    "    for data_athlete_url in data_athlete_urls:\n",
    "        athlete_id, athlete_name = extract_athlete_name_and_id(data_athlete_url=data_athlete_url)\n",
    "        athlete_id_to_name[athlete_id] = athlete_name\n",
    "    return athlete_id_to_name\n",
    "\n",
    "def print_athlete_id_to_name(athlete_id_to_name: Dict[int, str]) -> None:\n",
    "    \"\"\"\n",
    "    Utility printing function to check scraping successful.\n",
    "\n",
    "    Params:\n",
    "        athlete_id_to_name: dict of athlete id to name\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for athlete_id, athlete_name in athlete_id_to_name.items():\n",
    "        print(f\"{athlete_id}: {athlete_name}\")\n",
    "\n",
    "\n",
    "\n",
    "URL = 'https://www.worldathletics.org/world-rankings/100m/men?regionType=world&page=1&rankDate=2022-10-04&limitByCountry=0'\n",
    "results = extract_hidden_table_rows(URL=URL)\n",
    "data_athlete_urls = extract_data_athlete_urls(results=results)\n",
    "athlete_id_to_name = create_athlete_id_to_athlete(data_athlete_urls=data_athlete_urls)\n",
    "\n",
    "print_athlete_id_to_name(athlete_id_to_name=athlete_id_to_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphQL Queries and Obtaining Initial Data\n",
    "\n",
    "Note: The host name and api key are also dynamic so this may not work without updating the api key. To avoid having to run this again, I have just\n",
    "saved the data to pickle file. It is possible with selenium to always grab these and update the query but the season is over and the data won't be changing so not neccessary for now. In a production environment, this would be crucial.\n",
    "\n",
    "The code has been kept to demonstrate how this was achieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Returns a dict containing the required HTTP headers for the graphql request.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Host\": \"cyxcgiyvwfcg3hxgiozfwhicee.appsync-api.eu-west-1.amazonaws.com\",\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Language\": \"en-GB,en;q=0.5\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Referer\": \"https://worldathletics.org/\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"x-api-key\": \"da2-6e2ufs7vkffhdnowuanorycpia\",\n",
    "        \"x-amz-user-agent\": \"aws-amplify/3.0.2\",\n",
    "        \"Origin\": \"https://worldathletics.org\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"cross-site\",\n",
    "        \"Sec-GPC\": \"1\",\n",
    "        \"TE\": \"trailers\"\n",
    "    }\n",
    "    return headers\n",
    "\n",
    "def create_season_payload(athlete_id: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Create the payload for the athletes season graphql request.\n",
    "\n",
    "    Params:\n",
    "        athlete_id: Identifier for an athlete.\n",
    "    \n",
    "    Returns:\n",
    "        payload: graphql request payload.\n",
    "    \"\"\"\n",
    "    payload={\n",
    "        \"operationName\":\"GetSingleCompetitorResultsDiscipline\",\n",
    "        \"variables\":{\n",
    "            \"id\":athlete_id,\n",
    "            \"resultsByYearOrderBy\":\"discipline\",\n",
    "        },\n",
    "        \"query\":\"query GetSingleCompetitorResultsDiscipline($id: Int, $resultsByYearOrderBy: String, $resultsByYear: Int) {\\n  getSingleCompetitorResultsDiscipline(id: $id, resultsByYear: $resultsByYear, resultsByYearOrderBy: $resultsByYearOrderBy) {\\n    parameters {\\n      resultsByYear\\n      resultsByYearOrderBy\\n      __typename\\n    }\\n    activeYears\\n    resultsByEvent {\\n      indoor\\n      disciplineCode\\n      disciplineNameUrlSlug\\n      typeNameUrlSlug\\n      discipline\\n      withWind\\n      results {\\n        date\\n        competition\\n        venue\\n        country\\n        category\\n        race\\n        place\\n        mark\\n        wind\\n        notLegal\\n        resultScore\\n        remark\\n        __typename\\n      }\\n      __typename\\n    }\\n    __typename\\n  }\\n}\\n\"\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "def create_all_time_payload(athlete_id: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Create the payload for the athletes all-time graphql request.\n",
    "\n",
    "    Params:\n",
    "        athlete_id: Identifier for an athlete.\n",
    "    \n",
    "    Returns:\n",
    "        payload: graphql request payload.\n",
    "    \"\"\"\n",
    "    payload={\n",
    "        \"operationName\": \"GetSingleCompetitorAllTimePersonalTop10\",\n",
    "        \"variables\":{\n",
    "            \"allTimePersonalTop10Discipline\": 10229630, #fixed id for 100m\n",
    "            \"id\":athlete_id,\n",
    "        },\n",
    "        \"query\":\"query GetSingleCompetitorAllTimePersonalTop10($id: Int, $urlSlug: String, $allTimePersonalTop10Discipline: Int) {\\n  getSingleCompetitorAllTimePersonalTop10(id: $id, urlSlug: $urlSlug, allTimePersonalTop10Discipline: $allTimePersonalTop10Discipline) {\\n    parameters {\\n      allTimePersonalTop10Discipline\\n      __typename\\n    }\\n    disciplines {\\n      id\\n      name\\n      __typename\\n    }\\n    results {\\n      discipline\\n      date\\n      competition\\n      country\\n      category\\n      race\\n      place\\n      result\\n      wind\\n      drop\\n      withWind\\n      withDrop\\n      score\\n      records\\n      remark\\n      __typename\\n    }\\n    __typename\\n  }\\n}\\n\"\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "def create_basic_df_from_event_results(event_results: Dict) -> pd.DataFrame:\n",
    "    df = pd.DataFrame.from_records(event_results)\n",
    "    df = df.drop(['remark', '__typename'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_season_results(data: Dict) -> pd.DataFrame:\n",
    "    events = data['data']['getSingleCompetitorResultsDiscipline']['resultsByEvent']\n",
    "    event_results = None\n",
    "    for event in events:\n",
    "        if event[\"disciplineCode\"] == \"100\":\n",
    "            event_results = event['results']\n",
    "\n",
    "    df = create_basic_df_from_event_results(event_results)\n",
    "    return df\n",
    "\n",
    "def filter_all_time_results(data: Dict) -> pd.DataFrame:\n",
    "    event_results = data[\"data\"][\"getSingleCompetitorAllTimePersonalTop10\"][\"results\"]\n",
    "    df = create_basic_df_from_event_results(event_results)\n",
    "    return df\n",
    "\n",
    "def init_athlete_to_results(athlete_id_to_name: Dict[int, str]) -> Dict[str, Dict[str, pd.DataFrame]]:\n",
    "    athlete_to_results = {}\n",
    "    for athlete_name in athlete_id_to_name.values():\n",
    "        athlete_to_results[athlete_name] = dict.fromkeys([\"season\", \"all_time\"], None)\n",
    "    return athlete_to_results\n",
    "\n",
    "def make_graphql_request(url: str, headers: Dict, payload: Dict) -> Dict:\n",
    "    response = requests.post(url=url, json=payload, headers=headers)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "def get_results(athlete_id, payload_func, filter_func) -> pd.DataFrame:\n",
    "    payload = payload_func(athlete_id=athlete_id)\n",
    "    data = make_graphql_request(url=url, headers=headers, payload=payload)\n",
    "    df = filter_func(data) \n",
    "    return df\n",
    "\n",
    "def get_athlete_results(athlete_id: int) -> pd.DataFrame:\n",
    "    season_df = get_results(athlete_id, create_season_payload, filter_season_results)\n",
    "    all_time_df = get_results(athlete_id, create_all_time_payload, filter_all_time_results)\n",
    "\n",
    "    return season_df, all_time_df\n",
    "\n",
    "def create_initial_dataset(athlete_id_to_name: Dict[int, str], athlete_to_results: Dict[str, Dict[str, None]]) -> Dict[str, Dict[str, pd.DataFrame]]:\n",
    "    for athlete_id, athlete_name in athlete_id_to_name.items():\n",
    "        season_df, all_time_df = get_athlete_results(athlete_id)\n",
    "        athlete_to_results[athlete_name][\"season\"] = season_df\n",
    "        athlete_to_results[athlete_name][\"all_time\"] = all_time_df\n",
    "    \n",
    "    return athlete_to_results\n",
    "\n",
    "\n",
    "url = \"https://cyxcgiyvwfcg3hxgiozfwhicee.appsync-api.eu-west-1.amazonaws.com/graphql\"\n",
    "headers = create_headers()\n",
    "athlete_to_results = init_athlete_to_results(athlete_id_to_name)\n",
    "athlete_to_results = create_initial_dataset(athlete_id_to_name=athlete_id_to_name, athlete_to_results=athlete_to_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(athlete_to_results, open('data2.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Part 1\n",
    "\n",
    "## Data Cleaning and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_to_results = pickle.load(open('data.pickle', 'rb'))\n",
    "# https://www.worldathletics.org/world-ranking-rules/track-field-events\n",
    "\n",
    "event_precedence_map = {\n",
    "    \"OW\": 1,\n",
    "    \"DF\": 2,\n",
    "    \"GW\": 3,\n",
    "    \"GL\": 4,\n",
    "    \"A\": 4,\n",
    "    \"B\": 5,\n",
    "    \"C\": 6,\n",
    "    \"D\": 7,\n",
    "    \"E\": 8,\n",
    "    \"F\": 9,\n",
    "}\n",
    "\n",
    "def wind_adjusted_time(time, wind):\n",
    "    # https://www.tandfonline.com/doi/full/10.1080/17461391.2018.1480062\n",
    "    a = 0.009459\n",
    "    B = 0.0449\n",
    "    b = 0.0042\n",
    "    adjusted = time - (B*wind) + (a*time*wind) - (b*wind*wind) \n",
    "    return round(adjusted, 2)\n",
    "\n",
    "def ensure_df_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
    "    df['place'] = pd.to_numeric(df['place'], errors='coerce')\n",
    "    df['wind'] = pd.to_numeric(df['wind'], errors='coerce')\n",
    "    df = df.dropna()\n",
    "    df['time'] = df['time'].astype(float)\n",
    "    df['place'] = df['place'].astype(float).astype(int)\n",
    "    df['wind'] = df['wind'].astype(float)\n",
    "    df['wind_adjusted_time'] = df.apply(lambda x: wind_adjusted_time(time=x['time'], wind=x['wind']), axis=1)\n",
    "    df['category'] = df['category'].map(event_precedence_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def clean_season_df(season: pd.DataFrame) -> pd.DataFrame:\n",
    "    season = season.rename(columns={'mark': 'time', 'resultScore': 'score'})\n",
    "    # able to drop race as its information is contained within score\n",
    "    season = season.drop(columns=['competition', 'country', 'venue', 'notLegal', 'race'], axis=1)\n",
    "    season = season[season['score'] != 0]\n",
    "    season = ensure_df_types(season)\n",
    "    return season\n",
    "\n",
    "# def clean_all_time_frame(all_time: pd.DataFrame) -> pd.DataFrame:\n",
    "def clean_all_time_df(all_time: pd.DataFrame) -> pd.DataFrame:\n",
    "    all_time = all_time.rename(columns={'result': 'time'})\n",
    "    all_time = all_time.drop(columns=['competition', 'country', 'race', 'discipline', 'drop', 'withWind', 'withDrop', 'records'], axis=1)\n",
    "    all_time = ensure_df_types(all_time)\n",
    "    return all_time\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_kalman_gain(noise, uncertainty):\n",
    "    kalman_gain = noise/(noise + uncertainty)\n",
    "    return kalman_gain\n",
    "\n",
    "def calc_update(mean, kalman_gain, measurement):\n",
    "    new_mean = mean + kalman_gain * (measurement - mean)\n",
    "    return new_mean\n",
    "\n",
    "def calc_drift(uncertainty, time, drift):\n",
    "    uncertainty += time * drift\n",
    "    return uncertainty\n",
    "\n",
    "def extract_x0(x0):\n",
    "    noise = x0[0]\n",
    "    uncertainty = x0[1]\n",
    "    mean = x0[2]\n",
    "    drift = x0[3]\n",
    "    return noise, uncertainty, mean, drift\n",
    "    \n",
    "\n",
    "\n",
    "def kalman_filter(x0, args):\n",
    "    season = args\n",
    "    noise, uncertainty, mean, drift = extract_x0(x0)\n",
    "    error = 0\n",
    "    # iterate\n",
    "    for row in season.itertuples():\n",
    "        kg = calc_kalman_gain(noise=noise, uncertainty=uncertainty)\n",
    "        error += abs(mean - row.wind_adjusted_time)\n",
    "        mean = calc_update(mean=mean, kalman_gain=kg, measurement=row.wind_adjusted_time)\n",
    "        uncertainty = calc_drift(uncertainty=uncertainty, time=mean, drift=drift)\n",
    "\n",
    "    return error\n",
    "\n",
    "def calc_params(season: pd.DataFrame):\n",
    "    initial_params = [2, 2, 10, 0.01]\n",
    "    bounds = ((0, None), (0, None), (0, None), (0, None)) \n",
    "    return minimize(fun=kalman_filter, x0=initial_params, args=season, bounds=bounds, options={\"disp\": False})\n",
    "\n",
    "def calc_estimated_next_run(x0, previous_run):\n",
    "    noise, uncertainty, mean, drift = extract_x0(x0)\n",
    "    kg = calc_kalman_gain(noise=noise, uncertainty=uncertainty)\n",
    "    mean = calc_update(mean=mean, kalman_gain=kg, measurement=previous_run)\n",
    "    return mean\n",
    "\n",
    "def kalman_filter_prediction(season: pd.DataFrame):\n",
    "    x = calc_params(season)\n",
    "    previous_run = season.tail(1)['wind_adjusted_time']\n",
    "    result = calc_estimated_next_run(x.x, previous_run=previous_run)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsuccessful athlete data processed: 0\n"
     ]
    }
   ],
   "source": [
    "def create_athlete_final_dict(season: pd.DataFrame, all_time: pd.DataFrame, athlete: str) -> Dict:\n",
    "    athlete_season = clean_season_df(season)\n",
    "    athlete_all_time = clean_all_time_df(all_time)\n",
    "\n",
    "    athlete_all_time = athlete_all_time.sort_values(by='time', ascending=True)\n",
    "    athlete_season = athlete_season.sort_values(by='date', ascending=True)\n",
    "\n",
    "    athlete_final_dict = {}\n",
    "    athlete_final_dict['athlete'] = athlete\n",
    "\n",
    "    # separate target now to avoid information 'leakage' into feature creation\n",
    "    athlete_final_dict['next_run'] = float(athlete_season.tail(1)['wind_adjusted_time'])\n",
    "    athlete_season = athlete_season[:-1].copy()\n",
    "\n",
    "    athlete_final_dict['season_time_best'] = athlete_season['wind_adjusted_time'].min()\n",
    "    athlete_final_dict['season_time_top_3_avg'] = athlete_season['wind_adjusted_time'].sort_values()[:3].mean()\n",
    "    athlete_final_dict['season_time_most_recent_3_avg'] =athlete_season.tail(3)['wind_adjusted_time'].mean()\n",
    "\n",
    "    ## This below steps utilises the kalman filter \n",
    "    athlete_final_dict['season_time_kfp'] = float(kalman_filter_prediction(athlete_season))\n",
    "\n",
    "    athlete_final_dict['season_time_avg'] = athlete_season['wind_adjusted_time'].mean()\n",
    "    athlete_final_dict['season_score_best'] = athlete_season['score'].max()\n",
    "    athlete_final_dict['season_score_avg'] = athlete_season['score'].mean()\n",
    "    athlete_final_dict['years_since_pb'] = 2022 - athlete_all_time['date'].iloc[0].year\n",
    "    athlete_final_dict['all_time_time_best'] = athlete_all_time['wind_adjusted_time'].iloc[0]\n",
    "    athlete_final_dict['all_time_score_best'] = athlete_all_time['score'].iloc[0]\n",
    "    athlete_final_dict['all_time_time_top_3_avg'] = athlete_all_time.head(3)['wind_adjusted_time'].mean()\n",
    "\n",
    "    return athlete_final_dict\n",
    "\n",
    "def create_final_dataset(athlete_to_results: Dict) -> pd.DataFrame:\n",
    "    final_athlete_dict_list = []\n",
    "    failed_athletes = []\n",
    "    for athlete, results in athlete_to_results.items():\n",
    "        try:\n",
    "            final_athlete_dict = create_athlete_final_dict(season=results['season'], all_time=results['all_time'], athlete=athlete)\n",
    "            final_athlete_dict_list.append(final_athlete_dict)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            failed_athletes.append(athlete)\n",
    "            pass\n",
    "    \n",
    "    print(f\"unsuccessful athlete data processed: {len(failed_athletes)}\")\n",
    "\n",
    "    final_df = pd.DataFrame(final_athlete_dict_list)\n",
    "    return final_df\n",
    "\n",
    "df = create_final_dataset(athlete_to_results=athlete_to_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "athlete_index = df.pop('athlete') \n",
    "df = df.astype('float32')\n",
    "y = df.pop('next_run')\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 11) (10, 11) (90,) (10,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "3/3 [==============================] - 1s 84ms/step - loss: 9.8620 - mae: 9.8620 - val_loss: 9.7671 - val_mae: 9.7671\n",
      "Epoch 2/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.7956 - mae: 9.7956 - val_loss: 9.7030 - val_mae: 9.7030\n",
      "Epoch 3/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.7298 - mae: 9.7298 - val_loss: 9.6387 - val_mae: 9.6387\n",
      "Epoch 4/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 9.6632 - mae: 9.6632 - val_loss: 9.5742 - val_mae: 9.5742\n",
      "Epoch 5/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 9.5972 - mae: 9.5972 - val_loss: 9.5104 - val_mae: 9.5104\n",
      "Epoch 6/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 9.5308 - mae: 9.5308 - val_loss: 9.4464 - val_mae: 9.4464\n",
      "Epoch 7/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.4644 - mae: 9.4644 - val_loss: 9.3822 - val_mae: 9.3822\n",
      "Epoch 8/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.3975 - mae: 9.3975 - val_loss: 9.3185 - val_mae: 9.3185\n",
      "Epoch 9/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 9.3305 - mae: 9.3305 - val_loss: 9.2556 - val_mae: 9.2556\n",
      "Epoch 10/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.2631 - mae: 9.2631 - val_loss: 9.1930 - val_mae: 9.1930\n",
      "Epoch 11/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 9.1956 - mae: 9.1956 - val_loss: 9.1297 - val_mae: 9.1297\n",
      "Epoch 12/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 9.1272 - mae: 9.1272 - val_loss: 9.0646 - val_mae: 9.0646\n",
      "Epoch 13/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 9.0579 - mae: 9.0579 - val_loss: 8.9965 - val_mae: 8.9965\n",
      "Epoch 14/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.9858 - mae: 8.9858 - val_loss: 8.9262 - val_mae: 8.9262\n",
      "Epoch 15/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.9115 - mae: 8.9115 - val_loss: 8.8530 - val_mae: 8.8530\n",
      "Epoch 16/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 8.8347 - mae: 8.8347 - val_loss: 8.7764 - val_mae: 8.7764\n",
      "Epoch 17/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.7539 - mae: 8.7539 - val_loss: 8.6953 - val_mae: 8.6953\n",
      "Epoch 18/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.6677 - mae: 8.6677 - val_loss: 8.6089 - val_mae: 8.6089\n",
      "Epoch 19/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 8.5779 - mae: 8.5779 - val_loss: 8.5174 - val_mae: 8.5174\n",
      "Epoch 20/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.4830 - mae: 8.4830 - val_loss: 8.4212 - val_mae: 8.4212\n",
      "Epoch 21/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 8.3830 - mae: 8.3830 - val_loss: 8.3192 - val_mae: 8.3192\n",
      "Epoch 22/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.2764 - mae: 8.2764 - val_loss: 8.2113 - val_mae: 8.2113\n",
      "Epoch 23/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.1645 - mae: 8.1645 - val_loss: 8.0971 - val_mae: 8.0971\n",
      "Epoch 24/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.0443 - mae: 8.0443 - val_loss: 7.9761 - val_mae: 7.9761\n",
      "Epoch 25/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.9177 - mae: 7.9177 - val_loss: 7.8482 - val_mae: 7.8482\n",
      "Epoch 26/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 7.7851 - mae: 7.7851 - val_loss: 7.7131 - val_mae: 7.7131\n",
      "Epoch 27/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7.6449 - mae: 7.6449 - val_loss: 7.5718 - val_mae: 7.5718\n",
      "Epoch 28/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 7.4979 - mae: 7.4979 - val_loss: 7.4226 - val_mae: 7.4226\n",
      "Epoch 29/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7.3434 - mae: 7.3434 - val_loss: 7.2665 - val_mae: 7.2665\n",
      "Epoch 30/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7.1798 - mae: 7.1798 - val_loss: 7.1012 - val_mae: 7.1012\n",
      "Epoch 31/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7.0076 - mae: 7.0076 - val_loss: 6.9262 - val_mae: 6.9262\n",
      "Epoch 32/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6.8265 - mae: 6.8265 - val_loss: 6.7393 - val_mae: 6.7393\n",
      "Epoch 33/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 6.6355 - mae: 6.6355 - val_loss: 6.5407 - val_mae: 6.5407\n",
      "Epoch 34/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6.4299 - mae: 6.4299 - val_loss: 6.3315 - val_mae: 6.3315\n",
      "Epoch 35/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6.2125 - mae: 6.2125 - val_loss: 6.1102 - val_mae: 6.1102\n",
      "Epoch 36/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.9830 - mae: 5.9830 - val_loss: 5.8774 - val_mae: 5.8774\n",
      "Epoch 37/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5.7427 - mae: 5.7427 - val_loss: 5.6351 - val_mae: 5.6351\n",
      "Epoch 38/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 5.4928 - mae: 5.4928 - val_loss: 5.3834 - val_mae: 5.3834\n",
      "Epoch 39/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 5.2328 - mae: 5.2328 - val_loss: 5.1220 - val_mae: 5.1220\n",
      "Epoch 40/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.9642 - mae: 4.9642 - val_loss: 4.8507 - val_mae: 4.8507\n",
      "Epoch 41/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6841 - mae: 4.6841 - val_loss: 4.5695 - val_mae: 4.5695\n",
      "Epoch 42/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.3949 - mae: 4.3949 - val_loss: 4.2788 - val_mae: 4.2788\n",
      "Epoch 43/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.0936 - mae: 4.0936 - val_loss: 3.9788 - val_mae: 3.9788\n",
      "Epoch 44/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.7824 - mae: 3.7824 - val_loss: 3.6682 - val_mae: 3.6682\n",
      "Epoch 45/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.4632 - mae: 3.4632 - val_loss: 3.3464 - val_mae: 3.3464\n",
      "Epoch 46/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.1295 - mae: 3.1295 - val_loss: 3.0148 - val_mae: 3.0148\n",
      "Epoch 47/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.7885 - mae: 2.7885 - val_loss: 2.6723 - val_mae: 2.6723\n",
      "Epoch 48/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.4327 - mae: 2.4327 - val_loss: 2.3188 - val_mae: 2.3188\n",
      "Epoch 49/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.0687 - mae: 2.0687 - val_loss: 1.9990 - val_mae: 1.9990\n",
      "Epoch 50/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.6937 - mae: 1.6937 - val_loss: 1.6758 - val_mae: 1.6758\n",
      "Epoch 51/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3295 - mae: 1.3295 - val_loss: 1.3550 - val_mae: 1.3550\n",
      "Epoch 52/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0339 - mae: 1.0339 - val_loss: 1.1262 - val_mae: 1.1262\n",
      "Epoch 53/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8338 - mae: 0.8338 - val_loss: 0.9357 - val_mae: 0.9357\n",
      "Epoch 54/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7106 - mae: 0.7106 - val_loss: 0.8466 - val_mae: 0.8466\n",
      "Epoch 55/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6634 - mae: 0.6634 - val_loss: 0.7806 - val_mae: 0.7806\n",
      "Epoch 56/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6861 - mae: 0.6861 - val_loss: 0.7479 - val_mae: 0.7479\n",
      "Epoch 57/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7345 - mae: 0.7345 - val_loss: 0.7271 - val_mae: 0.7271\n",
      "Epoch 58/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7506 - mae: 0.7506 - val_loss: 0.7189 - val_mae: 0.7189\n",
      "Epoch 59/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7306 - mae: 0.7306 - val_loss: 0.7188 - val_mae: 0.7188\n",
      "Epoch 60/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6882 - mae: 0.6882 - val_loss: 0.7226 - val_mae: 0.7226\n",
      "Epoch 61/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6533 - mae: 0.6533 - val_loss: 0.7327 - val_mae: 0.7327\n",
      "Epoch 62/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6308 - mae: 0.6308 - val_loss: 0.7400 - val_mae: 0.7400\n",
      "Epoch 63/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6157 - mae: 0.6157 - val_loss: 0.7437 - val_mae: 0.7437\n",
      "Epoch 64/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6092 - mae: 0.6092 - val_loss: 0.7435 - val_mae: 0.7435\n",
      "Epoch 65/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6069 - mae: 0.6069 - val_loss: 0.7366 - val_mae: 0.7366\n",
      "Epoch 66/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6014 - mae: 0.6014 - val_loss: 0.7164 - val_mae: 0.7164\n",
      "Epoch 67/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5874 - mae: 0.5874 - val_loss: 0.6907 - val_mae: 0.6907\n",
      "Epoch 68/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5719 - mae: 0.5719 - val_loss: 0.6625 - val_mae: 0.6625\n",
      "Epoch 69/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5548 - mae: 0.5548 - val_loss: 0.6317 - val_mae: 0.6317\n",
      "Epoch 70/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5397 - mae: 0.5397 - val_loss: 0.6015 - val_mae: 0.6015\n",
      "Epoch 71/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5237 - mae: 0.5237 - val_loss: 0.5777 - val_mae: 0.5777\n",
      "Epoch 72/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5115 - mae: 0.5115 - val_loss: 0.5575 - val_mae: 0.5575\n",
      "Epoch 73/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5014 - mae: 0.5014 - val_loss: 0.5448 - val_mae: 0.5448\n",
      "Epoch 74/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4906 - mae: 0.4906 - val_loss: 0.5289 - val_mae: 0.5289\n",
      "Epoch 75/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4823 - mae: 0.4823 - val_loss: 0.5095 - val_mae: 0.5095\n",
      "Epoch 76/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4736 - mae: 0.4736 - val_loss: 0.4932 - val_mae: 0.4932\n",
      "Epoch 77/10000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4651 - mae: 0.4651 - val_loss: 0.4780 - val_mae: 0.4780\n",
      "Epoch 78/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4575 - mae: 0.4575 - val_loss: 0.4668 - val_mae: 0.4668\n",
      "Epoch 79/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4490 - mae: 0.4490 - val_loss: 0.4584 - val_mae: 0.4584\n",
      "Epoch 80/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4411 - mae: 0.4411 - val_loss: 0.4476 - val_mae: 0.4476\n",
      "Epoch 81/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4335 - mae: 0.4335 - val_loss: 0.4385 - val_mae: 0.4385\n",
      "Epoch 82/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4265 - mae: 0.4265 - val_loss: 0.4328 - val_mae: 0.4328\n",
      "Epoch 83/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4212 - mae: 0.4212 - val_loss: 0.4243 - val_mae: 0.4243\n",
      "Epoch 84/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4153 - mae: 0.4153 - val_loss: 0.4200 - val_mae: 0.4200\n",
      "Epoch 85/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4096 - mae: 0.4096 - val_loss: 0.4164 - val_mae: 0.4164\n",
      "Epoch 86/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4046 - mae: 0.4046 - val_loss: 0.4105 - val_mae: 0.4105\n",
      "Epoch 87/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3989 - mae: 0.3989 - val_loss: 0.4042 - val_mae: 0.4042\n",
      "Epoch 88/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3940 - mae: 0.3940 - val_loss: 0.3984 - val_mae: 0.3984\n",
      "Epoch 89/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3889 - mae: 0.3889 - val_loss: 0.3933 - val_mae: 0.3933\n",
      "Epoch 90/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3851 - mae: 0.3851 - val_loss: 0.3899 - val_mae: 0.3899\n",
      "Epoch 91/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3811 - mae: 0.3811 - val_loss: 0.3870 - val_mae: 0.3870\n",
      "Epoch 92/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3767 - mae: 0.3767 - val_loss: 0.3840 - val_mae: 0.3840\n",
      "Epoch 93/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3729 - mae: 0.3729 - val_loss: 0.3804 - val_mae: 0.3804\n",
      "Epoch 94/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3692 - mae: 0.3692 - val_loss: 0.3758 - val_mae: 0.3758\n",
      "Epoch 95/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3636 - mae: 0.3636 - val_loss: 0.3709 - val_mae: 0.3709\n",
      "Epoch 96/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3666 - mae: 0.3666 - val_loss: 0.3701 - val_mae: 0.3701\n",
      "Epoch 97/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3636 - mae: 0.3636 - val_loss: 0.3649 - val_mae: 0.3649\n",
      "Epoch 98/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3569 - mae: 0.3569 - val_loss: 0.3589 - val_mae: 0.3589\n",
      "Epoch 99/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3523 - mae: 0.3523 - val_loss: 0.3553 - val_mae: 0.3553\n",
      "Epoch 100/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3481 - mae: 0.3481 - val_loss: 0.3510 - val_mae: 0.3510\n",
      "Epoch 101/10000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3456 - mae: 0.3456 - val_loss: 0.3463 - val_mae: 0.3463\n",
      "Epoch 102/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3419 - mae: 0.3419 - val_loss: 0.3439 - val_mae: 0.3439\n",
      "Epoch 103/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3382 - mae: 0.3382 - val_loss: 0.3428 - val_mae: 0.3428\n",
      "Epoch 104/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3363 - mae: 0.3363 - val_loss: 0.3403 - val_mae: 0.3403\n",
      "Epoch 105/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3328 - mae: 0.3328 - val_loss: 0.3343 - val_mae: 0.3343\n",
      "Epoch 106/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3271 - mae: 0.3271 - val_loss: 0.3285 - val_mae: 0.3285\n",
      "Epoch 107/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3265 - mae: 0.3265 - val_loss: 0.3255 - val_mae: 0.3255\n",
      "Epoch 108/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3257 - mae: 0.3257 - val_loss: 0.3219 - val_mae: 0.3219\n",
      "Epoch 109/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3212 - mae: 0.3212 - val_loss: 0.3192 - val_mae: 0.3192\n",
      "Epoch 110/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3174 - mae: 0.3174 - val_loss: 0.3186 - val_mae: 0.3186\n",
      "Epoch 111/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3137 - mae: 0.3137 - val_loss: 0.3123 - val_mae: 0.3123\n",
      "Epoch 112/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3114 - mae: 0.3114 - val_loss: 0.3090 - val_mae: 0.3090\n",
      "Epoch 113/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3087 - mae: 0.3087 - val_loss: 0.3085 - val_mae: 0.3085\n",
      "Epoch 114/10000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.3050 - mae: 0.3050 - val_loss: 0.3080 - val_mae: 0.3080\n",
      "Epoch 115/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3035 - mae: 0.3035 - val_loss: 0.3022 - val_mae: 0.3022\n",
      "Epoch 116/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3014 - mae: 0.3014 - val_loss: 0.2973 - val_mae: 0.2973\n",
      "Epoch 117/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2985 - mae: 0.2985 - val_loss: 0.2974 - val_mae: 0.2974\n",
      "Epoch 118/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2965 - mae: 0.2965 - val_loss: 0.2976 - val_mae: 0.2976\n",
      "Epoch 119/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2983 - mae: 0.2983 - val_loss: 0.2915 - val_mae: 0.2915\n",
      "Epoch 120/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2909 - mae: 0.2909 - val_loss: 0.2839 - val_mae: 0.2839\n",
      "Epoch 121/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2918 - mae: 0.2918 - val_loss: 0.2803 - val_mae: 0.2803\n",
      "Epoch 122/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2901 - mae: 0.2901 - val_loss: 0.2795 - val_mae: 0.2795\n",
      "Epoch 123/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2869 - mae: 0.2869 - val_loss: 0.2779 - val_mae: 0.2779\n",
      "Epoch 124/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2846 - mae: 0.2846 - val_loss: 0.2775 - val_mae: 0.2775\n",
      "Epoch 125/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2856 - mae: 0.2856 - val_loss: 0.2742 - val_mae: 0.2742\n",
      "Epoch 126/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2810 - mae: 0.2810 - val_loss: 0.2673 - val_mae: 0.2673\n",
      "Epoch 127/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2863 - mae: 0.2863 - val_loss: 0.2654 - val_mae: 0.2654\n",
      "Epoch 128/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2851 - mae: 0.2851 - val_loss: 0.2649 - val_mae: 0.2649\n",
      "Epoch 129/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2786 - mae: 0.2786 - val_loss: 0.2647 - val_mae: 0.2647\n",
      "Epoch 130/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2774 - mae: 0.2774 - val_loss: 0.2637 - val_mae: 0.2637\n",
      "Epoch 131/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2782 - mae: 0.2782 - val_loss: 0.2638 - val_mae: 0.2638\n",
      "Epoch 132/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2791 - mae: 0.2791 - val_loss: 0.2646 - val_mae: 0.2646\n",
      "Epoch 133/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2798 - mae: 0.2798 - val_loss: 0.2597 - val_mae: 0.2597\n",
      "Epoch 134/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2762 - mae: 0.2762 - val_loss: 0.2562 - val_mae: 0.2562\n",
      "Epoch 135/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2739 - mae: 0.2739 - val_loss: 0.2522 - val_mae: 0.2522\n",
      "Epoch 136/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2713 - mae: 0.2713 - val_loss: 0.2491 - val_mae: 0.2491\n",
      "Epoch 137/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2711 - mae: 0.2711 - val_loss: 0.2467 - val_mae: 0.2467\n",
      "Epoch 138/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2698 - mae: 0.2698 - val_loss: 0.2454 - val_mae: 0.2454\n",
      "Epoch 139/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2688 - mae: 0.2688 - val_loss: 0.2434 - val_mae: 0.2434\n",
      "Epoch 140/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2680 - mae: 0.2680 - val_loss: 0.2424 - val_mae: 0.2424\n",
      "Epoch 141/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2686 - mae: 0.2686 - val_loss: 0.2415 - val_mae: 0.2415\n",
      "Epoch 142/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2668 - mae: 0.2668 - val_loss: 0.2397 - val_mae: 0.2397\n",
      "Epoch 143/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2664 - mae: 0.2664 - val_loss: 0.2398 - val_mae: 0.2398\n",
      "Epoch 144/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2662 - mae: 0.2662 - val_loss: 0.2370 - val_mae: 0.2370\n",
      "Epoch 145/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2642 - mae: 0.2642 - val_loss: 0.2321 - val_mae: 0.2321\n",
      "Epoch 146/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2639 - mae: 0.2639 - val_loss: 0.2311 - val_mae: 0.2311\n",
      "Epoch 147/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2656 - mae: 0.2656 - val_loss: 0.2301 - val_mae: 0.2301\n",
      "Epoch 148/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2669 - mae: 0.2669 - val_loss: 0.2285 - val_mae: 0.2285\n",
      "Epoch 149/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2638 - mae: 0.2638 - val_loss: 0.2267 - val_mae: 0.2267\n",
      "Epoch 150/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2616 - mae: 0.2616 - val_loss: 0.2245 - val_mae: 0.2245\n",
      "Epoch 151/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2608 - mae: 0.2608 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 152/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2587 - mae: 0.2587 - val_loss: 0.2223 - val_mae: 0.2223\n",
      "Epoch 153/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2576 - mae: 0.2576 - val_loss: 0.2189 - val_mae: 0.2189\n",
      "Epoch 154/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2564 - mae: 0.2564 - val_loss: 0.2179 - val_mae: 0.2179\n",
      "Epoch 155/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2592 - mae: 0.2592 - val_loss: 0.2169 - val_mae: 0.2169\n",
      "Epoch 156/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2573 - mae: 0.2573 - val_loss: 0.2143 - val_mae: 0.2143\n",
      "Epoch 157/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2553 - mae: 0.2553 - val_loss: 0.2196 - val_mae: 0.2196\n",
      "Epoch 158/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2560 - mae: 0.2560 - val_loss: 0.2146 - val_mae: 0.2146\n",
      "Epoch 159/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2550 - mae: 0.2550 - val_loss: 0.2124 - val_mae: 0.2124\n",
      "Epoch 160/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2577 - mae: 0.2577 - val_loss: 0.2147 - val_mae: 0.2147\n",
      "Epoch 161/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2578 - mae: 0.2578 - val_loss: 0.2077 - val_mae: 0.2077\n",
      "Epoch 162/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2560 - mae: 0.2560 - val_loss: 0.2129 - val_mae: 0.2129\n",
      "Epoch 163/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2521 - mae: 0.2521 - val_loss: 0.2057 - val_mae: 0.2057\n",
      "Epoch 164/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2527 - mae: 0.2527 - val_loss: 0.2059 - val_mae: 0.2059\n",
      "Epoch 165/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2511 - mae: 0.2511 - val_loss: 0.2057 - val_mae: 0.2057\n",
      "Epoch 166/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2499 - mae: 0.2499 - val_loss: 0.2141 - val_mae: 0.2141\n",
      "Epoch 167/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2536 - mae: 0.2536 - val_loss: 0.2120 - val_mae: 0.2120\n",
      "Epoch 168/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2506 - mae: 0.2506 - val_loss: 0.2044 - val_mae: 0.2044\n",
      "Epoch 169/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2509 - mae: 0.2509 - val_loss: 0.2047 - val_mae: 0.2047\n",
      "Epoch 170/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2516 - mae: 0.2516 - val_loss: 0.2053 - val_mae: 0.2053\n",
      "Epoch 171/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2518 - mae: 0.2518 - val_loss: 0.2047 - val_mae: 0.2047\n",
      "Epoch 172/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2503 - mae: 0.2503 - val_loss: 0.2040 - val_mae: 0.2040\n",
      "Epoch 173/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2489 - mae: 0.2489 - val_loss: 0.2037 - val_mae: 0.2037\n",
      "Epoch 174/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2495 - mae: 0.2495 - val_loss: 0.2040 - val_mae: 0.2040\n",
      "Epoch 175/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2493 - mae: 0.2493 - val_loss: 0.2058 - val_mae: 0.2058\n",
      "Epoch 176/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2479 - mae: 0.2479 - val_loss: 0.2086 - val_mae: 0.2086\n",
      "Epoch 177/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2481 - mae: 0.2481 - val_loss: 0.2124 - val_mae: 0.2124\n",
      "Epoch 178/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2494 - mae: 0.2494 - val_loss: 0.2103 - val_mae: 0.2103\n",
      "Epoch 179/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2484 - mae: 0.2484 - val_loss: 0.2097 - val_mae: 0.2097\n",
      "Epoch 180/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2484 - mae: 0.2484 - val_loss: 0.2104 - val_mae: 0.2104\n",
      "Epoch 181/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2482 - mae: 0.2482 - val_loss: 0.2081 - val_mae: 0.2081\n",
      "Epoch 182/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2478 - mae: 0.2478 - val_loss: 0.2032 - val_mae: 0.2032\n",
      "Epoch 183/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2477 - mae: 0.2477 - val_loss: 0.2030 - val_mae: 0.2030\n",
      "Epoch 184/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2481 - mae: 0.2481 - val_loss: 0.2033 - val_mae: 0.2033\n",
      "Epoch 185/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2469 - mae: 0.2469 - val_loss: 0.2107 - val_mae: 0.2107\n",
      "Epoch 186/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2516 - mae: 0.2516 - val_loss: 0.2124 - val_mae: 0.2124\n",
      "Epoch 187/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2493 - mae: 0.2493 - val_loss: 0.2023 - val_mae: 0.2023\n",
      "Epoch 188/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2476 - mae: 0.2476 - val_loss: 0.2011 - val_mae: 0.2011\n",
      "Epoch 189/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2501 - mae: 0.2501 - val_loss: 0.2009 - val_mae: 0.2009\n",
      "Epoch 190/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2473 - mae: 0.2473 - val_loss: 0.2043 - val_mae: 0.2043\n",
      "Epoch 191/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2448 - mae: 0.2448 - val_loss: 0.2172 - val_mae: 0.2172\n",
      "Epoch 192/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2509 - mae: 0.2509 - val_loss: 0.2324 - val_mae: 0.2324\n",
      "Epoch 193/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2560 - mae: 0.2560 - val_loss: 0.2194 - val_mae: 0.2194\n",
      "Epoch 194/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2465 - mae: 0.2465 - val_loss: 0.1987 - val_mae: 0.1987\n",
      "Epoch 195/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2478 - mae: 0.2478 - val_loss: 0.2038 - val_mae: 0.2038\n",
      "Epoch 196/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2652 - mae: 0.2652 - val_loss: 0.2049 - val_mae: 0.2049\n",
      "Epoch 197/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2603 - mae: 0.2603 - val_loss: 0.1963 - val_mae: 0.1963\n",
      "Epoch 198/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2465 - mae: 0.2465 - val_loss: 0.2231 - val_mae: 0.2231\n",
      "Epoch 199/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2539 - mae: 0.2539 - val_loss: 0.2357 - val_mae: 0.2357\n",
      "Epoch 200/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2533 - mae: 0.2533 - val_loss: 0.2021 - val_mae: 0.2021\n",
      "Epoch 201/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2463 - mae: 0.2463 - val_loss: 0.1948 - val_mae: 0.1948\n",
      "Epoch 202/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2483 - mae: 0.2483 - val_loss: 0.1955 - val_mae: 0.1955\n",
      "Epoch 203/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2479 - mae: 0.2479 - val_loss: 0.1964 - val_mae: 0.1964\n",
      "Epoch 204/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2439 - mae: 0.2439 - val_loss: 0.2061 - val_mae: 0.2061\n",
      "Epoch 205/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2472 - mae: 0.2472 - val_loss: 0.2097 - val_mae: 0.2097\n",
      "Epoch 206/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2472 - mae: 0.2472 - val_loss: 0.2027 - val_mae: 0.2027\n",
      "Epoch 207/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2439 - mae: 0.2439 - val_loss: 0.2005 - val_mae: 0.2005\n",
      "Epoch 208/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2429 - mae: 0.2429 - val_loss: 0.2041 - val_mae: 0.2041\n",
      "Epoch 209/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2434 - mae: 0.2434 - val_loss: 0.2041 - val_mae: 0.2041\n",
      "Epoch 210/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2433 - mae: 0.2433 - val_loss: 0.2011 - val_mae: 0.2011\n",
      "Epoch 211/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2437 - mae: 0.2437 - val_loss: 0.1986 - val_mae: 0.1986\n",
      "Epoch 212/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2427 - mae: 0.2427 - val_loss: 0.2031 - val_mae: 0.2031\n",
      "Epoch 213/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2427 - mae: 0.2427 - val_loss: 0.2055 - val_mae: 0.2055\n",
      "Epoch 214/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2449 - mae: 0.2449 - val_loss: 0.2040 - val_mae: 0.2040\n",
      "Epoch 215/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2435 - mae: 0.2435 - val_loss: 0.1958 - val_mae: 0.1958\n",
      "Epoch 216/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2468 - mae: 0.2468 - val_loss: 0.1960 - val_mae: 0.1960\n",
      "Epoch 217/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2445 - mae: 0.2445 - val_loss: 0.1973 - val_mae: 0.1973\n",
      "Epoch 218/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2467 - mae: 0.2467 - val_loss: 0.2094 - val_mae: 0.2094\n",
      "Epoch 219/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2465 - mae: 0.2465 - val_loss: 0.1983 - val_mae: 0.1983\n",
      "Epoch 220/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2419 - mae: 0.2419 - val_loss: 0.1943 - val_mae: 0.1943\n",
      "Epoch 221/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2446 - mae: 0.2446 - val_loss: 0.1929 - val_mae: 0.1929\n",
      "Epoch 222/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2410 - mae: 0.2410 - val_loss: 0.2017 - val_mae: 0.2017\n",
      "Epoch 223/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2463 - mae: 0.2463 - val_loss: 0.2153 - val_mae: 0.2153\n",
      "Epoch 224/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2490 - mae: 0.2490 - val_loss: 0.2030 - val_mae: 0.2030\n",
      "Epoch 225/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2407 - mae: 0.2407 - val_loss: 0.1925 - val_mae: 0.1925\n",
      "Epoch 226/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2442 - mae: 0.2442 - val_loss: 0.2000 - val_mae: 0.2000\n",
      "Epoch 227/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2550 - mae: 0.2550 - val_loss: 0.1978 - val_mae: 0.1978\n",
      "Epoch 228/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2479 - mae: 0.2479 - val_loss: 0.1897 - val_mae: 0.1897\n",
      "Epoch 229/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2427 - mae: 0.2427 - val_loss: 0.1947 - val_mae: 0.1947\n",
      "Epoch 230/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2436 - mae: 0.2436 - val_loss: 0.1939 - val_mae: 0.1939\n",
      "Epoch 231/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2424 - mae: 0.2424 - val_loss: 0.1889 - val_mae: 0.1889\n",
      "Epoch 232/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2422 - mae: 0.2422 - val_loss: 0.1916 - val_mae: 0.1916\n",
      "Epoch 233/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2433 - mae: 0.2433 - val_loss: 0.1892 - val_mae: 0.1892\n",
      "Epoch 234/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.1955 - val_mae: 0.1955\n",
      "Epoch 235/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2455 - mae: 0.2455 - val_loss: 0.2107 - val_mae: 0.2107\n",
      "Epoch 236/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2459 - mae: 0.2459 - val_loss: 0.2001 - val_mae: 0.2001\n",
      "Epoch 237/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2419 - mae: 0.2419 - val_loss: 0.1898 - val_mae: 0.1898\n",
      "Epoch 238/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2422 - mae: 0.2422 - val_loss: 0.1923 - val_mae: 0.1923\n",
      "Epoch 239/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2425 - mae: 0.2425 - val_loss: 0.1901 - val_mae: 0.1901\n",
      "Epoch 240/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2447 - mae: 0.2447 - val_loss: 0.1989 - val_mae: 0.1989\n",
      "Epoch 241/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2410 - mae: 0.2410 - val_loss: 0.1944 - val_mae: 0.1944\n",
      "Epoch 242/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2385 - mae: 0.2385 - val_loss: 0.1917 - val_mae: 0.1917\n",
      "Epoch 243/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.1925 - val_mae: 0.1925\n",
      "Epoch 244/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.1935 - val_mae: 0.1935\n",
      "Epoch 245/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2413 - mae: 0.2413 - val_loss: 0.2071 - val_mae: 0.2071\n",
      "Epoch 246/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2463 - mae: 0.2463 - val_loss: 0.2053 - val_mae: 0.2053\n",
      "Epoch 247/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2439 - mae: 0.2439 - val_loss: 0.1962 - val_mae: 0.1962\n",
      "Epoch 248/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2360 - mae: 0.2360 - val_loss: 0.1915 - val_mae: 0.1915\n",
      "Epoch 249/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2422 - mae: 0.2422 - val_loss: 0.1979 - val_mae: 0.1979\n",
      "Epoch 250/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2525 - mae: 0.2525 - val_loss: 0.1961 - val_mae: 0.1961\n",
      "Epoch 251/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2479 - mae: 0.2479 - val_loss: 0.1900 - val_mae: 0.1900\n",
      "Epoch 252/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2423 - mae: 0.2423 - val_loss: 0.1921 - val_mae: 0.1921\n",
      "Epoch 253/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2377 - mae: 0.2377 - val_loss: 0.1873 - val_mae: 0.1873\n",
      "Epoch 254/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2401 - mae: 0.2401 - val_loss: 0.1893 - val_mae: 0.1893\n",
      "Epoch 255/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.1871 - val_mae: 0.1871\n",
      "Epoch 256/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2366 - mae: 0.2366 - val_loss: 0.1886 - val_mae: 0.1886\n",
      "Epoch 257/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2370 - mae: 0.2370 - val_loss: 0.1907 - val_mae: 0.1907\n",
      "Epoch 258/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2378 - mae: 0.2378 - val_loss: 0.1925 - val_mae: 0.1925\n",
      "Epoch 259/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.1912 - val_mae: 0.1912\n",
      "Epoch 260/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2383 - mae: 0.2383 - val_loss: 0.1870 - val_mae: 0.1870\n",
      "Epoch 261/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2379 - mae: 0.2379 - val_loss: 0.1866 - val_mae: 0.1866\n",
      "Epoch 262/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2372 - mae: 0.2372 - val_loss: 0.1893 - val_mae: 0.1893\n",
      "Epoch 263/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2367 - mae: 0.2367 - val_loss: 0.1899 - val_mae: 0.1899\n",
      "Epoch 264/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2366 - mae: 0.2366 - val_loss: 0.1865 - val_mae: 0.1865\n",
      "Epoch 265/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2354 - mae: 0.2354 - val_loss: 0.1859 - val_mae: 0.1859\n",
      "Epoch 266/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2371 - mae: 0.2371 - val_loss: 0.1866 - val_mae: 0.1866\n",
      "Epoch 267/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2372 - mae: 0.2372 - val_loss: 0.1863 - val_mae: 0.1863\n",
      "Epoch 268/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2356 - mae: 0.2356 - val_loss: 0.1896 - val_mae: 0.1896\n",
      "Epoch 269/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2354 - mae: 0.2354 - val_loss: 0.1856 - val_mae: 0.1856\n",
      "Epoch 270/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2363 - mae: 0.2363 - val_loss: 0.1859 - val_mae: 0.1859\n",
      "Epoch 271/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2358 - mae: 0.2358 - val_loss: 0.1860 - val_mae: 0.1860\n",
      "Epoch 272/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2350 - mae: 0.2350 - val_loss: 0.1910 - val_mae: 0.1910\n",
      "Epoch 273/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2355 - mae: 0.2355 - val_loss: 0.1882 - val_mae: 0.1882\n",
      "Epoch 274/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2331 - mae: 0.2331 - val_loss: 0.1869 - val_mae: 0.1869\n",
      "Epoch 275/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2439 - mae: 0.2439 - val_loss: 0.1922 - val_mae: 0.1922\n",
      "Epoch 276/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2441 - mae: 0.2441 - val_loss: 0.1860 - val_mae: 0.1860\n",
      "Epoch 277/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2353 - mae: 0.2353 - val_loss: 0.1995 - val_mae: 0.1995\n",
      "Epoch 278/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2414 - mae: 0.2414 - val_loss: 0.2033 - val_mae: 0.2033\n",
      "Epoch 279/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.1887 - val_mae: 0.1887\n",
      "Epoch 280/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2341 - mae: 0.2341 - val_loss: 0.1859 - val_mae: 0.1859\n",
      "Epoch 281/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2380 - mae: 0.2380 - val_loss: 0.1853 - val_mae: 0.1853\n",
      "Epoch 282/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2354 - mae: 0.2354 - val_loss: 0.1932 - val_mae: 0.1932\n",
      "Epoch 283/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2363 - mae: 0.2363 - val_loss: 0.1921 - val_mae: 0.1921\n",
      "Epoch 284/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2356 - mae: 0.2356 - val_loss: 0.1872 - val_mae: 0.1872\n",
      "Epoch 285/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2342 - mae: 0.2342 - val_loss: 0.1828 - val_mae: 0.1828\n",
      "Epoch 286/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2358 - mae: 0.2358 - val_loss: 0.1819 - val_mae: 0.1819\n",
      "Epoch 287/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2335 - mae: 0.2335 - val_loss: 0.1839 - val_mae: 0.1839\n",
      "Epoch 288/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2333 - mae: 0.2333 - val_loss: 0.1910 - val_mae: 0.1910\n",
      "Epoch 289/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2376 - mae: 0.2376 - val_loss: 0.1915 - val_mae: 0.1915\n",
      "Epoch 290/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2351 - mae: 0.2351 - val_loss: 0.1808 - val_mae: 0.1808\n",
      "Epoch 291/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2317 - mae: 0.2317 - val_loss: 0.1761 - val_mae: 0.1761\n",
      "Epoch 292/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2356 - mae: 0.2356 - val_loss: 0.1772 - val_mae: 0.1772\n",
      "Epoch 293/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2310 - mae: 0.2310 - val_loss: 0.1831 - val_mae: 0.1831\n",
      "Epoch 294/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2341 - mae: 0.2341 - val_loss: 0.1841 - val_mae: 0.1841\n",
      "Epoch 295/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2339 - mae: 0.2339 - val_loss: 0.1750 - val_mae: 0.1750\n",
      "Epoch 296/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2314 - mae: 0.2314 - val_loss: 0.1760 - val_mae: 0.1760\n",
      "Epoch 297/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2310 - mae: 0.2310 - val_loss: 0.1731 - val_mae: 0.1731\n",
      "Epoch 298/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2317 - mae: 0.2317 - val_loss: 0.1722 - val_mae: 0.1722\n",
      "Epoch 299/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2304 - mae: 0.2304 - val_loss: 0.1768 - val_mae: 0.1768\n",
      "Epoch 300/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2321 - mae: 0.2321 - val_loss: 0.1753 - val_mae: 0.1753\n",
      "Epoch 301/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2341 - mae: 0.2341 - val_loss: 0.1803 - val_mae: 0.1803\n",
      "Epoch 302/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2342 - mae: 0.2342 - val_loss: 0.1762 - val_mae: 0.1762\n",
      "Epoch 303/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2320 - mae: 0.2320 - val_loss: 0.1749 - val_mae: 0.1749\n",
      "Epoch 304/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2301 - mae: 0.2301 - val_loss: 0.1733 - val_mae: 0.1733\n",
      "Epoch 305/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2295 - mae: 0.2295 - val_loss: 0.1735 - val_mae: 0.1735\n",
      "Epoch 306/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2294 - mae: 0.2294 - val_loss: 0.1728 - val_mae: 0.1728\n",
      "Epoch 307/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2303 - mae: 0.2303 - val_loss: 0.1737 - val_mae: 0.1737\n",
      "Epoch 308/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2281 - mae: 0.2281 - val_loss: 0.1768 - val_mae: 0.1768\n",
      "Epoch 309/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2294 - mae: 0.2294 - val_loss: 0.1759 - val_mae: 0.1759\n",
      "Epoch 310/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2289 - mae: 0.2289 - val_loss: 0.1753 - val_mae: 0.1753\n",
      "Epoch 311/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2291 - mae: 0.2291 - val_loss: 0.1728 - val_mae: 0.1728\n",
      "Epoch 312/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2297 - mae: 0.2297 - val_loss: 0.1716 - val_mae: 0.1716\n",
      "Epoch 313/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2284 - mae: 0.2284 - val_loss: 0.1753 - val_mae: 0.1753\n",
      "Epoch 314/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2311 - mae: 0.2311 - val_loss: 0.1732 - val_mae: 0.1732\n",
      "Epoch 315/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2288 - mae: 0.2288 - val_loss: 0.1755 - val_mae: 0.1755\n",
      "Epoch 316/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2291 - mae: 0.2291 - val_loss: 0.1763 - val_mae: 0.1763\n",
      "Epoch 317/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2307 - mae: 0.2307 - val_loss: 0.1707 - val_mae: 0.1707\n",
      "Epoch 318/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2303 - mae: 0.2303 - val_loss: 0.1736 - val_mae: 0.1736\n",
      "Epoch 319/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2306 - mae: 0.2306 - val_loss: 0.1712 - val_mae: 0.1712\n",
      "Epoch 320/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2284 - mae: 0.2284 - val_loss: 0.1698 - val_mae: 0.1698\n",
      "Epoch 321/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2277 - mae: 0.2277 - val_loss: 0.1713 - val_mae: 0.1713\n",
      "Epoch 322/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2269 - mae: 0.2269 - val_loss: 0.1711 - val_mae: 0.1711\n",
      "Epoch 323/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2270 - mae: 0.2270 - val_loss: 0.1700 - val_mae: 0.1700\n",
      "Epoch 324/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2268 - mae: 0.2268 - val_loss: 0.1726 - val_mae: 0.1726\n",
      "Epoch 325/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2281 - mae: 0.2281 - val_loss: 0.1732 - val_mae: 0.1732\n",
      "Epoch 326/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2262 - mae: 0.2262 - val_loss: 0.1731 - val_mae: 0.1731\n",
      "Epoch 327/10000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2288 - mae: 0.2288 - val_loss: 0.1754 - val_mae: 0.1754\n",
      "Epoch 328/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2297 - mae: 0.2297 - val_loss: 0.1701 - val_mae: 0.1701\n",
      "Epoch 329/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2272 - mae: 0.2272 - val_loss: 0.1690 - val_mae: 0.1690\n",
      "Epoch 330/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2269 - mae: 0.2269 - val_loss: 0.1693 - val_mae: 0.1693\n",
      "Epoch 331/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2291 - mae: 0.2291 - val_loss: 0.1704 - val_mae: 0.1704\n",
      "Epoch 332/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2263 - mae: 0.2263 - val_loss: 0.1693 - val_mae: 0.1693\n",
      "Epoch 333/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2270 - mae: 0.2270 - val_loss: 0.1714 - val_mae: 0.1714\n",
      "Epoch 334/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2285 - mae: 0.2285 - val_loss: 0.1701 - val_mae: 0.1701\n",
      "Epoch 335/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2263 - mae: 0.2263 - val_loss: 0.1752 - val_mae: 0.1752\n",
      "Epoch 336/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2302 - mae: 0.2302 - val_loss: 0.1747 - val_mae: 0.1747\n",
      "Epoch 337/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2273 - mae: 0.2273 - val_loss: 0.1746 - val_mae: 0.1746\n",
      "Epoch 338/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2308 - mae: 0.2308 - val_loss: 0.1716 - val_mae: 0.1716\n",
      "Epoch 339/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2286 - mae: 0.2286 - val_loss: 0.1772 - val_mae: 0.1772\n",
      "Epoch 340/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2268 - mae: 0.2268 - val_loss: 0.1703 - val_mae: 0.1703\n",
      "Epoch 341/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2294 - mae: 0.2294 - val_loss: 0.1832 - val_mae: 0.1832\n",
      "Epoch 342/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2349 - mae: 0.2349 - val_loss: 0.1809 - val_mae: 0.1809\n",
      "Epoch 343/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2322 - mae: 0.2322 - val_loss: 0.1692 - val_mae: 0.1692\n",
      "Epoch 344/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2242 - mae: 0.2242 - val_loss: 0.1735 - val_mae: 0.1735\n",
      "Epoch 345/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2276 - mae: 0.2276 - val_loss: 0.1777 - val_mae: 0.1777\n",
      "Epoch 346/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2335 - mae: 0.2335 - val_loss: 0.1789 - val_mae: 0.1789\n",
      "Epoch 347/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2304 - mae: 0.2304 - val_loss: 0.1717 - val_mae: 0.1717\n",
      "Epoch 348/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2252 - mae: 0.2252 - val_loss: 0.1748 - val_mae: 0.1748\n",
      "Epoch 349/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2298 - mae: 0.2298 - val_loss: 0.1711 - val_mae: 0.1711\n",
      "Epoch 350/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2283 - mae: 0.2283 - val_loss: 0.1678 - val_mae: 0.1678\n",
      "Epoch 351/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2244 - mae: 0.2244 - val_loss: 0.1673 - val_mae: 0.1673\n",
      "Epoch 352/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2247 - mae: 0.2247 - val_loss: 0.1680 - val_mae: 0.1680\n",
      "Epoch 353/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2259 - mae: 0.2259 - val_loss: 0.1697 - val_mae: 0.1697\n",
      "Epoch 354/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2290 - mae: 0.2290 - val_loss: 0.1733 - val_mae: 0.1733\n",
      "Epoch 355/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2282 - mae: 0.2282 - val_loss: 0.1685 - val_mae: 0.1685\n",
      "Epoch 356/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2226 - mae: 0.2226 - val_loss: 0.1715 - val_mae: 0.1715\n",
      "Epoch 357/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2296 - mae: 0.2296 - val_loss: 0.1735 - val_mae: 0.1735\n",
      "Epoch 358/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2272 - mae: 0.2272 - val_loss: 0.1680 - val_mae: 0.1680\n",
      "Epoch 359/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2238 - mae: 0.2238 - val_loss: 0.1678 - val_mae: 0.1678\n",
      "Epoch 360/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2231 - mae: 0.2231 - val_loss: 0.1676 - val_mae: 0.1676\n",
      "Epoch 361/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2254 - mae: 0.2254 - val_loss: 0.1682 - val_mae: 0.1682\n",
      "Epoch 362/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2236 - mae: 0.2236 - val_loss: 0.1733 - val_mae: 0.1733\n",
      "Epoch 363/10000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2271 - mae: 0.2271 - val_loss: 0.1801 - val_mae: 0.1801\n",
      "Epoch 364/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2333 - mae: 0.2333 - val_loss: 0.1755 - val_mae: 0.1755\n",
      "Epoch 365/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2244 - mae: 0.2244 - val_loss: 0.1691 - val_mae: 0.1691\n",
      "Epoch 366/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2259 - mae: 0.2259 - val_loss: 0.1710 - val_mae: 0.1710\n",
      "Epoch 367/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2243 - mae: 0.2243 - val_loss: 0.1676 - val_mae: 0.1676\n",
      "Epoch 368/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2260 - mae: 0.2260 - val_loss: 0.1714 - val_mae: 0.1714\n",
      "Epoch 369/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2258 - mae: 0.2258 - val_loss: 0.1671 - val_mae: 0.1671\n",
      "Epoch 370/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2242 - mae: 0.2242 - val_loss: 0.1649 - val_mae: 0.1649\n",
      "Epoch 371/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2217 - mae: 0.2217 - val_loss: 0.1654 - val_mae: 0.1654\n",
      "Epoch 372/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2212 - mae: 0.2212 - val_loss: 0.1698 - val_mae: 0.1698\n",
      "Epoch 373/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2266 - mae: 0.2266 - val_loss: 0.1738 - val_mae: 0.1738\n",
      "Epoch 374/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2263 - mae: 0.2263 - val_loss: 0.1686 - val_mae: 0.1686\n",
      "Epoch 375/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2232 - mae: 0.2232 - val_loss: 0.1702 - val_mae: 0.1702\n",
      "Epoch 376/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2250 - mae: 0.2250 - val_loss: 0.1694 - val_mae: 0.1694\n",
      "Epoch 377/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2236 - mae: 0.2236 - val_loss: 0.1656 - val_mae: 0.1656\n",
      "Epoch 378/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2212 - mae: 0.2212 - val_loss: 0.1713 - val_mae: 0.1713\n",
      "Epoch 379/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2262 - mae: 0.2262 - val_loss: 0.1717 - val_mae: 0.1717\n",
      "Epoch 380/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2253 - mae: 0.2253 - val_loss: 0.1662 - val_mae: 0.1662\n",
      "Epoch 381/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2217 - mae: 0.2217 - val_loss: 0.1711 - val_mae: 0.1711\n",
      "Epoch 382/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2269 - mae: 0.2269 - val_loss: 0.1646 - val_mae: 0.1646\n",
      "Epoch 383/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2216 - mae: 0.2216 - val_loss: 0.1691 - val_mae: 0.1691\n",
      "Epoch 384/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2247 - mae: 0.2247 - val_loss: 0.1693 - val_mae: 0.1693\n",
      "Epoch 385/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2236 - mae: 0.2236 - val_loss: 0.1634 - val_mae: 0.1634\n",
      "Epoch 386/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2239 - mae: 0.2239 - val_loss: 0.1714 - val_mae: 0.1714\n",
      "Epoch 387/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2295 - mae: 0.2295 - val_loss: 0.1662 - val_mae: 0.1662\n",
      "Epoch 388/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2213 - mae: 0.2213 - val_loss: 0.1661 - val_mae: 0.1661\n",
      "Epoch 389/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2280 - mae: 0.2280 - val_loss: 0.1746 - val_mae: 0.1746\n",
      "Epoch 390/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2327 - mae: 0.2327 - val_loss: 0.1667 - val_mae: 0.1667\n",
      "Epoch 391/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2202 - mae: 0.2202 - val_loss: 0.1631 - val_mae: 0.1631\n",
      "Epoch 392/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2226 - mae: 0.2226 - val_loss: 0.1685 - val_mae: 0.1685\n",
      "Epoch 393/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2219 - mae: 0.2219 - val_loss: 0.1633 - val_mae: 0.1633\n",
      "Epoch 394/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2212 - mae: 0.2212 - val_loss: 0.1710 - val_mae: 0.1710\n",
      "Epoch 395/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2272 - mae: 0.2272 - val_loss: 0.1710 - val_mae: 0.1710\n",
      "Epoch 396/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2219 - mae: 0.2219 - val_loss: 0.1652 - val_mae: 0.1652\n",
      "Epoch 397/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2235 - mae: 0.2235 - val_loss: 0.1726 - val_mae: 0.1726\n",
      "Epoch 398/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2253 - mae: 0.2253 - val_loss: 0.1626 - val_mae: 0.1626\n",
      "Epoch 399/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2182 - mae: 0.2182 - val_loss: 0.1627 - val_mae: 0.1627\n",
      "Epoch 400/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2192 - mae: 0.2192 - val_loss: 0.1643 - val_mae: 0.1643\n",
      "Epoch 401/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2204 - mae: 0.2204 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 402/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2208 - mae: 0.2208 - val_loss: 0.1599 - val_mae: 0.1599\n",
      "Epoch 403/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2196 - mae: 0.2196 - val_loss: 0.1600 - val_mae: 0.1600\n",
      "Epoch 404/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2188 - mae: 0.2188 - val_loss: 0.1601 - val_mae: 0.1601\n",
      "Epoch 405/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2184 - mae: 0.2184 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 406/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2184 - mae: 0.2184 - val_loss: 0.1624 - val_mae: 0.1624\n",
      "Epoch 407/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2191 - mae: 0.2191 - val_loss: 0.1637 - val_mae: 0.1637\n",
      "Epoch 408/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2176 - mae: 0.2176 - val_loss: 0.1642 - val_mae: 0.1642\n",
      "Epoch 409/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2187 - mae: 0.2187 - val_loss: 0.1625 - val_mae: 0.1625\n",
      "Epoch 410/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2175 - mae: 0.2175 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 411/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2197 - mae: 0.2197 - val_loss: 0.1622 - val_mae: 0.1622\n",
      "Epoch 412/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2172 - mae: 0.2172 - val_loss: 0.1600 - val_mae: 0.1600\n",
      "Epoch 413/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2225 - mae: 0.2225 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 414/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2180 - mae: 0.2180 - val_loss: 0.1623 - val_mae: 0.1623\n",
      "Epoch 415/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2189 - mae: 0.2189 - val_loss: 0.1688 - val_mae: 0.1688\n",
      "Epoch 416/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2259 - mae: 0.2259 - val_loss: 0.1681 - val_mae: 0.1681\n",
      "Epoch 417/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2227 - mae: 0.2227 - val_loss: 0.1611 - val_mae: 0.1611\n",
      "Epoch 418/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2168 - mae: 0.2168 - val_loss: 0.1646 - val_mae: 0.1646\n",
      "Epoch 419/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2203 - mae: 0.2203 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 420/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2171 - mae: 0.2171 - val_loss: 0.1670 - val_mae: 0.1670\n",
      "Epoch 421/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2205 - mae: 0.2205 - val_loss: 0.1689 - val_mae: 0.1689\n",
      "Epoch 422/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2211 - mae: 0.2211 - val_loss: 0.1657 - val_mae: 0.1657\n",
      "Epoch 423/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2176 - mae: 0.2176 - val_loss: 0.1669 - val_mae: 0.1669\n",
      "Epoch 424/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2189 - mae: 0.2189 - val_loss: 0.1634 - val_mae: 0.1634\n",
      "Epoch 425/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2163 - mae: 0.2163 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 426/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2155 - mae: 0.2155 - val_loss: 0.1597 - val_mae: 0.1597\n",
      "Epoch 427/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2172 - mae: 0.2172 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 428/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2173 - mae: 0.2173 - val_loss: 0.1584 - val_mae: 0.1584\n",
      "Epoch 429/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2179 - mae: 0.2179 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 430/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2200 - mae: 0.2200 - val_loss: 0.1604 - val_mae: 0.1604\n",
      "Epoch 431/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2179 - mae: 0.2179 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 432/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2200 - mae: 0.2200 - val_loss: 0.1634 - val_mae: 0.1634\n",
      "Epoch 433/10000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2196 - mae: 0.2196 - val_loss: 0.1576 - val_mae: 0.1576\n",
      "Epoch 434/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2139 - mae: 0.2139 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 435/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2276 - mae: 0.2276 - val_loss: 0.1677 - val_mae: 0.1677\n",
      "Epoch 436/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2277 - mae: 0.2277 - val_loss: 0.1612 - val_mae: 0.1612\n",
      "Epoch 437/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2190 - mae: 0.2190 - val_loss: 0.1601 - val_mae: 0.1601\n",
      "Epoch 438/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2174 - mae: 0.2174 - val_loss: 0.1588 - val_mae: 0.1588\n",
      "Epoch 439/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2181 - mae: 0.2181 - val_loss: 0.1594 - val_mae: 0.1594\n",
      "Epoch 440/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2152 - mae: 0.2152 - val_loss: 0.1612 - val_mae: 0.1612\n",
      "Epoch 441/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2149 - mae: 0.2149 - val_loss: 0.1610 - val_mae: 0.1610\n",
      "Epoch 442/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2139 - mae: 0.2139 - val_loss: 0.1620 - val_mae: 0.1620\n",
      "Epoch 443/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2148 - mae: 0.2148 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 444/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2142 - mae: 0.2142 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 445/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2151 - mae: 0.2151 - val_loss: 0.1621 - val_mae: 0.1621\n",
      "Epoch 446/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2161 - mae: 0.2161 - val_loss: 0.1597 - val_mae: 0.1597\n",
      "Epoch 447/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2140 - mae: 0.2140 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 448/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2144 - mae: 0.2144 - val_loss: 0.1604 - val_mae: 0.1604\n",
      "Epoch 449/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2135 - mae: 0.2135 - val_loss: 0.1586 - val_mae: 0.1586\n",
      "Epoch 450/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2152 - mae: 0.2152 - val_loss: 0.1604 - val_mae: 0.1604\n",
      "Epoch 451/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2148 - mae: 0.2148 - val_loss: 0.1579 - val_mae: 0.1579\n",
      "Epoch 452/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2139 - mae: 0.2139 - val_loss: 0.1575 - val_mae: 0.1575\n",
      "Epoch 453/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2138 - mae: 0.2138 - val_loss: 0.1574 - val_mae: 0.1574\n",
      "Epoch 454/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2132 - mae: 0.2132 - val_loss: 0.1578 - val_mae: 0.1578\n",
      "Epoch 455/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2137 - mae: 0.2137 - val_loss: 0.1585 - val_mae: 0.1585\n",
      "Epoch 456/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2129 - mae: 0.2129 - val_loss: 0.1585 - val_mae: 0.1585\n",
      "Epoch 457/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2144 - mae: 0.2144 - val_loss: 0.1588 - val_mae: 0.1588\n",
      "Epoch 458/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2134 - mae: 0.2134 - val_loss: 0.1595 - val_mae: 0.1595\n",
      "Epoch 459/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2125 - mae: 0.2125 - val_loss: 0.1597 - val_mae: 0.1597\n",
      "Epoch 460/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2121 - mae: 0.2121 - val_loss: 0.1600 - val_mae: 0.1600\n",
      "Epoch 461/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2130 - mae: 0.2130 - val_loss: 0.1608 - val_mae: 0.1608\n",
      "Epoch 462/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2136 - mae: 0.2136 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 463/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2139 - mae: 0.2139 - val_loss: 0.1610 - val_mae: 0.1610\n",
      "Epoch 464/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2132 - mae: 0.2132 - val_loss: 0.1591 - val_mae: 0.1591\n",
      "Epoch 465/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2122 - mae: 0.2122 - val_loss: 0.1588 - val_mae: 0.1588\n",
      "Epoch 466/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2137 - mae: 0.2137 - val_loss: 0.1574 - val_mae: 0.1574\n",
      "Epoch 467/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2124 - mae: 0.2124 - val_loss: 0.1572 - val_mae: 0.1572\n",
      "Epoch 468/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2113 - mae: 0.2113 - val_loss: 0.1573 - val_mae: 0.1573\n",
      "Epoch 469/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2125 - mae: 0.2125 - val_loss: 0.1577 - val_mae: 0.1577\n",
      "Epoch 470/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2108 - mae: 0.2108 - val_loss: 0.1588 - val_mae: 0.1588\n",
      "Epoch 471/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2161 - mae: 0.2161 - val_loss: 0.1618 - val_mae: 0.1618\n",
      "Epoch 472/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2146 - mae: 0.2146 - val_loss: 0.1568 - val_mae: 0.1568\n",
      "Epoch 473/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2162 - mae: 0.2162 - val_loss: 0.1631 - val_mae: 0.1631\n",
      "Epoch 474/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2165 - mae: 0.2165 - val_loss: 0.1556 - val_mae: 0.1556\n",
      "Epoch 475/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2131 - mae: 0.2131 - val_loss: 0.1599 - val_mae: 0.1599\n",
      "Epoch 476/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2179 - mae: 0.2179 - val_loss: 0.1551 - val_mae: 0.1551\n",
      "Epoch 477/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2114 - mae: 0.2114 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 478/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2126 - mae: 0.2126 - val_loss: 0.1574 - val_mae: 0.1574\n",
      "Epoch 479/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2163 - mae: 0.2163 - val_loss: 0.1521 - val_mae: 0.1521\n",
      "Epoch 480/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2137 - mae: 0.2137 - val_loss: 0.1522 - val_mae: 0.1522\n",
      "Epoch 481/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2126 - mae: 0.2126 - val_loss: 0.1522 - val_mae: 0.1522\n",
      "Epoch 482/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2128 - mae: 0.2128 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 483/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2125 - mae: 0.2125 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 484/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2118 - mae: 0.2118 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 485/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2112 - mae: 0.2112 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 486/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2111 - mae: 0.2111 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 487/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2118 - mae: 0.2118 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 488/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2101 - mae: 0.2101 - val_loss: 0.1534 - val_mae: 0.1534\n",
      "Epoch 489/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2115 - mae: 0.2115 - val_loss: 0.1562 - val_mae: 0.1562\n",
      "Epoch 490/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2138 - mae: 0.2138 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 491/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2101 - mae: 0.2101 - val_loss: 0.1537 - val_mae: 0.1537\n",
      "Epoch 492/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2092 - mae: 0.2092 - val_loss: 0.1544 - val_mae: 0.1544\n",
      "Epoch 493/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.2102 - mae: 0.2102 - val_loss: 0.1549 - val_mae: 0.1549\n",
      "Epoch 494/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2110 - mae: 0.2110 - val_loss: 0.1550 - val_mae: 0.1550\n",
      "Epoch 495/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2112 - mae: 0.2112 - val_loss: 0.1554 - val_mae: 0.1554\n",
      "Epoch 496/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2102 - mae: 0.2102 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 497/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2119 - mae: 0.2119 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 498/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2096 - mae: 0.2096 - val_loss: 0.1562 - val_mae: 0.1562\n",
      "Epoch 499/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2119 - mae: 0.2119 - val_loss: 0.1594 - val_mae: 0.1594\n",
      "Epoch 500/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2118 - mae: 0.2118 - val_loss: 0.1573 - val_mae: 0.1573\n",
      "Epoch 501/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2090 - mae: 0.2090 - val_loss: 0.1585 - val_mae: 0.1585\n",
      "Epoch 502/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2103 - mae: 0.2103 - val_loss: 0.1556 - val_mae: 0.1556\n",
      "Epoch 503/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2082 - mae: 0.2082 - val_loss: 0.1542 - val_mae: 0.1542\n",
      "Epoch 504/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2083 - mae: 0.2083 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 505/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2080 - mae: 0.2080 - val_loss: 0.1545 - val_mae: 0.1545\n",
      "Epoch 506/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2085 - mae: 0.2085 - val_loss: 0.1544 - val_mae: 0.1544\n",
      "Epoch 507/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2087 - mae: 0.2087 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 508/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2088 - mae: 0.2088 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 509/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2094 - mae: 0.2094 - val_loss: 0.1552 - val_mae: 0.1552\n",
      "Epoch 510/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2113 - mae: 0.2113 - val_loss: 0.1567 - val_mae: 0.1567\n",
      "Epoch 511/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2121 - mae: 0.2121 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 512/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2097 - mae: 0.2097 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 513/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2083 - mae: 0.2083 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 514/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2079 - mae: 0.2079 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 515/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2091 - mae: 0.2091 - val_loss: 0.1534 - val_mae: 0.1534\n",
      "Epoch 516/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2081 - mae: 0.2081 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 517/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2094 - mae: 0.2094 - val_loss: 0.1519 - val_mae: 0.1519\n",
      "Epoch 518/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2081 - mae: 0.2081 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 519/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2071 - mae: 0.2071 - val_loss: 0.1531 - val_mae: 0.1531\n",
      "Epoch 520/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2075 - mae: 0.2075 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 521/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2073 - mae: 0.2073 - val_loss: 0.1534 - val_mae: 0.1534\n",
      "Epoch 522/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2100 - mae: 0.2100 - val_loss: 0.1522 - val_mae: 0.1522\n",
      "Epoch 523/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2083 - mae: 0.2083 - val_loss: 0.1510 - val_mae: 0.1510\n",
      "Epoch 524/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2080 - mae: 0.2080 - val_loss: 0.1518 - val_mae: 0.1518\n",
      "Epoch 525/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2082 - mae: 0.2082 - val_loss: 0.1523 - val_mae: 0.1523\n",
      "Epoch 526/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2074 - mae: 0.2074 - val_loss: 0.1516 - val_mae: 0.1516\n",
      "Epoch 527/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2075 - mae: 0.2075 - val_loss: 0.1522 - val_mae: 0.1522\n",
      "Epoch 528/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2068 - mae: 0.2068 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 529/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2066 - mae: 0.2066 - val_loss: 0.1545 - val_mae: 0.1545\n",
      "Epoch 530/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2073 - mae: 0.2073 - val_loss: 0.1540 - val_mae: 0.1540\n",
      "Epoch 531/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2101 - mae: 0.2101 - val_loss: 0.1545 - val_mae: 0.1545\n",
      "Epoch 532/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2090 - mae: 0.2090 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 533/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2053 - mae: 0.2053 - val_loss: 0.1531 - val_mae: 0.1531\n",
      "Epoch 534/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2070 - mae: 0.2070 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 535/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2058 - mae: 0.2058 - val_loss: 0.1548 - val_mae: 0.1548\n",
      "Epoch 536/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2109 - mae: 0.2109 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 537/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2059 - mae: 0.2059 - val_loss: 0.1510 - val_mae: 0.1510\n",
      "Epoch 538/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2126 - mae: 0.2126 - val_loss: 0.1651 - val_mae: 0.1651\n",
      "Epoch 539/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2170 - mae: 0.2170 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 540/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2091 - mae: 0.2091 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 541/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2051 - mae: 0.2051 - val_loss: 0.1500 - val_mae: 0.1500\n",
      "Epoch 542/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2057 - mae: 0.2057 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 543/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2064 - mae: 0.2064 - val_loss: 0.1519 - val_mae: 0.1519\n",
      "Epoch 544/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2088 - mae: 0.2088 - val_loss: 0.1508 - val_mae: 0.1508\n",
      "Epoch 545/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2043 - mae: 0.2043 - val_loss: 0.1510 - val_mae: 0.1510\n",
      "Epoch 546/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2056 - mae: 0.2056 - val_loss: 0.1500 - val_mae: 0.1500\n",
      "Epoch 547/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2063 - mae: 0.2063 - val_loss: 0.1507 - val_mae: 0.1507\n",
      "Epoch 548/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2054 - mae: 0.2054 - val_loss: 0.1509 - val_mae: 0.1509\n",
      "Epoch 549/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2060 - mae: 0.2060 - val_loss: 0.1508 - val_mae: 0.1508\n",
      "Epoch 550/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2079 - mae: 0.2079 - val_loss: 0.1501 - val_mae: 0.1501\n",
      "Epoch 551/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2014 - mae: 0.2014 - val_loss: 0.1565 - val_mae: 0.1565\n",
      "Epoch 552/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2131 - mae: 0.2131 - val_loss: 0.1561 - val_mae: 0.1561\n",
      "Epoch 553/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2098 - mae: 0.2098 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 554/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2040 - mae: 0.2040 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 555/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2041 - mae: 0.2041 - val_loss: 0.1495 - val_mae: 0.1495\n",
      "Epoch 556/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2056 - mae: 0.2056 - val_loss: 0.1492 - val_mae: 0.1492\n",
      "Epoch 557/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2033 - mae: 0.2033 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 558/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2035 - mae: 0.2035 - val_loss: 0.1503 - val_mae: 0.1503\n",
      "Epoch 559/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2031 - mae: 0.2031 - val_loss: 0.1507 - val_mae: 0.1507\n",
      "Epoch 560/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2050 - mae: 0.2050 - val_loss: 0.1505 - val_mae: 0.1505\n",
      "Epoch 561/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2036 - mae: 0.2036 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 562/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2026 - mae: 0.2026 - val_loss: 0.1492 - val_mae: 0.1492\n",
      "Epoch 563/10000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.2045 - mae: 0.2045 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 564/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2047 - mae: 0.2047 - val_loss: 0.1491 - val_mae: 0.1491\n",
      "Epoch 565/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2035 - mae: 0.2035 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 566/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2038 - mae: 0.2038 - val_loss: 0.1491 - val_mae: 0.1491\n",
      "Epoch 567/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2028 - mae: 0.2028 - val_loss: 0.1498 - val_mae: 0.1498\n",
      "Epoch 568/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2031 - mae: 0.2031 - val_loss: 0.1510 - val_mae: 0.1510\n",
      "Epoch 569/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2029 - mae: 0.2029 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 570/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2049 - mae: 0.2049 - val_loss: 0.1501 - val_mae: 0.1501\n",
      "Epoch 571/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2046 - mae: 0.2046 - val_loss: 0.1505 - val_mae: 0.1505\n",
      "Epoch 572/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2063 - mae: 0.2063 - val_loss: 0.1484 - val_mae: 0.1484\n",
      "Epoch 573/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2024 - mae: 0.2024 - val_loss: 0.1469 - val_mae: 0.1469\n",
      "Epoch 574/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2034 - mae: 0.2034 - val_loss: 0.1504 - val_mae: 0.1504\n",
      "Epoch 575/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2063 - mae: 0.2063 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 576/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2007 - mae: 0.2007 - val_loss: 0.1475 - val_mae: 0.1475\n",
      "Epoch 577/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2053 - mae: 0.2053 - val_loss: 0.1506 - val_mae: 0.1506\n",
      "Epoch 578/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2091 - mae: 0.2091 - val_loss: 0.1478 - val_mae: 0.1478\n",
      "Epoch 579/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2015 - mae: 0.2015 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 580/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2095 - mae: 0.2095 - val_loss: 0.1537 - val_mae: 0.1537\n",
      "Epoch 581/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2062 - mae: 0.2062 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 582/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2019 - mae: 0.2019 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 583/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2079 - mae: 0.2079 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 584/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2016 - mae: 0.2016 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 585/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2048 - mae: 0.2048 - val_loss: 0.1566 - val_mae: 0.1566\n",
      "Epoch 586/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2090 - mae: 0.2090 - val_loss: 0.1446 - val_mae: 0.1446\n",
      "Epoch 587/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2013 - mae: 0.2013 - val_loss: 0.1484 - val_mae: 0.1484\n",
      "Epoch 588/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2098 - mae: 0.2098 - val_loss: 0.1496 - val_mae: 0.1496\n",
      "Epoch 589/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2089 - mae: 0.2089 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 590/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2025 - mae: 0.2025 - val_loss: 0.1525 - val_mae: 0.1525\n",
      "Epoch 591/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2083 - mae: 0.2083 - val_loss: 0.1505 - val_mae: 0.1505\n",
      "Epoch 592/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2043 - mae: 0.2043 - val_loss: 0.1446 - val_mae: 0.1446\n",
      "Epoch 593/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2034 - mae: 0.2034 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 594/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2117 - mae: 0.2117 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 595/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2016 - mae: 0.2016 - val_loss: 0.1445 - val_mae: 0.1445\n",
      "Epoch 596/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2042 - mae: 0.2042 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 597/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2042 - mae: 0.2042 - val_loss: 0.1437 - val_mae: 0.1437\n",
      "Epoch 598/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2023 - mae: 0.2023 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 599/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2089 - mae: 0.2089 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 600/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2036 - mae: 0.2036 - val_loss: 0.1441 - val_mae: 0.1441\n",
      "Epoch 601/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2002 - mae: 0.2002 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 602/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1994 - mae: 0.1994 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 603/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2041 - mae: 0.2041 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 604/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2011 - mae: 0.2011 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 605/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2006 - mae: 0.2006 - val_loss: 0.1552 - val_mae: 0.1552\n",
      "Epoch 606/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2081 - mae: 0.2081 - val_loss: 0.1489 - val_mae: 0.1489\n",
      "Epoch 607/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.2021 - mae: 0.2021 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 608/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2006 - mae: 0.2006 - val_loss: 0.1442 - val_mae: 0.1442\n",
      "Epoch 609/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2006 - mae: 0.2006 - val_loss: 0.1437 - val_mae: 0.1437\n",
      "Epoch 610/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2007 - mae: 0.2007 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 611/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2037 - mae: 0.2037 - val_loss: 0.1434 - val_mae: 0.1434\n",
      "Epoch 612/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1992 - mae: 0.1992 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 613/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2005 - mae: 0.2005 - val_loss: 0.1441 - val_mae: 0.1441\n",
      "Epoch 614/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2009 - mae: 0.2009 - val_loss: 0.1439 - val_mae: 0.1439\n",
      "Epoch 615/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1992 - mae: 0.1992 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 616/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2005 - mae: 0.2005 - val_loss: 0.1452 - val_mae: 0.1452\n",
      "Epoch 617/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2025 - mae: 0.2025 - val_loss: 0.1478 - val_mae: 0.1478\n",
      "Epoch 618/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2032 - mae: 0.2032 - val_loss: 0.1505 - val_mae: 0.1505\n",
      "Epoch 619/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2020 - mae: 0.2020 - val_loss: 0.1448 - val_mae: 0.1448\n",
      "Epoch 620/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1999 - mae: 0.1999 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 621/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2006 - mae: 0.2006 - val_loss: 0.1441 - val_mae: 0.1441\n",
      "Epoch 622/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1977 - mae: 0.1977 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 623/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2036 - mae: 0.2036 - val_loss: 0.1445 - val_mae: 0.1445\n",
      "Epoch 624/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1982 - mae: 0.1982 - val_loss: 0.1452 - val_mae: 0.1452\n",
      "Epoch 625/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2029 - mae: 0.2029 - val_loss: 0.1467 - val_mae: 0.1467\n",
      "Epoch 626/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.2028 - mae: 0.2028 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 627/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1971 - mae: 0.1971 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 628/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1991 - mae: 0.1991 - val_loss: 0.1460 - val_mae: 0.1460\n",
      "Epoch 629/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1972 - mae: 0.1972 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 630/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2014 - mae: 0.2014 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 631/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1997 - mae: 0.1997 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 632/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1968 - mae: 0.1968 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 633/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2040 - mae: 0.2040 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 634/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1963 - mae: 0.1963 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 635/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2033 - mae: 0.2033 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 636/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1985 - mae: 0.1985 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 637/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2006 - mae: 0.2006 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 638/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2023 - mae: 0.2023 - val_loss: 0.1437 - val_mae: 0.1437\n",
      "Epoch 639/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2004 - mae: 0.2004 - val_loss: 0.1438 - val_mae: 0.1438\n",
      "Epoch 640/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1969 - mae: 0.1969 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 641/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1985 - mae: 0.1985 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 642/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2054 - mae: 0.2054 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 643/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1976 - mae: 0.1976 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 644/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1966 - mae: 0.1966 - val_loss: 0.1481 - val_mae: 0.1481\n",
      "Epoch 645/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2021 - mae: 0.2021 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 646/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2007 - mae: 0.2007 - val_loss: 0.1498 - val_mae: 0.1498\n",
      "Epoch 647/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1973 - mae: 0.1973 - val_loss: 0.1475 - val_mae: 0.1475\n",
      "Epoch 648/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1962 - mae: 0.1962 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 649/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1965 - mae: 0.1965 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 650/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1958 - mae: 0.1958 - val_loss: 0.1434 - val_mae: 0.1434\n",
      "Epoch 651/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1985 - mae: 0.1985 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 652/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1993 - mae: 0.1993 - val_loss: 0.1429 - val_mae: 0.1429\n",
      "Epoch 653/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1952 - mae: 0.1952 - val_loss: 0.1434 - val_mae: 0.1434\n",
      "Epoch 654/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1984 - mae: 0.1984 - val_loss: 0.1439 - val_mae: 0.1439\n",
      "Epoch 655/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1979 - mae: 0.1979 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 656/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1979 - mae: 0.1979 - val_loss: 0.1542 - val_mae: 0.1542\n",
      "Epoch 657/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2036 - mae: 0.2036 - val_loss: 0.1433 - val_mae: 0.1433\n",
      "Epoch 658/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1963 - mae: 0.1963 - val_loss: 0.1431 - val_mae: 0.1431\n",
      "Epoch 659/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1967 - mae: 0.1967 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 660/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1943 - mae: 0.1943 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 661/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1977 - mae: 0.1977 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 662/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1957 - mae: 0.1957 - val_loss: 0.1429 - val_mae: 0.1429\n",
      "Epoch 663/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1978 - mae: 0.1978 - val_loss: 0.1438 - val_mae: 0.1438\n",
      "Epoch 664/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1984 - mae: 0.1984 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 665/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1951 - mae: 0.1951 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 666/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1941 - mae: 0.1941 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 667/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1965 - mae: 0.1965 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 668/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1974 - mae: 0.1974 - val_loss: 0.1403 - val_mae: 0.1403\n",
      "Epoch 669/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1945 - mae: 0.1945 - val_loss: 0.1413 - val_mae: 0.1413\n",
      "Epoch 670/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1941 - mae: 0.1941 - val_loss: 0.1422 - val_mae: 0.1422\n",
      "Epoch 671/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1952 - mae: 0.1952 - val_loss: 0.1433 - val_mae: 0.1433\n",
      "Epoch 672/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1988 - mae: 0.1988 - val_loss: 0.1430 - val_mae: 0.1430\n",
      "Epoch 673/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1939 - mae: 0.1939 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 674/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1958 - mae: 0.1958 - val_loss: 0.1459 - val_mae: 0.1459\n",
      "Epoch 675/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1925 - mae: 0.1925 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 676/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1961 - mae: 0.1961 - val_loss: 0.1415 - val_mae: 0.1415\n",
      "Epoch 677/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1947 - mae: 0.1947 - val_loss: 0.1424 - val_mae: 0.1424\n",
      "Epoch 678/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1977 - mae: 0.1977 - val_loss: 0.1445 - val_mae: 0.1445\n",
      "Epoch 679/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1942 - mae: 0.1942 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 680/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1931 - mae: 0.1931 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 681/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2005 - mae: 0.2005 - val_loss: 0.1408 - val_mae: 0.1408\n",
      "Epoch 682/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1935 - mae: 0.1935 - val_loss: 0.1419 - val_mae: 0.1419\n",
      "Epoch 683/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2022 - mae: 0.2022 - val_loss: 0.1582 - val_mae: 0.1582\n",
      "Epoch 684/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2062 - mae: 0.2062 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 685/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1922 - mae: 0.1922 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 686/10000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2004 - mae: 0.2004 - val_loss: 0.1417 - val_mae: 0.1417\n",
      "Epoch 687/10000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1970 - mae: 0.1970 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 688/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1984 - mae: 0.1984 - val_loss: 0.1495 - val_mae: 0.1495\n",
      "Epoch 689/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1976 - mae: 0.1976 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 690/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1954 - mae: 0.1954 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 691/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1985 - mae: 0.1985 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 692/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1950 - mae: 0.1950 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 693/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1929 - mae: 0.1929 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 694/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1994 - mae: 0.1994 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 695/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1968 - mae: 0.1968 - val_loss: 0.1435 - val_mae: 0.1435\n",
      "Epoch 696/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1964 - mae: 0.1964 - val_loss: 0.1434 - val_mae: 0.1434\n",
      "Epoch 697/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1946 - mae: 0.1946 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 698/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1937 - mae: 0.1937 - val_loss: 0.1371 - val_mae: 0.1371\n",
      "Epoch 699/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1941 - mae: 0.1941 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 700/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1913 - mae: 0.1913 - val_loss: 0.1371 - val_mae: 0.1371\n",
      "Epoch 701/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1970 - mae: 0.1970 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 702/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2084 - mae: 0.2084 - val_loss: 0.1401 - val_mae: 0.1401\n",
      "Epoch 703/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1992 - mae: 0.1992 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 704/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1949 - mae: 0.1949 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 705/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1957 - mae: 0.1957 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 706/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1931 - mae: 0.1931 - val_loss: 0.1400 - val_mae: 0.1400\n",
      "Epoch 707/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1985 - mae: 0.1985 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 708/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1961 - mae: 0.1961 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 709/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1910 - mae: 0.1910 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 710/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1904 - mae: 0.1904 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 711/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1912 - mae: 0.1912 - val_loss: 0.1393 - val_mae: 0.1393\n",
      "Epoch 712/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1912 - mae: 0.1912 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 713/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1896 - mae: 0.1896 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 714/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1899 - mae: 0.1899 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 715/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1896 - mae: 0.1896 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 716/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1930 - mae: 0.1930 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 717/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1918 - mae: 0.1918 - val_loss: 0.1367 - val_mae: 0.1367\n",
      "Epoch 718/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1891 - mae: 0.1891 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 719/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1890 - mae: 0.1890 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 720/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1939 - mae: 0.1939 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 721/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1960 - mae: 0.1960 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 722/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1880 - mae: 0.1880 - val_loss: 0.1437 - val_mae: 0.1437\n",
      "Epoch 723/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1978 - mae: 0.1978 - val_loss: 0.1478 - val_mae: 0.1478\n",
      "Epoch 724/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1943 - mae: 0.1943 - val_loss: 0.1362 - val_mae: 0.1362\n",
      "Epoch 725/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1914 - mae: 0.1914 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 726/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1940 - mae: 0.1940 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 727/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1915 - mae: 0.1915 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 728/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1933 - mae: 0.1933 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 729/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1930 - mae: 0.1930 - val_loss: 0.1363 - val_mae: 0.1363\n",
      "Epoch 730/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1902 - mae: 0.1902 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 731/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1889 - mae: 0.1889 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 732/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1881 - mae: 0.1881 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 733/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1900 - mae: 0.1900 - val_loss: 0.1399 - val_mae: 0.1399\n",
      "Epoch 734/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1906 - mae: 0.1906 - val_loss: 0.1367 - val_mae: 0.1367\n",
      "Epoch 735/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1867 - mae: 0.1867 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 736/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1930 - mae: 0.1930 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 737/10000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1882 - mae: 0.1882 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 738/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1894 - mae: 0.1894 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 739/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1886 - mae: 0.1886 - val_loss: 0.1367 - val_mae: 0.1367\n",
      "Epoch 740/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1900 - mae: 0.1900 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 741/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1883 - mae: 0.1883 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 742/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1865 - mae: 0.1865 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 743/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1879 - mae: 0.1879 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 744/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1881 - mae: 0.1881 - val_loss: 0.1357 - val_mae: 0.1357\n",
      "Epoch 745/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1889 - mae: 0.1889 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 746/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1881 - mae: 0.1881 - val_loss: 0.1351 - val_mae: 0.1351\n",
      "Epoch 747/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1887 - mae: 0.1887 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 748/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1919 - mae: 0.1919 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 749/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1898 - mae: 0.1898 - val_loss: 0.1343 - val_mae: 0.1343\n",
      "Epoch 750/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1865 - mae: 0.1865 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 751/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1863 - mae: 0.1863 - val_loss: 0.1350 - val_mae: 0.1350\n",
      "Epoch 752/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1902 - mae: 0.1902 - val_loss: 0.1341 - val_mae: 0.1341\n",
      "Epoch 753/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1936 - mae: 0.1936 - val_loss: 0.1386 - val_mae: 0.1386\n",
      "Epoch 754/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1925 - mae: 0.1925 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 755/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1878 - mae: 0.1878 - val_loss: 0.1342 - val_mae: 0.1342\n",
      "Epoch 756/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1870 - mae: 0.1870 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 757/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1886 - mae: 0.1886 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 758/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1886 - mae: 0.1886 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 759/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1852 - mae: 0.1852 - val_loss: 0.1362 - val_mae: 0.1362\n",
      "Epoch 760/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1876 - mae: 0.1876 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 761/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1836 - mae: 0.1836 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 762/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1953 - mae: 0.1953 - val_loss: 0.1504 - val_mae: 0.1504\n",
      "Epoch 763/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1915 - mae: 0.1915 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 764/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1945 - mae: 0.1945 - val_loss: 0.1413 - val_mae: 0.1413\n",
      "Epoch 765/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1934 - mae: 0.1934 - val_loss: 0.1350 - val_mae: 0.1350\n",
      "Epoch 766/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1843 - mae: 0.1843 - val_loss: 0.1447 - val_mae: 0.1447\n",
      "Epoch 767/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1917 - mae: 0.1917 - val_loss: 0.1393 - val_mae: 0.1393\n",
      "Epoch 768/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1831 - mae: 0.1831 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 769/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1917 - mae: 0.1917 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 770/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1914 - mae: 0.1914 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 771/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1909 - mae: 0.1909 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 772/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2038 - mae: 0.2038 - val_loss: 0.1519 - val_mae: 0.1519\n",
      "Epoch 773/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1911 - mae: 0.1911 - val_loss: 0.1346 - val_mae: 0.1346\n",
      "Epoch 774/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1859 - mae: 0.1859 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 775/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1946 - mae: 0.1946 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 776/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1853 - mae: 0.1853 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 777/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1996 - mae: 0.1996 - val_loss: 0.1595 - val_mae: 0.1595\n",
      "Epoch 778/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1996 - mae: 0.1996 - val_loss: 0.1342 - val_mae: 0.1342\n",
      "Epoch 779/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1865 - mae: 0.1865 - val_loss: 0.1371 - val_mae: 0.1371\n",
      "Epoch 780/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1928 - mae: 0.1928 - val_loss: 0.1342 - val_mae: 0.1342\n",
      "Epoch 781/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1858 - mae: 0.1858 - val_loss: 0.1390 - val_mae: 0.1390\n",
      "Epoch 782/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1859 - mae: 0.1859 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 783/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1843 - mae: 0.1843 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 784/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1851 - mae: 0.1851 - val_loss: 0.1322 - val_mae: 0.1322\n",
      "Epoch 785/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1859 - mae: 0.1859 - val_loss: 0.1323 - val_mae: 0.1323\n",
      "Epoch 786/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1876 - mae: 0.1876 - val_loss: 0.1328 - val_mae: 0.1328\n",
      "Epoch 787/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1839 - mae: 0.1839 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 788/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1890 - mae: 0.1890 - val_loss: 0.1430 - val_mae: 0.1430\n",
      "Epoch 789/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1894 - mae: 0.1894 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 790/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1855 - mae: 0.1855 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 791/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1974 - mae: 0.1974 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 792/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1856 - mae: 0.1856 - val_loss: 0.1452 - val_mae: 0.1452\n",
      "Epoch 793/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1932 - mae: 0.1932 - val_loss: 0.1611 - val_mae: 0.1611\n",
      "Epoch 794/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1982 - mae: 0.1982 - val_loss: 0.1389 - val_mae: 0.1389\n",
      "Epoch 795/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1839 - mae: 0.1839 - val_loss: 0.1371 - val_mae: 0.1371\n",
      "Epoch 796/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1988 - mae: 0.1988 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 797/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1870 - mae: 0.1870 - val_loss: 0.1390 - val_mae: 0.1390\n",
      "Epoch 798/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1911 - mae: 0.1911 - val_loss: 0.1524 - val_mae: 0.1524\n",
      "Epoch 799/10000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1956 - mae: 0.1956 - val_loss: 0.1338 - val_mae: 0.1338\n",
      "Epoch 800/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1832 - mae: 0.1832 - val_loss: 0.1322 - val_mae: 0.1322\n",
      "Epoch 801/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1840 - mae: 0.1840 - val_loss: 0.1326 - val_mae: 0.1326\n",
      "Epoch 802/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1840 - mae: 0.1840 - val_loss: 0.1351 - val_mae: 0.1351\n",
      "Epoch 803/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1866 - mae: 0.1866 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 804/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1884 - mae: 0.1884 - val_loss: 0.1332 - val_mae: 0.1332\n",
      "Epoch 805/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1844 - mae: 0.1844 - val_loss: 0.1333 - val_mae: 0.1333\n",
      "Epoch 806/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1829 - mae: 0.1829 - val_loss: 0.1344 - val_mae: 0.1344\n",
      "Epoch 807/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1832 - mae: 0.1832 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 808/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1852 - mae: 0.1852 - val_loss: 0.1334 - val_mae: 0.1334\n",
      "Epoch 809/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1816 - mae: 0.1816 - val_loss: 0.1326 - val_mae: 0.1326\n",
      "Epoch 810/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1815 - mae: 0.1815 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 811/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1813 - mae: 0.1813 - val_loss: 0.1332 - val_mae: 0.1332\n",
      "Epoch 812/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1813 - mae: 0.1813 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 813/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1810 - mae: 0.1810 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 814/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1823 - mae: 0.1823 - val_loss: 0.1346 - val_mae: 0.1346\n",
      "Epoch 815/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1831 - mae: 0.1831 - val_loss: 0.1326 - val_mae: 0.1326\n",
      "Epoch 816/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1847 - mae: 0.1847 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 817/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1874 - mae: 0.1874 - val_loss: 0.1334 - val_mae: 0.1334\n",
      "Epoch 818/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1821 - mae: 0.1821 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 819/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1840 - mae: 0.1840 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 820/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1864 - mae: 0.1864 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 821/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1836 - mae: 0.1836 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 822/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1806 - mae: 0.1806 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 823/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1813 - mae: 0.1813 - val_loss: 0.1338 - val_mae: 0.1338\n",
      "Epoch 824/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1809 - mae: 0.1809 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 825/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1805 - mae: 0.1805 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 826/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1802 - mae: 0.1802 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 827/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1806 - mae: 0.1806 - val_loss: 0.1338 - val_mae: 0.1338\n",
      "Epoch 828/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1795 - mae: 0.1795 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 829/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1819 - mae: 0.1819 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 830/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1812 - mae: 0.1812 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 831/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1832 - mae: 0.1832 - val_loss: 0.1313 - val_mae: 0.1313\n",
      "Epoch 832/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1797 - mae: 0.1797 - val_loss: 0.1313 - val_mae: 0.1313\n",
      "Epoch 833/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1790 - mae: 0.1790 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 834/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1832 - mae: 0.1832 - val_loss: 0.1360 - val_mae: 0.1360\n",
      "Epoch 835/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1811 - mae: 0.1811 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 836/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1794 - mae: 0.1794 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 837/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1813 - mae: 0.1813 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 838/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1793 - mae: 0.1793 - val_loss: 0.1323 - val_mae: 0.1323\n",
      "Epoch 839/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1801 - mae: 0.1801 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 840/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1850 - mae: 0.1850 - val_loss: 0.1313 - val_mae: 0.1313\n",
      "Epoch 841/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1795 - mae: 0.1795 - val_loss: 0.1365 - val_mae: 0.1365\n",
      "Epoch 842/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1837 - mae: 0.1837 - val_loss: 0.1399 - val_mae: 0.1399\n",
      "Epoch 843/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1857 - mae: 0.1857 - val_loss: 0.1326 - val_mae: 0.1326\n",
      "Epoch 844/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1787 - mae: 0.1787 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 845/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1802 - mae: 0.1802 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 846/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1784 - mae: 0.1784 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 847/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1805 - mae: 0.1805 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 848/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1817 - mae: 0.1817 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 849/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1901 - mae: 0.1901 - val_loss: 0.1384 - val_mae: 0.1384\n",
      "Epoch 850/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1924 - mae: 0.1924 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 851/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1825 - mae: 0.1825 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 852/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1808 - mae: 0.1808 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 853/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1791 - mae: 0.1791 - val_loss: 0.1299 - val_mae: 0.1299\n",
      "Epoch 854/10000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1793 - mae: 0.1793 - val_loss: 0.1299 - val_mae: 0.1299\n",
      "Epoch 855/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1784 - mae: 0.1784 - val_loss: 0.1313 - val_mae: 0.1313\n",
      "Epoch 856/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1778 - mae: 0.1778 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 857/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1794 - mae: 0.1794 - val_loss: 0.1302 - val_mae: 0.1302\n",
      "Epoch 858/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1786 - mae: 0.1786 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 859/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1774 - mae: 0.1774 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 860/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1776 - mae: 0.1776 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 861/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1777 - mae: 0.1777 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 862/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1777 - mae: 0.1777 - val_loss: 0.1336 - val_mae: 0.1336\n",
      "Epoch 863/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1779 - mae: 0.1779 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 864/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1771 - mae: 0.1771 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 865/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1799 - mae: 0.1799 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 866/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1771 - mae: 0.1771 - val_loss: 0.1365 - val_mae: 0.1365\n",
      "Epoch 867/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1786 - mae: 0.1786 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 868/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1774 - mae: 0.1774 - val_loss: 0.1328 - val_mae: 0.1328\n",
      "Epoch 869/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1769 - mae: 0.1769 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 870/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1786 - mae: 0.1786 - val_loss: 0.1318 - val_mae: 0.1318\n",
      "Epoch 871/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1798 - mae: 0.1798 - val_loss: 0.1438 - val_mae: 0.1438\n",
      "Epoch 872/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1847 - mae: 0.1847 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 873/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1779 - mae: 0.1779 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 874/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1853 - mae: 0.1853 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 875/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1795 - mae: 0.1795 - val_loss: 0.1452 - val_mae: 0.1452\n",
      "Epoch 876/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1884 - mae: 0.1884 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 877/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1841 - mae: 0.1841 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 878/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1812 - mae: 0.1812 - val_loss: 0.1343 - val_mae: 0.1343\n",
      "Epoch 879/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1823 - mae: 0.1823 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 880/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1767 - mae: 0.1767 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 881/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1765 - mae: 0.1765 - val_loss: 0.1323 - val_mae: 0.1323\n",
      "Epoch 882/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1768 - mae: 0.1768 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 883/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1773 - mae: 0.1773 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 884/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1801 - mae: 0.1801 - val_loss: 0.1346 - val_mae: 0.1346\n",
      "Epoch 885/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1789 - mae: 0.1789 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 886/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1805 - mae: 0.1805 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 887/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1778 - mae: 0.1778 - val_loss: 0.1334 - val_mae: 0.1334\n",
      "Epoch 888/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1759 - mae: 0.1759 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 889/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1827 - mae: 0.1827 - val_loss: 0.1346 - val_mae: 0.1346\n",
      "Epoch 890/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1776 - mae: 0.1776 - val_loss: 0.1302 - val_mae: 0.1302\n",
      "Epoch 891/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1772 - mae: 0.1772 - val_loss: 0.1318 - val_mae: 0.1318\n",
      "Epoch 892/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1753 - mae: 0.1753 - val_loss: 0.1336 - val_mae: 0.1336\n",
      "Epoch 893/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1768 - mae: 0.1768 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 894/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1747 - mae: 0.1747 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 895/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1768 - mae: 0.1768 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 896/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1745 - mae: 0.1745 - val_loss: 0.1362 - val_mae: 0.1362\n",
      "Epoch 897/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1868 - mae: 0.1868 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 898/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1850 - mae: 0.1850 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 899/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1744 - mae: 0.1744 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 900/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1797 - mae: 0.1797 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 901/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1750 - mae: 0.1750 - val_loss: 0.1331 - val_mae: 0.1331\n",
      "Epoch 902/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1828 - mae: 0.1828 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 903/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1849 - mae: 0.1849 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 904/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1753 - mae: 0.1753 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 905/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1769 - mae: 0.1769 - val_loss: 0.1317 - val_mae: 0.1317\n",
      "Epoch 906/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1738 - mae: 0.1738 - val_loss: 0.1314 - val_mae: 0.1314\n",
      "Epoch 907/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1768 - mae: 0.1768 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 908/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1843 - mae: 0.1843 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 909/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1790 - mae: 0.1790 - val_loss: 0.1457 - val_mae: 0.1457\n",
      "Epoch 910/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1852 - mae: 0.1852 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 911/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1760 - mae: 0.1760 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 912/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1769 - mae: 0.1769 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 913/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1906 - mae: 0.1906 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 914/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1797 - mae: 0.1797 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 915/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1765 - mae: 0.1765 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 916/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1749 - mae: 0.1749 - val_loss: 0.1297 - val_mae: 0.1297\n",
      "Epoch 917/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1775 - mae: 0.1775 - val_loss: 0.1321 - val_mae: 0.1321\n",
      "Epoch 918/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1773 - mae: 0.1773 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 919/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1767 - mae: 0.1767 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 920/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1735 - mae: 0.1735 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 921/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1771 - mae: 0.1771 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 922/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1811 - mae: 0.1811 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 923/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1730 - mae: 0.1730 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 924/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1791 - mae: 0.1791 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 925/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1756 - mae: 0.1756 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 926/10000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1740 - mae: 0.1740 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 927/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1732 - mae: 0.1732 - val_loss: 0.1365 - val_mae: 0.1365\n",
      "Epoch 928/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1738 - mae: 0.1738 - val_loss: 0.1313 - val_mae: 0.1313\n",
      "Epoch 929/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1746 - mae: 0.1746 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 930/10000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1816 - mae: 0.1816 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 931/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1784 - mae: 0.1784 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 932/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1732 - mae: 0.1732 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 933/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1735 - mae: 0.1735 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 934/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1734 - mae: 0.1734 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 935/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1790 - mae: 0.1790 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 936/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1907 - mae: 0.1907 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 937/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1783 - mae: 0.1783 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 938/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1787 - mae: 0.1787 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 939/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1828 - mae: 0.1828 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 940/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1705 - mae: 0.1705 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 941/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1786 - mae: 0.1786 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 942/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1817 - mae: 0.1817 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 943/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1736 - mae: 0.1736 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 944/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1746 - mae: 0.1746 - val_loss: 0.1365 - val_mae: 0.1365\n",
      "Epoch 945/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1752 - mae: 0.1752 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 946/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1725 - mae: 0.1725 - val_loss: 0.1336 - val_mae: 0.1336\n",
      "Epoch 947/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 948/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1715 - mae: 0.1715 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 949/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1722 - mae: 0.1722 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 950/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1717 - mae: 0.1717 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 951/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1738 - mae: 0.1738 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 952/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1756 - mae: 0.1756 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 953/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1706 - mae: 0.1706 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 954/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1761 - mae: 0.1761 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 955/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1711 - mae: 0.1711 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 956/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1740 - mae: 0.1740 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 957/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1784 - mae: 0.1784 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 958/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1742 - mae: 0.1742 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 959/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1770 - mae: 0.1770 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 960/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1798 - mae: 0.1798 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 961/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 962/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1723 - mae: 0.1723 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 963/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1707 - mae: 0.1707 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 964/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1698 - mae: 0.1698 - val_loss: 0.1291 - val_mae: 0.1291\n",
      "Epoch 965/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1697 - mae: 0.1697 - val_loss: 0.1317 - val_mae: 0.1317\n",
      "Epoch 966/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1705 - mae: 0.1705 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 967/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1718 - mae: 0.1718 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 968/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1698 - mae: 0.1698 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 969/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1699 - mae: 0.1699 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 970/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 971/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1713 - mae: 0.1713 - val_loss: 0.1314 - val_mae: 0.1314\n",
      "Epoch 972/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1695 - mae: 0.1695 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 973/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1704 - mae: 0.1704 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 974/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1695 - mae: 0.1695 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 975/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1729 - mae: 0.1729 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 976/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1723 - mae: 0.1723 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 977/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.1446 - val_mae: 0.1446\n",
      "Epoch 978/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1760 - mae: 0.1760 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 979/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1704 - mae: 0.1704 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 980/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1840 - mae: 0.1840 - val_loss: 0.1430 - val_mae: 0.1430\n",
      "Epoch 981/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1835 - mae: 0.1835 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 982/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1726 - mae: 0.1726 - val_loss: 0.1552 - val_mae: 0.1552\n",
      "Epoch 983/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1969 - mae: 0.1969 - val_loss: 0.1539 - val_mae: 0.1539\n",
      "Epoch 984/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1859 - mae: 0.1859 - val_loss: 0.1291 - val_mae: 0.1291\n",
      "Epoch 985/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1777 - mae: 0.1777 - val_loss: 0.1455 - val_mae: 0.1455\n",
      "Epoch 986/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1877 - mae: 0.1877 - val_loss: 0.1344 - val_mae: 0.1344\n",
      "Epoch 987/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1729 - mae: 0.1729 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 988/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1754 - mae: 0.1754 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 989/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1701 - mae: 0.1701 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 990/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1759 - mae: 0.1759 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 991/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1712 - mae: 0.1712 - val_loss: 0.1343 - val_mae: 0.1343\n",
      "Epoch 992/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1699 - mae: 0.1699 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 993/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1761 - mae: 0.1761 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 994/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1686 - mae: 0.1686 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 995/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1732 - mae: 0.1732 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 996/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 997/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 998/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.1277 - val_mae: 0.1277\n",
      "Epoch 999/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 1000/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1708 - mae: 0.1708 - val_loss: 0.1292 - val_mae: 0.1292\n",
      "Epoch 1001/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1709 - mae: 0.1709 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 1002/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1709 - mae: 0.1709 - val_loss: 0.1276 - val_mae: 0.1276\n",
      "Epoch 1003/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 1004/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1700 - mae: 0.1700 - val_loss: 0.1268 - val_mae: 0.1268\n",
      "Epoch 1005/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 1006/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1683 - mae: 0.1683 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 1007/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1684 - mae: 0.1684 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 1008/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1682 - mae: 0.1682 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 1009/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1696 - mae: 0.1696 - val_loss: 0.1318 - val_mae: 0.1318\n",
      "Epoch 1010/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1681 - mae: 0.1681 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 1011/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1696 - mae: 0.1696 - val_loss: 0.1276 - val_mae: 0.1276\n",
      "Epoch 1012/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1700 - mae: 0.1700 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 1013/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1695 - mae: 0.1695 - val_loss: 0.1273 - val_mae: 0.1273\n",
      "Epoch 1014/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1674 - mae: 0.1674 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 1015/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1743 - mae: 0.1743 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 1016/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1676 - mae: 0.1676 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 1017/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1749 - mae: 0.1749 - val_loss: 0.1427 - val_mae: 0.1427\n",
      "Epoch 1018/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1725 - mae: 0.1725 - val_loss: 0.1281 - val_mae: 0.1281\n",
      "Epoch 1019/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1686 - mae: 0.1686 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 1020/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1291 - val_mae: 0.1291\n",
      "Epoch 1021/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1681 - mae: 0.1681 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 1022/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1684 - mae: 0.1684 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 1023/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1659 - mae: 0.1659 - val_loss: 0.1279 - val_mae: 0.1279\n",
      "Epoch 1024/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1681 - mae: 0.1681 - val_loss: 0.1283 - val_mae: 0.1283\n",
      "Epoch 1025/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1681 - mae: 0.1681 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1026/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1658 - mae: 0.1658 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 1027/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1288 - val_mae: 0.1288\n",
      "Epoch 1028/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1653 - mae: 0.1653 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 1029/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 1030/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 1031/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1657 - mae: 0.1657 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 1032/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 1033/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1672 - mae: 0.1672 - val_loss: 0.1288 - val_mae: 0.1288\n",
      "Epoch 1034/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 1035/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1668 - mae: 0.1668 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 1036/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 1037/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1654 - mae: 0.1654 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 1038/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1777 - mae: 0.1777 - val_loss: 0.1365 - val_mae: 0.1365\n",
      "Epoch 1039/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1731 - mae: 0.1731 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 1040/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1713 - mae: 0.1713 - val_loss: 0.1417 - val_mae: 0.1417\n",
      "Epoch 1041/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 1042/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1711 - mae: 0.1711 - val_loss: 0.1333 - val_mae: 0.1333\n",
      "Epoch 1043/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1715 - mae: 0.1715 - val_loss: 0.1331 - val_mae: 0.1331\n",
      "Epoch 1044/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1685 - mae: 0.1685 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 1045/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1643 - mae: 0.1643 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 1046/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1673 - mae: 0.1673 - val_loss: 0.1363 - val_mae: 0.1363\n",
      "Epoch 1047/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1741 - mae: 0.1741 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1048/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1725 - mae: 0.1725 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 1049/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1678 - mae: 0.1678 - val_loss: 0.1346 - val_mae: 0.1346\n",
      "Epoch 1050/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 1051/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1688 - mae: 0.1688 - val_loss: 0.1294 - val_mae: 0.1294\n",
      "Epoch 1052/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1633 - mae: 0.1633 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 1053/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1707 - mae: 0.1707 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 1054/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1750 - mae: 0.1750 - val_loss: 0.1336 - val_mae: 0.1336\n",
      "Epoch 1055/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1656 - mae: 0.1656 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1056/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1836 - mae: 0.1836 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 1057/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1735 - mae: 0.1735 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 1058/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1710 - mae: 0.1710 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 1059/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1714 - mae: 0.1714 - val_loss: 0.1302 - val_mae: 0.1302\n",
      "Epoch 1060/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1653 - mae: 0.1653 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 1061/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1668 - mae: 0.1668 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 1062/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1651 - mae: 0.1651 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 1063/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1671 - mae: 0.1671 - val_loss: 0.1460 - val_mae: 0.1460\n",
      "Epoch 1064/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1781 - mae: 0.1781 - val_loss: 0.1420 - val_mae: 0.1420\n",
      "Epoch 1065/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1714 - mae: 0.1714 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 1066/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 1067/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.1322 - val_mae: 0.1322\n",
      "Epoch 1068/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1637 - mae: 0.1637 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 1069/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1655 - mae: 0.1655 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 1070/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1637 - mae: 0.1637 - val_loss: 0.1288 - val_mae: 0.1288\n",
      "Epoch 1071/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1659 - mae: 0.1659 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 1072/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1635 - mae: 0.1635 - val_loss: 0.1447 - val_mae: 0.1447\n",
      "Epoch 1073/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1726 - mae: 0.1726 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 1074/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1669 - mae: 0.1669 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 1075/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1646 - mae: 0.1646 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 1076/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1648 - mae: 0.1648 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 1077/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1666 - mae: 0.1666 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1078/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1676 - mae: 0.1676 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 1079/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1673 - mae: 0.1673 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 1080/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1648 - mae: 0.1648 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1081/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1673 - mae: 0.1673 - val_loss: 0.1427 - val_mae: 0.1427\n",
      "Epoch 1082/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1675 - mae: 0.1675 - val_loss: 0.1333 - val_mae: 0.1333\n",
      "Epoch 1083/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1633 - mae: 0.1633 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 1084/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 1085/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1614 - mae: 0.1614 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 1086/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1669 - mae: 0.1669 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 1087/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1630 - mae: 0.1630 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 1088/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1668 - mae: 0.1668 - val_loss: 0.1322 - val_mae: 0.1322\n",
      "Epoch 1089/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1667 - mae: 0.1667 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 1090/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1644 - mae: 0.1644 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 1091/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1619 - mae: 0.1619 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 1092/10000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1624 - mae: 0.1624 - val_loss: 0.1297 - val_mae: 0.1297\n",
      "Epoch 1093/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1627 - mae: 0.1627 - val_loss: 0.1343 - val_mae: 0.1343\n",
      "Epoch 1094/10000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1703 - mae: 0.1703 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 1095/10000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1660 - mae: 0.1660 - val_loss: 0.1294 - val_mae: 0.1294\n",
      "Epoch 1096/10000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 1097/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1721 - mae: 0.1721 - val_loss: 0.1297 - val_mae: 0.1297\n",
      "Epoch 1098/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 1099/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 1100/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1741 - mae: 0.1741 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 1101/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1643 - mae: 0.1643 - val_loss: 0.1317 - val_mae: 0.1317\n",
      "Epoch 1102/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1619 - mae: 0.1619 - val_loss: 0.1328 - val_mae: 0.1328\n",
      "Epoch 1103/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1617 - mae: 0.1617 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 1104/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1621 - mae: 0.1621 - val_loss: 0.1281 - val_mae: 0.1281\n",
      "Epoch 1105/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1659 - mae: 0.1659 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 1106/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1741 - mae: 0.1741 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 1107/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1651 - mae: 0.1651 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 1108/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1689 - mae: 0.1689 - val_loss: 0.1453 - val_mae: 0.1453\n",
      "Epoch 1109/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.1286 - val_mae: 0.1286\n",
      "Epoch 1110/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1637 - mae: 0.1637 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 1111/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1689 - mae: 0.1689 - val_loss: 0.1285 - val_mae: 0.1285\n",
      "Epoch 1112/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1646 - mae: 0.1646 - val_loss: 0.1313 - val_mae: 0.1313\n",
      "Epoch 1113/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1612 - mae: 0.1612 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 1114/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 1115/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1606 - mae: 0.1606 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 1116/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1627 - mae: 0.1627 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 1117/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1610 - mae: 0.1610 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 1118/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 1119/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 1120/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1613 - mae: 0.1613 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 1121/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.1291 - val_mae: 0.1291\n",
      "Epoch 1122/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1632 - mae: 0.1632 - val_loss: 0.1279 - val_mae: 0.1279\n",
      "Epoch 1123/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.1314 - val_mae: 0.1314\n",
      "Epoch 1124/10000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 1125/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1657 - mae: 0.1657 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1126/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1651 - mae: 0.1651 - val_loss: 0.1277 - val_mae: 0.1277\n",
      "Epoch 1127/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1273 - val_mae: 0.1273\n",
      "Epoch 1128/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 1129/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 1130/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1590 - mae: 0.1590 - val_loss: 0.1328 - val_mae: 0.1328\n",
      "Epoch 1131/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1350 - val_mae: 0.1350\n",
      "Epoch 1132/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1268 - val_mae: 0.1268\n",
      "Epoch 1133/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.1283 - val_mae: 0.1283\n",
      "Epoch 1134/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1593 - mae: 0.1593 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 1135/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1302 - val_mae: 0.1302\n",
      "Epoch 1136/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1595 - mae: 0.1595 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 1137/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1612 - mae: 0.1612 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 1138/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 1139/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1588 - mae: 0.1588 - val_loss: 0.1285 - val_mae: 0.1285\n",
      "Epoch 1140/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1615 - mae: 0.1615 - val_loss: 0.1288 - val_mae: 0.1288\n",
      "Epoch 1141/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1634 - mae: 0.1634 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 1142/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1593 - mae: 0.1593 - val_loss: 0.1286 - val_mae: 0.1286\n",
      "Epoch 1143/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1591 - mae: 0.1591 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 1144/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 1145/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1286 - val_mae: 0.1286\n",
      "Epoch 1146/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 1147/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1656 - mae: 0.1656 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 1148/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1586 - mae: 0.1586 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1149/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1615 - mae: 0.1615 - val_loss: 0.1357 - val_mae: 0.1357\n",
      "Epoch 1150/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1617 - mae: 0.1617 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 1151/10000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1589 - mae: 0.1589 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 1152/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1587 - mae: 0.1587 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 1153/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1154/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.1282 - val_mae: 0.1282\n",
      "Epoch 1155/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1587 - mae: 0.1587 - val_loss: 0.1289 - val_mae: 0.1289\n",
      "Epoch 1156/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1593 - mae: 0.1593 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 1157/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 1158/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1575 - mae: 0.1575 - val_loss: 0.1259 - val_mae: 0.1259\n",
      "Epoch 1159/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1583 - mae: 0.1583 - val_loss: 0.1262 - val_mae: 0.1262\n",
      "Epoch 1160/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1577 - mae: 0.1577 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 1161/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1609 - mae: 0.1609 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1162/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1631 - mae: 0.1631 - val_loss: 0.1341 - val_mae: 0.1341\n",
      "Epoch 1163/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1569 - mae: 0.1569 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 1164/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1641 - mae: 0.1641 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 1165/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1641 - mae: 0.1641 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 1166/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 1167/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1705 - mae: 0.1705 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 1168/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1263 - val_mae: 0.1263\n",
      "Epoch 1169/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.1328 - val_mae: 0.1328\n",
      "Epoch 1170/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1671 - mae: 0.1671 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 1171/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1636 - mae: 0.1636 - val_loss: 0.1331 - val_mae: 0.1331\n",
      "Epoch 1172/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 1173/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1612 - mae: 0.1612 - val_loss: 0.1332 - val_mae: 0.1332\n",
      "Epoch 1174/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 1175/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1610 - mae: 0.1610 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 1176/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1563 - mae: 0.1563 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 1177/10000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1427 - val_mae: 0.1427\n",
      "Epoch 1178/10000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1630 - mae: 0.1630 - val_loss: 0.1262 - val_mae: 0.1262\n",
      "Epoch 1179/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1604 - mae: 0.1604 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1180/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1852 - mae: 0.1852 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 1181/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1651 - mae: 0.1651 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 1182/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1611 - mae: 0.1611 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 1183/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1653 - mae: 0.1653 - val_loss: 0.1289 - val_mae: 0.1289\n",
      "Epoch 1184/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1583 - mae: 0.1583 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 1185/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1567 - mae: 0.1567 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 1186/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1568 - mae: 0.1568 - val_loss: 0.1390 - val_mae: 0.1390\n",
      "Epoch 1187/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 1188/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1574 - mae: 0.1574 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 1189/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1614 - mae: 0.1614 - val_loss: 0.1259 - val_mae: 0.1259\n",
      "Epoch 1190/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1563 - mae: 0.1563 - val_loss: 0.1323 - val_mae: 0.1323\n",
      "Epoch 1191/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1571 - mae: 0.1571 - val_loss: 0.1297 - val_mae: 0.1297\n",
      "Epoch 1192/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1564 - mae: 0.1564 - val_loss: 0.1286 - val_mae: 0.1286\n",
      "Epoch 1193/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1564 - mae: 0.1564 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 1194/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1567 - mae: 0.1567 - val_loss: 0.1328 - val_mae: 0.1328\n",
      "Epoch 1195/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1590 - mae: 0.1590 - val_loss: 0.1297 - val_mae: 0.1297\n",
      "Epoch 1196/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1567 - mae: 0.1567 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 1197/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1563 - mae: 0.1563 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 1198/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1569 - mae: 0.1569 - val_loss: 0.1338 - val_mae: 0.1338\n",
      "Epoch 1199/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1609 - mae: 0.1609 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 1200/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1582 - mae: 0.1582 - val_loss: 0.1334 - val_mae: 0.1334\n",
      "Epoch 1201/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1583 - mae: 0.1583 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1202/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 1203/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1549 - mae: 0.1549 - val_loss: 0.1314 - val_mae: 0.1314\n",
      "Epoch 1204/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1277 - val_mae: 0.1277\n",
      "Epoch 1205/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1591 - mae: 0.1591 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1206/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1637 - mae: 0.1637 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 1207/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1582 - mae: 0.1582 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 1208/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1551 - mae: 0.1551 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 1209/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1563 - mae: 0.1563 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 1210/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1559 - mae: 0.1559 - val_loss: 0.1386 - val_mae: 0.1386\n",
      "Epoch 1211/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1590 - mae: 0.1590 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 1212/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1592 - mae: 0.1592 - val_loss: 0.1351 - val_mae: 0.1351\n",
      "Epoch 1213/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1545 - mae: 0.1545 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 1214/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1549 - mae: 0.1549 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 1215/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.1285 - val_mae: 0.1285\n",
      "Epoch 1216/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1555 - mae: 0.1555 - val_loss: 0.1317 - val_mae: 0.1317\n",
      "Epoch 1217/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1555 - mae: 0.1555 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 1218/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1542 - mae: 0.1542 - val_loss: 0.1262 - val_mae: 0.1262\n",
      "Epoch 1219/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1564 - mae: 0.1564 - val_loss: 0.1266 - val_mae: 0.1266\n",
      "Epoch 1220/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1556 - mae: 0.1556 - val_loss: 0.1281 - val_mae: 0.1281\n",
      "Epoch 1221/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1563 - mae: 0.1563 - val_loss: 0.1363 - val_mae: 0.1363\n",
      "Epoch 1222/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1613 - mae: 0.1613 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 1223/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 1224/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1562 - mae: 0.1562 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 1225/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1226/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1550 - mae: 0.1550 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1227/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1546 - mae: 0.1546 - val_loss: 0.1289 - val_mae: 0.1289\n",
      "Epoch 1228/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1542 - mae: 0.1542 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 1229/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1534 - mae: 0.1534 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 1230/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1541 - mae: 0.1541 - val_loss: 0.1302 - val_mae: 0.1302\n",
      "Epoch 1231/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.1266 - val_mae: 0.1266\n",
      "Epoch 1232/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1535 - mae: 0.1535 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 1233/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1622 - mae: 0.1622 - val_loss: 0.1286 - val_mae: 0.1286\n",
      "Epoch 1234/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1581 - mae: 0.1581 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 1235/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1561 - mae: 0.1561 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 1236/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1586 - mae: 0.1586 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 1237/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1553 - mae: 0.1553 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 1238/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1534 - mae: 0.1534 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 1239/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1535 - mae: 0.1535 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 1240/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1551 - mae: 0.1551 - val_loss: 0.1264 - val_mae: 0.1264\n",
      "Epoch 1241/10000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1535 - mae: 0.1535 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 1242/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1545 - mae: 0.1545 - val_loss: 0.1351 - val_mae: 0.1351\n",
      "Epoch 1243/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1569 - mae: 0.1569 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 1244/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1530 - mae: 0.1530 - val_loss: 0.1268 - val_mae: 0.1268\n",
      "Epoch 1245/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.1286 - val_mae: 0.1286\n",
      "Epoch 1246/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1540 - mae: 0.1540 - val_loss: 0.1289 - val_mae: 0.1289\n",
      "Epoch 1247/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1540 - mae: 0.1540 - val_loss: 0.1294 - val_mae: 0.1294\n",
      "Epoch 1248/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1540 - mae: 0.1540 - val_loss: 0.1279 - val_mae: 0.1279\n",
      "Epoch 1249/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1540 - mae: 0.1540 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 1250/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1531 - mae: 0.1531 - val_loss: 0.1289 - val_mae: 0.1289\n",
      "Epoch 1251/10000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1538 - mae: 0.1538 - val_loss: 0.1331 - val_mae: 0.1331\n",
      "Epoch 1252/10000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1535 - mae: 0.1535 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 1253/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1529 - mae: 0.1529 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 1254/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1527 - mae: 0.1527 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 1255/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1540 - mae: 0.1540 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 1256/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1520 - mae: 0.1520 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 1257/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1521 - mae: 0.1521 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 1258/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1518 - mae: 0.1518 - val_loss: 0.1268 - val_mae: 0.1268\n",
      "Epoch 1259/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1528 - mae: 0.1528 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 1260/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1560 - mae: 0.1560 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 1261/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 1262/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1526 - mae: 0.1526 - val_loss: 0.1292 - val_mae: 0.1292\n",
      "Epoch 1263/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1545 - mae: 0.1545 - val_loss: 0.1279 - val_mae: 0.1279\n",
      "Epoch 1264/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1520 - mae: 0.1520 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 1265/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1518 - mae: 0.1518 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1266/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1518 - mae: 0.1518 - val_loss: 0.1255 - val_mae: 0.1255\n",
      "Epoch 1267/10000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1547 - mae: 0.1547 - val_loss: 0.1260 - val_mae: 0.1260\n",
      "Epoch 1268/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1516 - mae: 0.1516 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 1269/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1542 - mae: 0.1542 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 1270/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1512 - mae: 0.1512 - val_loss: 0.1256 - val_mae: 0.1256\n",
      "Epoch 1271/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1528 - mae: 0.1528 - val_loss: 0.1257 - val_mae: 0.1257\n",
      "Epoch 1272/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1518 - mae: 0.1518 - val_loss: 0.1273 - val_mae: 0.1273\n",
      "Epoch 1273/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1521 - mae: 0.1521 - val_loss: 0.1291 - val_mae: 0.1291\n",
      "Epoch 1274/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1527 - mae: 0.1527 - val_loss: 0.1321 - val_mae: 0.1321\n",
      "Epoch 1275/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1554 - mae: 0.1554 - val_loss: 0.1246 - val_mae: 0.1246\n",
      "Epoch 1276/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1529 - mae: 0.1529 - val_loss: 0.1253 - val_mae: 0.1253\n",
      "Epoch 1277/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1505 - mae: 0.1505 - val_loss: 0.1297 - val_mae: 0.1297\n",
      "Epoch 1278/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1512 - mae: 0.1512 - val_loss: 0.1336 - val_mae: 0.1336\n",
      "Epoch 1279/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1530 - mae: 0.1530 - val_loss: 0.1338 - val_mae: 0.1338\n",
      "Epoch 1280/10000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1509 - mae: 0.1509 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 1281/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1518 - mae: 0.1518 - val_loss: 0.1288 - val_mae: 0.1288\n",
      "Epoch 1282/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1505 - mae: 0.1505 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 1283/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1515 - mae: 0.1515 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 1284/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1532 - mae: 0.1532 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1285/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1492 - mae: 0.1492 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 1286/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1511 - mae: 0.1511 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 1287/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1558 - mae: 0.1558 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 1288/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1510 - mae: 0.1510 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 1289/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1576 - mae: 0.1576 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 1290/10000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.1565 - mae: 0.1565 - val_loss: 0.1286 - val_mae: 0.1286\n",
      "Epoch 1291/10000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1500 - mae: 0.1500 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 1292/10000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.1633 - mae: 0.1633 - val_loss: 0.1367 - val_mae: 0.1367\n",
      "Epoch 1293/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1494 - mae: 0.1494 - val_loss: 0.1346 - val_mae: 0.1346\n",
      "Epoch 1294/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1656 - mae: 0.1656 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 1295/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1561 - mae: 0.1561 - val_loss: 0.1343 - val_mae: 0.1343\n",
      "Epoch 1296/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1509 - mae: 0.1509 - val_loss: 0.1413 - val_mae: 0.1413\n",
      "Epoch 1297/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1570 - mae: 0.1570 - val_loss: 0.1399 - val_mae: 0.1399\n",
      "Epoch 1298/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1544 - mae: 0.1544 - val_loss: 0.1362 - val_mae: 0.1362\n",
      "Epoch 1299/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1515 - mae: 0.1515 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 1300/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1505 - mae: 0.1505 - val_loss: 0.1282 - val_mae: 0.1282\n",
      "Epoch 1301/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1510 - mae: 0.1510 - val_loss: 0.1292 - val_mae: 0.1292\n",
      "Epoch 1302/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1491 - mae: 0.1491 - val_loss: 0.1376 - val_mae: 0.1376\n",
      "Epoch 1303/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1556 - mae: 0.1556 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 1304/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1538 - mae: 0.1538 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 1305/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1475 - mae: 0.1475 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1306/10000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1668 - mae: 0.1668 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 1307/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 1308/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1532 - mae: 0.1532 - val_loss: 0.1405 - val_mae: 0.1405\n",
      "Epoch 1309/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1530 - mae: 0.1530 - val_loss: 0.1323 - val_mae: 0.1323\n",
      "Epoch 1310/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1534 - mae: 0.1534 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 1311/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1537 - mae: 0.1537 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 1312/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1490 - mae: 0.1490 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 1313/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1536 - mae: 0.1536 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 1314/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1487 - mae: 0.1487 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 1315/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1671 - mae: 0.1671 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 1316/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1587 - mae: 0.1587 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1317/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1483 - mae: 0.1483 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 1318/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 1319/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1494 - mae: 0.1494 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 1320/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1545 - mae: 0.1545 - val_loss: 0.1317 - val_mae: 0.1317\n",
      "Epoch 1321/10000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1494 - mae: 0.1494 - val_loss: 0.1360 - val_mae: 0.1360\n",
      "Epoch 1322/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1533 - mae: 0.1533 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 1323/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1554 - mae: 0.1554 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 1324/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1491 - mae: 0.1491 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 1325/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.1338 - val_mae: 0.1338\n",
      "Epoch 1326/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1488 - mae: 0.1488 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 1327/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1503 - mae: 0.1503 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1328/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1513 - mae: 0.1513 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 1329/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1487 - mae: 0.1487 - val_loss: 0.1350 - val_mae: 0.1350\n",
      "Epoch 1330/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 1331/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1473 - mae: 0.1473 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 1332/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1508 - mae: 0.1508 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 1333/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1500 - mae: 0.1500 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 1334/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1474 - mae: 0.1474 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 1335/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1472 - mae: 0.1472 - val_loss: 0.1334 - val_mae: 0.1334\n",
      "Epoch 1336/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1477 - mae: 0.1477 - val_loss: 0.1344 - val_mae: 0.1344\n",
      "Epoch 1337/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1466 - mae: 0.1466 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 1338/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1518 - mae: 0.1518 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 1339/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1464 - mae: 0.1464 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 1340/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1470 - mae: 0.1470 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 1341/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1493 - mae: 0.1493 - val_loss: 0.1350 - val_mae: 0.1350\n",
      "Epoch 1342/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1483 - mae: 0.1483 - val_loss: 0.1442 - val_mae: 0.1442\n",
      "Epoch 1343/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1550 - mae: 0.1550 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 1344/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1490 - mae: 0.1490 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 1345/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1476 - mae: 0.1476 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 1346/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1501 - mae: 0.1501 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1347/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1348/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1464 - mae: 0.1464 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 1349/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1470 - mae: 0.1470 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 1350/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1481 - mae: 0.1481 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 1351/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1564 - mae: 0.1564 - val_loss: 0.1525 - val_mae: 0.1525\n",
      "Epoch 1352/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1553 - mae: 0.1553 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 1353/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1473 - mae: 0.1473 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 1354/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1502 - mae: 0.1502 - val_loss: 0.1376 - val_mae: 0.1376\n",
      "Epoch 1355/10000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 1356/10000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1511 - mae: 0.1511 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 1357/10000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1504 - mae: 0.1504 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 1358/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1452 - mae: 0.1452 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 1359/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.1333 - val_mae: 0.1333\n",
      "Epoch 1360/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.1334 - val_mae: 0.1334\n",
      "Epoch 1361/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1448 - mae: 0.1448 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 1362/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1448 - mae: 0.1448 - val_loss: 0.1326 - val_mae: 0.1326\n",
      "Epoch 1363/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1445 - mae: 0.1445 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 1364/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1447 - mae: 0.1447 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 1365/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1459 - mae: 0.1459 - val_loss: 0.1392 - val_mae: 0.1392\n",
      "Epoch 1366/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1490 - mae: 0.1490 - val_loss: 0.1401 - val_mae: 0.1401\n",
      "Epoch 1367/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1479 - mae: 0.1479 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 1368/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1470 - mae: 0.1470 - val_loss: 0.1389 - val_mae: 0.1389\n",
      "Epoch 1369/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1503 - mae: 0.1503 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 1370/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1443 - mae: 0.1443 - val_loss: 0.1393 - val_mae: 0.1393\n",
      "Epoch 1371/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1507 - mae: 0.1507 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 1372/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 1373/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1469 - mae: 0.1469 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 1374/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1450 - mae: 0.1450 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 1375/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1475 - mae: 0.1475 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 1376/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1429 - mae: 0.1429 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 1377/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1437 - mae: 0.1437 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 1378/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1515 - mae: 0.1515 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 1379/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1440 - mae: 0.1440 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 1380/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1573 - mae: 0.1573 - val_loss: 0.1455 - val_mae: 0.1455\n",
      "Epoch 1381/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1556 - mae: 0.1556 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 1382/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1529 - mae: 0.1529 - val_loss: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1383/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1384/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1464 - mae: 0.1464 - val_loss: 0.1362 - val_mae: 0.1362\n",
      "Epoch 1385/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1458 - mae: 0.1458 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 1386/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1441 - mae: 0.1441 - val_loss: 0.1415 - val_mae: 0.1415\n",
      "Epoch 1387/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1433 - mae: 0.1433 - val_loss: 0.1350 - val_mae: 0.1350\n",
      "Epoch 1388/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1425 - mae: 0.1425 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 1389/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1472 - mae: 0.1472 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 1390/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1458 - mae: 0.1458 - val_loss: 0.1523 - val_mae: 0.1523\n",
      "Epoch 1391/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1555 - mae: 0.1555 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 1392/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1447 - mae: 0.1447 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 1393/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1522 - mae: 0.1522 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 1394/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 1395/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1453 - mae: 0.1453 - val_loss: 0.1598 - val_mae: 0.1598\n",
      "Epoch 1396/10000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1589 - mae: 0.1589 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 1397/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1471 - val_mae: 0.1471\n",
      "Epoch 1398/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1674 - mae: 0.1674 - val_loss: 0.1405 - val_mae: 0.1405\n",
      "Epoch 1399/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1519 - mae: 0.1519 - val_loss: 0.1481 - val_mae: 0.1481\n",
      "Epoch 1400/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1513 - mae: 0.1513 - val_loss: 0.1459 - val_mae: 0.1459\n",
      "Epoch 1401/10000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1469 - mae: 0.1469 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 1402/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1449 - mae: 0.1449 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 1403/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.1419 - val_mae: 0.1419\n",
      "Epoch 1404/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 1405/10000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1470 - mae: 0.1470 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1406/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1423 - mae: 0.1423 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 1407/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1430 - mae: 0.1430 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 1408/10000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.1384 - val_mae: 0.1384\n",
      "Epoch 1409/10000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1452 - mae: 0.1452 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 1410/10000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1437 - mae: 0.1437 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1411/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1417 - mae: 0.1417 - val_loss: 0.1362 - val_mae: 0.1362\n",
      "Epoch 1412/10000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1437 - mae: 0.1437 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1413/10000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1425 - mae: 0.1425 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 1414/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1415/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1416/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 1417/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1390 - mae: 0.1390 - val_loss: 0.1453 - val_mae: 0.1453\n",
      "Epoch 1418/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1474 - mae: 0.1474 - val_loss: 0.1495 - val_mae: 0.1495\n",
      "Epoch 1419/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1509 - mae: 0.1509 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 1420/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1422 - mae: 0.1422 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 1421/10000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1414 - mae: 0.1414 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1422/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 1423/10000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 1424/10000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 1425/10000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1470 - mae: 0.1470 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 1426/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1444 - mae: 0.1444 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 1427/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1448 - mae: 0.1448 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 1428/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1407 - mae: 0.1407 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 1429/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1462 - mae: 0.1462 - val_loss: 0.1496 - val_mae: 0.1496\n",
      "Epoch 1430/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1452 - mae: 0.1452 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 1431/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1444 - mae: 0.1444 - val_loss: 0.1472 - val_mae: 0.1472\n",
      "Epoch 1432/10000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1592 - mae: 0.1592 - val_loss: 0.1386 - val_mae: 0.1386\n",
      "Epoch 1433/10000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1412 - mae: 0.1412 - val_loss: 0.1510 - val_mae: 0.1510\n",
      "Epoch 1434/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1504 - mae: 0.1504 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1435/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1438 - mae: 0.1438 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 1436/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 1437/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1494 - mae: 0.1494 - val_loss: 0.1403 - val_mae: 0.1403\n",
      "Epoch 1438/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 1439/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1429 - mae: 0.1429 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 1440/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1414 - mae: 0.1414 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 1441/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.1376 - val_mae: 0.1376\n",
      "Epoch 1442/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1417 - mae: 0.1417 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 1443/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.1431 - val_mae: 0.1431\n",
      "Epoch 1444/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 1445/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1418 - mae: 0.1418 - val_loss: 0.1351 - val_mae: 0.1351\n",
      "Epoch 1446/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1420 - mae: 0.1420 - val_loss: 0.1393 - val_mae: 0.1393\n",
      "Epoch 1447/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.1403 - val_mae: 0.1403\n",
      "Epoch 1448/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 1449/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1420 - mae: 0.1420 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 1450/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1436 - mae: 0.1436 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 1451/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1393 - mae: 0.1393 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 1452/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1453/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1381 - mae: 0.1381 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 1454/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1474 - mae: 0.1474 - val_loss: 0.1417 - val_mae: 0.1417\n",
      "Epoch 1455/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1470 - mae: 0.1470 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 1456/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1414 - mae: 0.1414 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 1457/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1393 - mae: 0.1393 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 1458/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1406 - mae: 0.1406 - val_loss: 0.1416 - val_mae: 0.1416\n",
      "Epoch 1459/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1380 - mae: 0.1380 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 1460/10000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1417 - mae: 0.1417 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 1461/10000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1415 - mae: 0.1415 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 1462/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1463/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 1464/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1433 - mae: 0.1433 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 1465/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1402 - mae: 0.1402 - val_loss: 0.1360 - val_mae: 0.1360\n",
      "Epoch 1466/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1450 - mae: 0.1450 - val_loss: 0.1354 - val_mae: 0.1354\n",
      "Epoch 1467/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1394 - mae: 0.1394 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 1468/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1574 - mae: 0.1574 - val_loss: 0.1557 - val_mae: 0.1557\n",
      "Epoch 1469/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1463 - mae: 0.1463 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 1470/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1437 - mae: 0.1437 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 1471/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1472/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1386 - mae: 0.1386 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 1473/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1377 - mae: 0.1377 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 1474/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1385 - mae: 0.1385 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 1475/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1376 - mae: 0.1376 - val_loss: 0.1446 - val_mae: 0.1446\n",
      "Epoch 1476/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1442 - mae: 0.1442 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 1477/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1478/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1376 - mae: 0.1376 - val_loss: 0.1405 - val_mae: 0.1405\n",
      "Epoch 1479/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1407 - mae: 0.1407 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1480/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1384 - mae: 0.1384 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 1481/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1420 - mae: 0.1420 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 1482/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1401 - mae: 0.1401 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 1483/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.1384 - val_mae: 0.1384\n",
      "Epoch 1484/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1368 - mae: 0.1368 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 1485/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1486/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1376 - mae: 0.1376 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 1487/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1368 - mae: 0.1368 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 1488/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1386 - mae: 0.1386 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 1489/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 1490/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 1491/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1406 - mae: 0.1406 - val_loss: 0.1472 - val_mae: 0.1472\n",
      "Epoch 1492/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1414 - mae: 0.1414 - val_loss: 0.1379 - val_mae: 0.1379\n",
      "Epoch 1493/10000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1387 - mae: 0.1387 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1494/10000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1378 - mae: 0.1378 - val_loss: 0.1446 - val_mae: 0.1446\n",
      "Epoch 1495/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1496/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.1395 - val_mae: 0.1395\n",
      "Epoch 1497/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1375 - mae: 0.1375 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 1498/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 1499/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 1500/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1484 - mae: 0.1484 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1501/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1356 - mae: 0.1356 - val_loss: 0.1422 - val_mae: 0.1422\n",
      "Epoch 1502/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1519 - mae: 0.1519 - val_loss: 0.1376 - val_mae: 0.1376\n",
      "Epoch 1503/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1420 - mae: 0.1420 - val_loss: 0.1491 - val_mae: 0.1491\n",
      "Epoch 1504/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1461 - mae: 0.1461 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 1505/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1390 - mae: 0.1390 - val_loss: 0.1351 - val_mae: 0.1351\n",
      "Epoch 1506/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1484 - mae: 0.1484 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 1507/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1446 - mae: 0.1446 - val_loss: 0.1439 - val_mae: 0.1439\n",
      "Epoch 1508/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1417 - mae: 0.1417 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 1509/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1412 - mae: 0.1412 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 1510/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1356 - mae: 0.1356 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 1511/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1394 - mae: 0.1394 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1512/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1383 - mae: 0.1383 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1513/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1363 - mae: 0.1363 - val_loss: 0.1393 - val_mae: 0.1393\n",
      "Epoch 1514/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1347 - mae: 0.1347 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 1515/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1361 - mae: 0.1361 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1516/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1357 - mae: 0.1357 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 1517/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1390 - mae: 0.1390 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1518/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 1519/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.1420 - val_mae: 0.1420\n",
      "Epoch 1520/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1376 - mae: 0.1376 - val_loss: 0.1482 - val_mae: 0.1482\n",
      "Epoch 1521/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1397 - mae: 0.1397 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1522/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1351 - mae: 0.1351 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 1523/10000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1355 - mae: 0.1355 - val_loss: 0.1417 - val_mae: 0.1417\n",
      "Epoch 1524/10000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 1525/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.1425 - val_mae: 0.1425\n",
      "Epoch 1526/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1361 - mae: 0.1361 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 1527/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1367 - mae: 0.1367 - val_loss: 0.1457 - val_mae: 0.1457\n",
      "Epoch 1528/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.1492 - val_mae: 0.1492\n",
      "Epoch 1529/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1392 - mae: 0.1392 - val_loss: 0.1400 - val_mae: 0.1400\n",
      "Epoch 1530/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1383 - mae: 0.1383 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 1531/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1378 - mae: 0.1378 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 1532/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1366 - mae: 0.1366 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 1533/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1356 - mae: 0.1356 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 1534/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1357 - mae: 0.1357 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 1535/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1345 - mae: 0.1345 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 1536/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1397 - mae: 0.1397 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 1537/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1351 - mae: 0.1351 - val_loss: 0.1470 - val_mae: 0.1470\n",
      "Epoch 1538/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1395 - mae: 0.1395 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1539/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1377 - mae: 0.1377 - val_loss: 0.1425 - val_mae: 0.1425\n",
      "Epoch 1540/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.1393 - val_mae: 0.1393\n",
      "Epoch 1541/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1380 - mae: 0.1380 - val_loss: 0.1437 - val_mae: 0.1437\n",
      "Epoch 1542/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1350 - mae: 0.1350 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 1543/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1449 - mae: 0.1449 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1544/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 1545/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1364 - mae: 0.1364 - val_loss: 0.1393 - val_mae: 0.1393\n",
      "Epoch 1546/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1547/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1360 - mae: 0.1360 - val_loss: 0.1365 - val_mae: 0.1365\n",
      "Epoch 1548/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1374 - mae: 0.1374 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 1549/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1352 - mae: 0.1352 - val_loss: 0.1470 - val_mae: 0.1470\n",
      "Epoch 1550/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1374 - mae: 0.1374 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 1551/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1336 - mae: 0.1336 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 1552/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1359 - mae: 0.1359 - val_loss: 0.1405 - val_mae: 0.1405\n",
      "Epoch 1553/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1359 - mae: 0.1359 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 1554/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1378 - mae: 0.1378 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 1555/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1350 - mae: 0.1350 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 1556/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1557/10000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.1475 - val_mae: 0.1475\n",
      "Epoch 1558/10000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1395 - mae: 0.1395 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1559/10000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1329 - mae: 0.1329 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 1560/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 1561/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1361 - mae: 0.1361 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1562/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1342 - mae: 0.1342 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 1563/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1346 - mae: 0.1346 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 1564/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1360 - mae: 0.1360 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 1565/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1336 - mae: 0.1336 - val_loss: 0.1503 - val_mae: 0.1503\n",
      "Epoch 1566/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1421 - mae: 0.1421 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 1567/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1329 - mae: 0.1329 - val_loss: 0.1408 - val_mae: 0.1408\n",
      "Epoch 1568/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1479 - mae: 0.1479 - val_loss: 0.1395 - val_mae: 0.1395\n",
      "Epoch 1569/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 1570/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1352 - mae: 0.1352 - val_loss: 0.1424 - val_mae: 0.1424\n",
      "Epoch 1571/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1342 - mae: 0.1342 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1572/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1333 - mae: 0.1333 - val_loss: 0.1441 - val_mae: 0.1441\n",
      "Epoch 1573/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1347 - mae: 0.1347 - val_loss: 0.1433 - val_mae: 0.1433\n",
      "Epoch 1574/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1318 - mae: 0.1318 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 1575/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1346 - mae: 0.1346 - val_loss: 0.1419 - val_mae: 0.1419\n",
      "Epoch 1576/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1337 - mae: 0.1337 - val_loss: 0.1472 - val_mae: 0.1472\n",
      "Epoch 1577/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1578/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1349 - mae: 0.1349 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 1579/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1398 - mae: 0.1398 - val_loss: 0.1379 - val_mae: 0.1379\n",
      "Epoch 1580/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1381 - mae: 0.1381 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 1581/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1346 - mae: 0.1346 - val_loss: 0.1433 - val_mae: 0.1433\n",
      "Epoch 1582/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1315 - mae: 0.1315 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 1583/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.1413 - val_mae: 0.1413\n",
      "Epoch 1584/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1336 - mae: 0.1336 - val_loss: 0.1477 - val_mae: 0.1477\n",
      "Epoch 1585/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1374 - mae: 0.1374 - val_loss: 0.1448 - val_mae: 0.1448\n",
      "Epoch 1586/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1326 - mae: 0.1326 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 1587/10000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1366 - mae: 0.1366 - val_loss: 0.1422 - val_mae: 0.1422\n",
      "Epoch 1588/10000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 1589/10000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1378 - mae: 0.1378 - val_loss: 0.1474 - val_mae: 0.1474\n",
      "Epoch 1590/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 1591/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1375 - mae: 0.1375 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 1592/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1364 - mae: 0.1364 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 1593/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 1594/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1340 - mae: 0.1340 - val_loss: 0.1435 - val_mae: 0.1435\n",
      "Epoch 1595/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1325 - mae: 0.1325 - val_loss: 0.1430 - val_mae: 0.1430\n",
      "Epoch 1596/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1339 - mae: 0.1339 - val_loss: 0.1417 - val_mae: 0.1417\n",
      "Epoch 1597/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1328 - mae: 0.1328 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 1598/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1332 - mae: 0.1332 - val_loss: 0.1434 - val_mae: 0.1434\n",
      "Epoch 1599/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1312 - mae: 0.1312 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 1600/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1335 - mae: 0.1335 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 1601/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1348 - mae: 0.1348 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 1602/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1368 - mae: 0.1368 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1603/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1373 - mae: 0.1373 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 1604/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1515 - mae: 0.1515 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 1605/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1347 - mae: 0.1347 - val_loss: 0.1551 - val_mae: 0.1551\n",
      "Epoch 1606/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1418 - mae: 0.1418 - val_loss: 0.1455 - val_mae: 0.1455\n",
      "Epoch 1607/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1308 - mae: 0.1308 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1608/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1426 - mae: 0.1426 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1609/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1306 - mae: 0.1306 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 1610/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1463 - mae: 0.1463 - val_loss: 0.1652 - val_mae: 0.1652\n",
      "Epoch 1611/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1511 - mae: 0.1511 - val_loss: 0.1442 - val_mae: 0.1442\n",
      "Epoch 1612/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1328 - mae: 0.1328 - val_loss: 0.1453 - val_mae: 0.1453\n",
      "Epoch 1613/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1521 - mae: 0.1521 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 1614/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1387 - mae: 0.1387 - val_loss: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1615/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1510 - mae: 0.1510 - val_loss: 0.1503 - val_mae: 0.1503\n",
      "Epoch 1616/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1398 - mae: 0.1398 - val_loss: 0.1425 - val_mae: 0.1425\n",
      "Epoch 1617/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 1618/10000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.1603 - val_mae: 0.1603\n",
      "Epoch 1619/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1519 - mae: 0.1519 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 1620/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1355 - mae: 0.1355 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 1621/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1533 - mae: 0.1533 - val_loss: 0.1457 - val_mae: 0.1457\n",
      "Epoch 1622/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1489 - mae: 0.1489 - val_loss: 0.1442 - val_mae: 0.1442\n",
      "Epoch 1623/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1340 - mae: 0.1340 - val_loss: 0.1663 - val_mae: 0.1663\n",
      "Epoch 1624/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1552 - mae: 0.1552 - val_loss: 0.1516 - val_mae: 0.1516\n",
      "Epoch 1625/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1354 - mae: 0.1354 - val_loss: 0.1379 - val_mae: 0.1379\n",
      "Epoch 1626/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1382 - mae: 0.1382 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1627/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.1476 - val_mae: 0.1476\n",
      "Epoch 1628/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1354 - mae: 0.1354 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 1629/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 1630/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1357 - mae: 0.1357 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 1631/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1318 - mae: 0.1318 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 1632/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.1427 - val_mae: 0.1427\n",
      "Epoch 1633/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1354 - mae: 0.1354 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 1634/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1354 - mae: 0.1354 - val_loss: 0.1424 - val_mae: 0.1424\n",
      "Epoch 1635/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1636/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 1637/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 1638/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1340 - mae: 0.1340 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 1639/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1374 - mae: 0.1374 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 1640/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1315 - mae: 0.1315 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 1641/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1325 - mae: 0.1325 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 1642/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1303 - mae: 0.1303 - val_loss: 0.1428 - val_mae: 0.1428\n",
      "Epoch 1643/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1310 - mae: 0.1310 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 1644/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1317 - mae: 0.1317 - val_loss: 0.1419 - val_mae: 0.1419\n",
      "Epoch 1645/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1300 - mae: 0.1300 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 1646/10000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1324 - mae: 0.1324 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1647/10000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1305 - mae: 0.1305 - val_loss: 0.1439 - val_mae: 0.1439\n",
      "Epoch 1648/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1298 - mae: 0.1298 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1649/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1325 - mae: 0.1325 - val_loss: 0.1413 - val_mae: 0.1413\n",
      "Epoch 1650/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1339 - mae: 0.1339 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 1651/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1320 - mae: 0.1320 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 1652/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1311 - mae: 0.1311 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 1653/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1298 - mae: 0.1298 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 1654/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1285 - mae: 0.1285 - val_loss: 0.1484 - val_mae: 0.1484\n",
      "Epoch 1655/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1338 - mae: 0.1338 - val_loss: 0.1478 - val_mae: 0.1478\n",
      "Epoch 1656/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1338 - mae: 0.1338 - val_loss: 0.1418 - val_mae: 0.1418\n",
      "Epoch 1657/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1327 - mae: 0.1327 - val_loss: 0.1452 - val_mae: 0.1452\n",
      "Epoch 1658/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1309 - mae: 0.1309 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 1659/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1308 - mae: 0.1308 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 1660/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1303 - mae: 0.1303 - val_loss: 0.1467 - val_mae: 0.1467\n",
      "Epoch 1661/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1313 - mae: 0.1313 - val_loss: 0.1483 - val_mae: 0.1483\n",
      "Epoch 1662/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1311 - mae: 0.1311 - val_loss: 0.1437 - val_mae: 0.1437\n",
      "Epoch 1663/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.1418 - val_mae: 0.1418\n",
      "Epoch 1664/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1292 - mae: 0.1292 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 1665/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.1474 - val_mae: 0.1474\n",
      "Epoch 1666/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1301 - mae: 0.1301 - val_loss: 0.1424 - val_mae: 0.1424\n",
      "Epoch 1667/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1327 - mae: 0.1327 - val_loss: 0.1448 - val_mae: 0.1448\n",
      "Epoch 1668/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1285 - mae: 0.1285 - val_loss: 0.1552 - val_mae: 0.1552\n",
      "Epoch 1669/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1389 - mae: 0.1389 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 1670/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1332 - mae: 0.1332 - val_loss: 0.1430 - val_mae: 0.1430\n",
      "Epoch 1671/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1371 - mae: 0.1371 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 1672/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1365 - mae: 0.1365 - val_loss: 0.1459 - val_mae: 0.1459\n",
      "Epoch 1673/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.1642 - val_mae: 0.1642\n",
      "Epoch 1674/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1466 - mae: 0.1466 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1675/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1311 - mae: 0.1311 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 1676/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1528 - mae: 0.1528 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 1677/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1354 - mae: 0.1354 - val_loss: 0.1544 - val_mae: 0.1544\n",
      "Epoch 1678/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1473 - mae: 0.1473 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 1679/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1373 - mae: 0.1373 - val_loss: 0.1431 - val_mae: 0.1431\n",
      "Epoch 1680/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1317 - mae: 0.1317 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 1681/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1327 - mae: 0.1327 - val_loss: 0.1452 - val_mae: 0.1452\n",
      "Epoch 1682/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1308 - mae: 0.1308 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 1683/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1301 - mae: 0.1301 - val_loss: 0.1418 - val_mae: 0.1418\n",
      "Epoch 1684/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.1389 - val_mae: 0.1389\n",
      "Epoch 1685/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1358 - mae: 0.1358 - val_loss: 0.1438 - val_mae: 0.1438\n",
      "Epoch 1686/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1284 - mae: 0.1284 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 1687/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1308 - mae: 0.1308 - val_loss: 0.1446 - val_mae: 0.1446\n",
      "Epoch 1688/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1331 - mae: 0.1331 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 1689/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1317 - mae: 0.1317 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 1690/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1281 - mae: 0.1281 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 1691/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1283 - mae: 0.1283 - val_loss: 0.1450 - val_mae: 0.1450\n",
      "Epoch 1692/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 1693/10000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1277 - mae: 0.1277 - val_loss: 0.1442 - val_mae: 0.1442\n",
      "Epoch 1694/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1292 - mae: 0.1292 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 1695/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1274 - mae: 0.1274 - val_loss: 0.1496 - val_mae: 0.1496\n",
      "Epoch 1696/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1305 - mae: 0.1305 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 1697/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1275 - mae: 0.1275 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 1698/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1294 - mae: 0.1294 - val_loss: 0.1439 - val_mae: 0.1439\n",
      "Epoch 1699/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1286 - mae: 0.1286 - val_loss: 0.1477 - val_mae: 0.1477\n",
      "Epoch 1700/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1280 - mae: 0.1280 - val_loss: 0.1456 - val_mae: 0.1456\n",
      "Epoch 1701/10000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1272 - mae: 0.1272 - val_loss: 0.1448 - val_mae: 0.1448\n",
      "Epoch 1702/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1271 - mae: 0.1271 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1703/10000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 1704/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1327 - mae: 0.1327 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 1705/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1274 - mae: 0.1274 - val_loss: 0.1442 - val_mae: 0.1442\n",
      "Epoch 1706/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1279 - mae: 0.1279 - val_loss: 0.1503 - val_mae: 0.1503\n",
      "Epoch 1707/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1309 - mae: 0.1309 - val_loss: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1708/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1376 - mae: 0.1376 - val_loss: 0.1474 - val_mae: 0.1474\n",
      "Epoch 1709/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1280 - mae: 0.1280 - val_loss: 0.1428 - val_mae: 0.1428\n",
      "Epoch 1710/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1338 - mae: 0.1338 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 1711/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1285 - mae: 0.1285 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1712/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1286 - mae: 0.1286 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1713/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1261 - mae: 0.1261 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 1714/10000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1333 - mae: 0.1333 - val_loss: 0.1415 - val_mae: 0.1415\n",
      "Epoch 1715/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.1477 - val_mae: 0.1477\n",
      "Epoch 1716/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1283 - mae: 0.1283 - val_loss: 0.1483 - val_mae: 0.1483\n",
      "Epoch 1717/10000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.1453 - val_mae: 0.1453\n",
      "Epoch 1718/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 1719/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1270 - mae: 0.1270 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 1720/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1277 - mae: 0.1277 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 1721/10000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.1441 - val_mae: 0.1441\n",
      "Epoch 1722/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.1472 - val_mae: 0.1472\n",
      "Epoch 1723/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1288 - mae: 0.1288 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 1724/10000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1298 - mae: 0.1298 - val_loss: 0.1412 - val_mae: 0.1412\n",
      "Epoch 1725/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1345 - mae: 0.1345 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 1726/10000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.1601 - val_mae: 0.1601\n",
      "Epoch 1727/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1440 - mae: 0.1440 - val_loss: 0.1670 - val_mae: 0.1670\n",
      "Epoch 1728/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1454 - mae: 0.1454 - val_loss: 0.1498 - val_mae: 0.1498\n",
      "Epoch 1729/10000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1276 - mae: 0.1276 - val_loss: 0.1440 - val_mae: 0.1440\n",
      "Epoch 1730/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1304 - mae: 0.1304 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 1731/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1272 - mae: 0.1272 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 1732/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1261 - mae: 0.1261 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 1733/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1299 - mae: 0.1299 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 1734/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.1524 - val_mae: 0.1524\n",
      "Epoch 1735/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1309 - mae: 0.1309 - val_loss: 0.1513 - val_mae: 0.1513\n",
      "Epoch 1736/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1294 - mae: 0.1294 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 1737/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.1492 - val_mae: 0.1492\n",
      "Epoch 1738/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 1739/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1288 - mae: 0.1288 - val_loss: 0.1452 - val_mae: 0.1452\n",
      "Epoch 1740/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1287 - mae: 0.1287 - val_loss: 0.1496 - val_mae: 0.1496\n",
      "Epoch 1741/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1296 - mae: 0.1296 - val_loss: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1742/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1352 - mae: 0.1352 - val_loss: 0.1491 - val_mae: 0.1491\n",
      "Epoch 1743/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1279 - mae: 0.1279 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 1744/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1320 - mae: 0.1320 - val_loss: 0.1489 - val_mae: 0.1489\n",
      "Epoch 1745/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1258 - mae: 0.1258 - val_loss: 0.1553 - val_mae: 0.1553\n",
      "Epoch 1746/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1315 - mae: 0.1315 - val_loss: 0.1514 - val_mae: 0.1514\n",
      "Epoch 1747/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1238 - mae: 0.1238 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 1748/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1363 - mae: 0.1363 - val_loss: 0.1447 - val_mae: 0.1447\n",
      "Epoch 1749/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1345 - mae: 0.1345 - val_loss: 0.1515 - val_mae: 0.1515\n",
      "Epoch 1750/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1253 - mae: 0.1253 - val_loss: 0.1555 - val_mae: 0.1555\n",
      "Epoch 1751/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1326 - mae: 0.1326 - val_loss: 0.1540 - val_mae: 0.1540\n",
      "Epoch 1752/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1279 - mae: 0.1279 - val_loss: 0.1484 - val_mae: 0.1484\n",
      "Epoch 1753/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.1457 - val_mae: 0.1457\n",
      "Epoch 1754/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1333 - mae: 0.1333 - val_loss: 0.1499 - val_mae: 0.1499\n",
      "Epoch 1755/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1257 - mae: 0.1257 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 1756/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1276 - mae: 0.1276 - val_loss: 0.1508 - val_mae: 0.1508\n",
      "Epoch 1757/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 1758/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1277 - mae: 0.1277 - val_loss: 0.1534 - val_mae: 0.1534\n",
      "Epoch 1759/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.1495 - val_mae: 0.1495\n",
      "Epoch 1760/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1277 - mae: 0.1277 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 1761/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1321 - mae: 0.1321 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 1762/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1276 - mae: 0.1276 - val_loss: 0.1553 - val_mae: 0.1553\n",
      "Epoch 1763/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1302 - mae: 0.1302 - val_loss: 0.1516 - val_mae: 0.1516\n",
      "Epoch 1764/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1253 - mae: 0.1253 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 1765/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.1478 - val_mae: 0.1478\n",
      "Epoch 1766/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1290 - mae: 0.1290 - val_loss: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1767/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1332 - mae: 0.1332 - val_loss: 0.1507 - val_mae: 0.1507\n",
      "Epoch 1768/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1308 - mae: 0.1308 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 1769/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1332 - mae: 0.1332 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 1770/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 1771/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1281 - mae: 0.1281 - val_loss: 0.1542 - val_mae: 0.1542\n",
      "Epoch 1772/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.1494 - val_mae: 0.1494\n",
      "Epoch 1773/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1774/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 1775/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1282 - mae: 0.1282 - val_loss: 0.1549 - val_mae: 0.1549\n",
      "Epoch 1776/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1300 - mae: 0.1300 - val_loss: 0.1525 - val_mae: 0.1525\n",
      "Epoch 1777/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.1494 - val_mae: 0.1494\n",
      "Epoch 1778/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1237 - mae: 0.1237 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 1779/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1272 - mae: 0.1272 - val_loss: 0.1523 - val_mae: 0.1523\n",
      "Epoch 1780/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.1483 - val_mae: 0.1483\n",
      "Epoch 1781/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1260 - mae: 0.1260 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 1782/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1250 - mae: 0.1250 - val_loss: 0.1511 - val_mae: 0.1511\n",
      "Epoch 1783/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.1513 - val_mae: 0.1513\n",
      "Epoch 1784/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 1785/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1247 - mae: 0.1247 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 1786/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1285 - mae: 0.1285 - val_loss: 0.1511 - val_mae: 0.1511\n",
      "Epoch 1787/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1284 - mae: 0.1284 - val_loss: 0.1607 - val_mae: 0.1607\n",
      "Epoch 1788/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 1789/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 1790/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1290 - mae: 0.1290 - val_loss: 0.1513 - val_mae: 0.1513\n",
      "Epoch 1791/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 1792/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1260 - mae: 0.1260 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1793/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1269 - mae: 0.1269 - val_loss: 0.1518 - val_mae: 0.1518\n",
      "Epoch 1794/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1245 - mae: 0.1245 - val_loss: 0.1481 - val_mae: 0.1481\n",
      "Epoch 1795/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1262 - mae: 0.1262 - val_loss: 0.1455 - val_mae: 0.1455\n",
      "Epoch 1796/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1307 - mae: 0.1307 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 1797/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 1798/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 1799/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1261 - mae: 0.1261 - val_loss: 0.1489 - val_mae: 0.1489\n",
      "Epoch 1800/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1239 - mae: 0.1239 - val_loss: 0.1489 - val_mae: 0.1489\n",
      "Epoch 1801/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.1471 - val_mae: 0.1471\n",
      "Epoch 1802/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1238 - mae: 0.1238 - val_loss: 0.1500 - val_mae: 0.1500\n",
      "Epoch 1803/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1248 - mae: 0.1248 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 1804/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1224 - mae: 0.1224 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 1805/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.1488 - val_mae: 0.1488\n",
      "Epoch 1806/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1230 - mae: 0.1230 - val_loss: 0.1508 - val_mae: 0.1508\n",
      "Epoch 1807/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 1808/10000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1290 - mae: 0.1290 - val_loss: 0.1458 - val_mae: 0.1458\n",
      "Epoch 1809/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 1810/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1300 - mae: 0.1300 - val_loss: 0.1504 - val_mae: 0.1504\n",
      "Epoch 1811/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1262 - mae: 0.1262 - val_loss: 0.1435 - val_mae: 0.1435\n",
      "Epoch 1812/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1292 - mae: 0.1292 - val_loss: 0.1522 - val_mae: 0.1522\n",
      "Epoch 1813/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.1693 - val_mae: 0.1693\n",
      "Epoch 1814/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.1515 - val_mae: 0.1515\n",
      "Epoch 1815/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1290 - mae: 0.1290 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 1816/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1289 - mae: 0.1289 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 1817/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 1818/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 1819/10000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1255 - mae: 0.1255 - val_loss: 0.1496 - val_mae: 0.1496\n",
      "Epoch 1820/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1234 - mae: 0.1234 - val_loss: 0.1514 - val_mae: 0.1514\n",
      "Epoch 1821/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.1499 - val_mae: 0.1499\n",
      "Epoch 1822/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1234 - mae: 0.1234 - val_loss: 0.1507 - val_mae: 0.1507\n",
      "Epoch 1823/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1249 - mae: 0.1249 - val_loss: 0.1518 - val_mae: 0.1518\n",
      "Epoch 1824/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 1825/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1226 - mae: 0.1226 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 1826/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.1521 - val_mae: 0.1521\n",
      "Epoch 1827/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1263 - mae: 0.1263 - val_loss: 0.1469 - val_mae: 0.1469\n",
      "Epoch 1828/10000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 1829/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1294 - mae: 0.1294 - val_loss: 0.1574 - val_mae: 0.1574\n",
      "Epoch 1830/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1287 - mae: 0.1287 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1831/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1242 - mae: 0.1242 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 1832/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 1833/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1230 - mae: 0.1230 - val_loss: 0.1505 - val_mae: 0.1505\n",
      "Epoch 1834/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1224 - mae: 0.1224 - val_loss: 0.1503 - val_mae: 0.1503\n",
      "Epoch 1835/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1212 - mae: 0.1212 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1836/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1234 - mae: 0.1234 - val_loss: 0.1512 - val_mae: 0.1512\n",
      "Epoch 1837/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.1549 - val_mae: 0.1549\n",
      "Epoch 1838/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1282 - mae: 0.1282 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 1839/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1255 - mae: 0.1255 - val_loss: 0.1495 - val_mae: 0.1495\n",
      "Epoch 1840/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1231 - mae: 0.1231 - val_loss: 0.1499 - val_mae: 0.1499\n",
      "Epoch 1841/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 1842/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1231 - mae: 0.1231 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 1843/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1223 - mae: 0.1223 - val_loss: 0.1500 - val_mae: 0.1500\n",
      "Epoch 1844/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1227 - mae: 0.1227 - val_loss: 0.1495 - val_mae: 0.1495\n",
      "Epoch 1845/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1229 - mae: 0.1229 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 1846/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 1847/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1215 - mae: 0.1215 - val_loss: 0.1510 - val_mae: 0.1510\n",
      "Epoch 1848/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 1849/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 1850/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1212 - mae: 0.1212 - val_loss: 0.1499 - val_mae: 0.1499\n",
      "Epoch 1851/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.1512 - val_mae: 0.1512\n",
      "Epoch 1852/10000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.1518 - val_mae: 0.1518\n",
      "Epoch 1853/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1213 - mae: 0.1213 - val_loss: 0.1504 - val_mae: 0.1504\n",
      "Epoch 1854/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1242 - mae: 0.1242 - val_loss: 0.1507 - val_mae: 0.1507\n",
      "Epoch 1855/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1204 - mae: 0.1204 - val_loss: 0.1546 - val_mae: 0.1546\n",
      "Epoch 1856/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 1857/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1263 - mae: 0.1263 - val_loss: 0.1495 - val_mae: 0.1495\n",
      "Epoch 1858/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1229 - mae: 0.1229 - val_loss: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1859/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1311 - mae: 0.1311 - val_loss: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1860/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.1513 - val_mae: 0.1513\n",
      "Epoch 1861/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1223 - mae: 0.1223 - val_loss: 0.1480 - val_mae: 0.1480\n",
      "Epoch 1862/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1306 - mae: 0.1306 - val_loss: 0.1477 - val_mae: 0.1477\n",
      "Epoch 1863/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1276 - mae: 0.1276 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 1864/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1247 - mae: 0.1247 - val_loss: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1865/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1279 - mae: 0.1279 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 1866/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.1494 - val_mae: 0.1494\n",
      "Epoch 1867/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1234 - mae: 0.1234 - val_loss: 0.1550 - val_mae: 0.1550\n",
      "Epoch 1868/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 1869/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 1870/10000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1307 - mae: 0.1307 - val_loss: 0.1514 - val_mae: 0.1514\n",
      "Epoch 1871/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1257 - mae: 0.1257 - val_loss: 0.1575 - val_mae: 0.1575\n",
      "Epoch 1872/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1261 - mae: 0.1261 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 1873/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.1507 - val_mae: 0.1507\n",
      "Epoch 1874/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1226 - mae: 0.1226 - val_loss: 0.1562 - val_mae: 0.1562\n",
      "Epoch 1875/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.1555 - val_mae: 0.1555\n",
      "Epoch 1876/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.1515 - val_mae: 0.1515\n",
      "Epoch 1877/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.1510 - val_mae: 0.1510\n",
      "Epoch 1878/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1227 - mae: 0.1227 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 1879/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1224 - mae: 0.1224 - val_loss: 0.1501 - val_mae: 0.1501\n",
      "Epoch 1880/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1230 - mae: 0.1230 - val_loss: 0.1518 - val_mae: 0.1518\n",
      "Epoch 1881/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1203 - mae: 0.1203 - val_loss: 0.1545 - val_mae: 0.1545\n",
      "Epoch 1882/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.1539 - val_mae: 0.1539\n",
      "Epoch 1883/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1231 - mae: 0.1231 - val_loss: 0.1513 - val_mae: 0.1513\n",
      "Epoch 1884/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1209 - mae: 0.1209 - val_loss: 0.1544 - val_mae: 0.1544\n",
      "Epoch 1885/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.1525 - val_mae: 0.1525\n",
      "Epoch 1886/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 1887/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1207 - mae: 0.1207 - val_loss: 0.1570 - val_mae: 0.1570\n",
      "Epoch 1888/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1242 - mae: 0.1242 - val_loss: 0.1540 - val_mae: 0.1540\n",
      "Epoch 1889/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1230 - mae: 0.1230 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 1890/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.1525 - val_mae: 0.1525\n",
      "Epoch 1891/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1184 - mae: 0.1184 - val_loss: 0.1685 - val_mae: 0.1685\n",
      "Epoch 1892/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1390 - mae: 0.1390 - val_loss: 0.1706 - val_mae: 0.1706\n",
      "Epoch 1893/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1331 - mae: 0.1331 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 1894/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1270 - mae: 0.1270 - val_loss: 0.1519 - val_mae: 0.1519\n",
      "Epoch 1895/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1297 - mae: 0.1297 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 1896/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.1578 - val_mae: 0.1578\n",
      "Epoch 1897/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1248 - mae: 0.1248 - val_loss: 0.1567 - val_mae: 0.1567\n",
      "Epoch 1898/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 1899/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1233 - mae: 0.1233 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 1900/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1207 - mae: 0.1207 - val_loss: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1901/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1248 - mae: 0.1248 - val_loss: 0.1620 - val_mae: 0.1620\n",
      "Epoch 1902/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.1555 - val_mae: 0.1555\n",
      "Epoch 1903/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 1904/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.1611 - val_mae: 0.1611\n",
      "Epoch 1905/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.1595 - val_mae: 0.1595\n",
      "Epoch 1906/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1203 - mae: 0.1203 - val_loss: 0.1521 - val_mae: 0.1521\n",
      "Epoch 1907/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1283 - mae: 0.1283 - val_loss: 0.1512 - val_mae: 0.1512\n",
      "Epoch 1908/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1242 - mae: 0.1242 - val_loss: 0.1578 - val_mae: 0.1578\n",
      "Epoch 1909/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 1910/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1245 - mae: 0.1245 - val_loss: 0.1559 - val_mae: 0.1559\n",
      "Epoch 1911/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1193 - mae: 0.1193 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 1912/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.1573 - val_mae: 0.1573\n",
      "Epoch 1913/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1209 - mae: 0.1209 - val_loss: 0.1630 - val_mae: 0.1630\n",
      "Epoch 1914/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1309 - mae: 0.1309 - val_loss: 0.1571 - val_mae: 0.1571\n",
      "Epoch 1915/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1231 - mae: 0.1231 - val_loss: 0.1488 - val_mae: 0.1488\n",
      "Epoch 1916/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1382 - mae: 0.1382 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 1917/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.1672 - val_mae: 0.1672\n",
      "Epoch 1918/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1324 - mae: 0.1324 - val_loss: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1919/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1200 - mae: 0.1200 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 1920/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1294 - mae: 0.1294 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 1921/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1262 - mae: 0.1262 - val_loss: 0.1567 - val_mae: 0.1567\n",
      "Epoch 1922/10000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1206 - mae: 0.1206 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 1923/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 1924/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 1925/10000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1926/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1257 - mae: 0.1257 - val_loss: 0.1678 - val_mae: 0.1678\n",
      "Epoch 1927/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1267 - mae: 0.1267 - val_loss: 0.1523 - val_mae: 0.1523\n",
      "Epoch 1928/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1213 - mae: 0.1213 - val_loss: 0.1494 - val_mae: 0.1494\n",
      "Epoch 1929/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.1500 - val_mae: 0.1500\n",
      "Epoch 1930/10000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1217 - mae: 0.1217 - val_loss: 0.1637 - val_mae: 0.1637\n",
      "Epoch 1931/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1284 - mae: 0.1284 - val_loss: 0.1580 - val_mae: 0.1580\n",
      "Epoch 1932/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1208 - mae: 0.1208 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 1933/10000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.1508 - val_mae: 0.1508\n",
      "Epoch 1934/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1200 - mae: 0.1200 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 1935/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1276 - mae: 0.1276 - val_loss: 0.1623 - val_mae: 0.1623\n",
      "Epoch 1936/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1271 - mae: 0.1271 - val_loss: 0.1559 - val_mae: 0.1559\n",
      "Epoch 1937/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1208 - mae: 0.1208 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 1938/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1205 - mae: 0.1205 - val_loss: 0.1529 - val_mae: 0.1529\n",
      "Epoch 1939/10000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1199 - mae: 0.1199 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 1940/10000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1187 - mae: 0.1187 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 1941/10000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.1510 - val_mae: 0.1510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd263551bb0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(11, input_dim=(11), activation='relu'),\n",
    "    tf.keras.layers.Dense(11, activation='relu'),\n",
    "    # tf.keras.layers.LayerNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='mae', patience=50)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=10000, \n",
    "          validation_split=0.2, \n",
    "          callbacks=[tensorboard_callback, early_stopping_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2609 - mae: 0.2609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26093778014183044, 0.26093778014183044]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.645921],\n",
       "       [10.361409],\n",
       "       [10.100461],\n",
       "       [10.146962],\n",
       "       [10.74464 ],\n",
       "       [10.552723],\n",
       "       [10.37155 ],\n",
       "       [ 9.981534],\n",
       "       [10.323005],\n",
       "       [10.774028]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 7.8963953e-01 -5.6810373e-01  2.7756453e-01 -1.2067894e-01\n",
      "  3.7670076e-01 -4.0882826e-04  1.6521513e-03  1.8400429e-02\n",
      " -1.3131101e+00 -2.6454628e-03  1.0316370e+00]\n",
      "Mean absolute error: 0.13\n",
      "Coefficient of determination: 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "\n",
    "\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:season_time_best Mean absolute error: 0.0747532844543457\n",
      "col:season_time_top_3_avg Mean absolute error: 0.07520818710327148\n",
      "col:season_time_most_recent_3_avg Mean absolute error: 0.0693659782409668\n",
      "col:season_time_kfp Mean absolute error: 0.09777774661779404\n",
      "col:season_time_avg Mean absolute error: 0.08429326862096786\n",
      "col:season_score_best Mean absolute error: 0.08030281215906143\n",
      "col:season_score_avg Mean absolute error: 0.0800803154706955\n",
      "col:years_since_pb Mean absolute error: 0.11100683361291885\n",
      "col:all_time_time_best Mean absolute error: 0.09207334369421005\n",
      "col:all_time_score_best Mean absolute error: 0.10538091510534286\n",
      "col:all_time_time_top_3_avg Mean absolute error: 0.10703583061695099\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, shuffle=True)\n",
    "\n",
    "def compare_cols_with_regression(col):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X_train[col].values.reshape(-1, 1), y_train)\n",
    "    y_pred = regr.predict(X_test[col].values.reshape(-1, 1))\n",
    "    print(f\"col:{col} Mean absolute error: {mean_absolute_error(y_test, y_pred)}\")\n",
    "\n",
    "for col in X_train.columns:\n",
    "    compare_cols_with_regression(col=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_time_best</th>\n",
       "      <th>season_time_top_3_avg</th>\n",
       "      <th>season_time_most_recent_3_avg</th>\n",
       "      <th>season_time_kfp</th>\n",
       "      <th>season_time_avg</th>\n",
       "      <th>season_score_best</th>\n",
       "      <th>season_score_avg</th>\n",
       "      <th>years_since_pb</th>\n",
       "      <th>all_time_time_best</th>\n",
       "      <th>all_time_score_best</th>\n",
       "      <th>all_time_time_top_3_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.07</td>\n",
       "      <td>10.123333</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.175022</td>\n",
       "      <td>10.182500</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>1144.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>9.896667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10.21</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>10.336667</td>\n",
       "      <td>10.389869</td>\n",
       "      <td>10.399500</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1079.449951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.23</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>10.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>10.06</td>\n",
       "      <td>10.116667</td>\n",
       "      <td>10.356667</td>\n",
       "      <td>10.462999</td>\n",
       "      <td>10.357500</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1093.875000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>10.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10.07</td>\n",
       "      <td>10.116667</td>\n",
       "      <td>10.206667</td>\n",
       "      <td>10.240000</td>\n",
       "      <td>10.610769</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>1048.923096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.07</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>10.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.98</td>\n",
       "      <td>10.016666</td>\n",
       "      <td>10.146667</td>\n",
       "      <td>10.170000</td>\n",
       "      <td>10.135000</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1167.111084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.04</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>10.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10.20</td>\n",
       "      <td>10.223333</td>\n",
       "      <td>10.260000</td>\n",
       "      <td>10.449679</td>\n",
       "      <td>10.426316</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>1060.052612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.18</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>10.196667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10.17</td>\n",
       "      <td>10.246667</td>\n",
       "      <td>10.283334</td>\n",
       "      <td>10.338379</td>\n",
       "      <td>10.344000</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>1105.800049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.17</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>10.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.08</td>\n",
       "      <td>10.106667</td>\n",
       "      <td>10.153334</td>\n",
       "      <td>10.120488</td>\n",
       "      <td>10.206000</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>1145.666626</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.03</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>10.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.02</td>\n",
       "      <td>10.073334</td>\n",
       "      <td>10.263333</td>\n",
       "      <td>10.270000</td>\n",
       "      <td>10.267895</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>1120.789429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>10.113334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10.12</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>10.153334</td>\n",
       "      <td>10.169958</td>\n",
       "      <td>10.172857</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>10.086667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    season_time_best  season_time_top_3_avg  season_time_most_recent_3_avg  \\\n",
       "28             10.07              10.123333                      10.220000   \n",
       "80             10.21              10.230000                      10.336667   \n",
       "92             10.06              10.116667                      10.356667   \n",
       "79             10.07              10.116667                      10.206667   \n",
       "23              9.98              10.016666                      10.146667   \n",
       "..               ...                    ...                            ...   \n",
       "81             10.20              10.223333                      10.260000   \n",
       "89             10.17              10.246667                      10.283334   \n",
       "29             10.08              10.106667                      10.153334   \n",
       "25             10.02              10.073334                      10.263333   \n",
       "86             10.12              10.133333                      10.153334   \n",
       "\n",
       "    season_time_kfp  season_time_avg  season_score_best  season_score_avg  \\\n",
       "28        10.175022        10.182500             1189.0       1144.375000   \n",
       "80        10.389869        10.399500             1145.0       1079.449951   \n",
       "92        10.462999        10.357500             1208.0       1093.875000   \n",
       "79        10.240000        10.610769             1199.0       1048.923096   \n",
       "23        10.170000        10.135000             1213.0       1167.111084   \n",
       "..              ...              ...                ...               ...   \n",
       "81        10.449679        10.426316             1142.0       1060.052612   \n",
       "89        10.338379        10.344000             1165.0       1105.800049   \n",
       "29        10.120488        10.206000             1193.0       1145.666626   \n",
       "25        10.270000        10.267895             1182.0       1120.789429   \n",
       "86        10.169958        10.172857             1189.0       1163.000000   \n",
       "\n",
       "    years_since_pb  all_time_time_best  all_time_score_best  \\\n",
       "28             1.0                9.89               1245.0   \n",
       "80             0.0               10.23               1145.0   \n",
       "92             0.0               10.09               1161.0   \n",
       "79             0.0               10.07               1199.0   \n",
       "23             4.0               10.04               1210.0   \n",
       "..             ...                 ...                  ...   \n",
       "81             0.0               10.18               1148.0   \n",
       "89             0.0               10.17               1165.0   \n",
       "29             3.0               10.03               1220.0   \n",
       "25             0.0               10.09               1182.0   \n",
       "86             1.0               10.01               1227.0   \n",
       "\n",
       "    all_time_time_top_3_avg  \n",
       "28                 9.896667  \n",
       "80                10.230000  \n",
       "92                10.166667  \n",
       "79                10.130000  \n",
       "23                10.040000  \n",
       "..                      ...  \n",
       "81                10.196667  \n",
       "89                10.270000  \n",
       "29                10.083333  \n",
       "25                10.113334  \n",
       "86                10.086667  \n",
       "\n",
       "[90 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram:///tmp/tmp1g4ppgxm/assets\n",
      "INFO:tensorflow:Assets written to: ram:///tmp/tmpvq_89x9a/assets\n",
      "INFO:tensorflow:Assets written to: ram:///tmp/tmp8wuwqpzl/assets\n",
      "INFO:tensorflow:Assets written to: ram:///tmp/tmpdssu83g9/assets\n",
      "Baseline: -0.32 (0.14) MAE\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "estimator = KerasRegressor(model=model, epochs=1000, batch_size=1, verbose=0)\n",
    "kfold = KFold(n_splits=4)\n",
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "print(\"Baseline: %.2f (%.2f) MAE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5f1e750012fad527\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5f1e750012fad527\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_time_best</th>\n",
       "      <th>season_time_top_3_avg</th>\n",
       "      <th>season_time_most_recent_3_avg</th>\n",
       "      <th>season_time_kfp</th>\n",
       "      <th>season_time_avg</th>\n",
       "      <th>season_score_best</th>\n",
       "      <th>season_score_avg</th>\n",
       "      <th>years_since_pb</th>\n",
       "      <th>all_time_time_best</th>\n",
       "      <th>all_time_score_best</th>\n",
       "      <th>all_time_time_top_3_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.01</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>10.116667</td>\n",
       "      <td>10.142288</td>\n",
       "      <td>10.124118</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>1156.294067</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.04</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>10.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>10.16</td>\n",
       "      <td>10.190000</td>\n",
       "      <td>10.263333</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>10.344666</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>1103.333374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>10.186666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.87</td>\n",
       "      <td>9.896667</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>10.067639</td>\n",
       "      <td>10.061429</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>1181.428589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>9.896667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.07</td>\n",
       "      <td>10.123333</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.175022</td>\n",
       "      <td>10.182500</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>1144.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>9.896667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10.12</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>10.153334</td>\n",
       "      <td>10.169958</td>\n",
       "      <td>10.172857</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>10.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10.13</td>\n",
       "      <td>10.150000</td>\n",
       "      <td>10.196667</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.227143</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>1134.571411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.11</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>10.143333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10.03</td>\n",
       "      <td>10.090000</td>\n",
       "      <td>10.306666</td>\n",
       "      <td>10.325055</td>\n",
       "      <td>10.236667</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>1139.333374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.03</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>10.153334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10.05</td>\n",
       "      <td>10.070000</td>\n",
       "      <td>10.146667</td>\n",
       "      <td>10.130004</td>\n",
       "      <td>10.142500</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1165.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.05</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>10.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10.14</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>10.334027</td>\n",
       "      <td>10.305294</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.11</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>10.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10.06</td>\n",
       "      <td>10.106667</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>10.274760</td>\n",
       "      <td>10.256000</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>1122.533325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>10.113334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.96</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>10.036667</td>\n",
       "      <td>10.065068</td>\n",
       "      <td>10.032000</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>1159.800049</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>9.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10.01</td>\n",
       "      <td>10.086667</td>\n",
       "      <td>10.213333</td>\n",
       "      <td>10.344679</td>\n",
       "      <td>10.270400</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1116.280029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>10.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10.08</td>\n",
       "      <td>10.160000</td>\n",
       "      <td>10.363334</td>\n",
       "      <td>10.290000</td>\n",
       "      <td>10.321034</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>1099.344849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.08</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>10.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9.97</td>\n",
       "      <td>9.993333</td>\n",
       "      <td>10.203333</td>\n",
       "      <td>10.090199</td>\n",
       "      <td>10.115000</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>10.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.05</td>\n",
       "      <td>10.070000</td>\n",
       "      <td>10.170000</td>\n",
       "      <td>10.170000</td>\n",
       "      <td>10.207369</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>1139.736816</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>9.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.97</td>\n",
       "      <td>9.993333</td>\n",
       "      <td>10.036667</td>\n",
       "      <td>10.050000</td>\n",
       "      <td>10.081111</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>1181.666626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.97</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>10.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.93</td>\n",
       "      <td>9.936666</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>10.179561</td>\n",
       "      <td>10.084348</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>1180.391357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>9.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.11</td>\n",
       "      <td>10.123333</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>10.195103</td>\n",
       "      <td>10.195000</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>1139.199951</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.92</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>9.936666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.01</td>\n",
       "      <td>10.023334</td>\n",
       "      <td>10.140000</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>1163.846191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.03</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>10.063334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10.14</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>10.223333</td>\n",
       "      <td>10.303872</td>\n",
       "      <td>10.344211</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>1092.578979</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>10.090000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season_time_best  season_time_top_3_avg  season_time_most_recent_3_avg  \\\n",
       "9              10.01              10.020000                      10.116667   \n",
       "87             10.16              10.190000                      10.263333   \n",
       "6               9.87               9.896667                       9.920000   \n",
       "28             10.07              10.123333                      10.220000   \n",
       "86             10.12              10.133333                      10.153334   \n",
       "65             10.13              10.150000                      10.196667   \n",
       "45             10.03              10.090000                      10.306666   \n",
       "61             10.05              10.070000                      10.146667   \n",
       "78             10.14              10.166667                      10.200000   \n",
       "75             10.06              10.106667                      10.130000   \n",
       "14              9.96              10.010000                      10.036667   \n",
       "43             10.01              10.086667                      10.213333   \n",
       "83             10.08              10.160000                      10.363334   \n",
       "30              9.97               9.993333                      10.203333   \n",
       "20             10.05              10.070000                      10.170000   \n",
       "12              9.97               9.993333                      10.036667   \n",
       "8               9.93               9.936666                      10.130000   \n",
       "32             10.11              10.123333                      10.250000   \n",
       "19             10.01              10.023334                      10.140000   \n",
       "36             10.14              10.166667                      10.223333   \n",
       "\n",
       "    season_time_kfp  season_time_avg  season_score_best  season_score_avg  \\\n",
       "9         10.142288        10.124118             1221.0       1156.294067   \n",
       "87        10.200000        10.344666             1179.0       1103.333374   \n",
       "6         10.067639        10.061429             1255.0       1181.428589   \n",
       "28        10.175022        10.182500             1189.0       1144.375000   \n",
       "86        10.169958        10.172857             1189.0       1163.000000   \n",
       "65        10.220000        10.227143             1165.0       1134.571411   \n",
       "45        10.325055        10.236667             1197.0       1139.333374   \n",
       "61        10.130004        10.142500             1213.0       1165.000000   \n",
       "78        10.334027        10.305294             1176.0       1107.000000   \n",
       "75        10.274760        10.256000             1193.0       1122.533325   \n",
       "14        10.065068        10.032000             1218.0       1159.800049   \n",
       "43        10.344679        10.270400             1175.0       1116.280029   \n",
       "83        10.290000        10.321034             1196.0       1099.344849   \n",
       "30        10.090199        10.115000             1241.0       1177.000000   \n",
       "20        10.170000        10.207369             1199.0       1139.736816   \n",
       "12        10.050000        10.081111             1241.0       1181.666626   \n",
       "8         10.179561        10.084348             1259.0       1180.391357   \n",
       "32        10.195103        10.195000             1172.0       1139.199951   \n",
       "19        10.130000        10.130000             1220.0       1163.846191   \n",
       "36        10.303872        10.344211             1179.0       1092.578979   \n",
       "\n",
       "    years_since_pb  all_time_time_best  all_time_score_best  \\\n",
       "9              6.0               10.04               1220.0   \n",
       "87             0.0               10.16               1179.0   \n",
       "6              0.0                9.87               1255.0   \n",
       "28             1.0                9.89               1245.0   \n",
       "86             1.0               10.01               1227.0   \n",
       "65             1.0               10.11               1169.0   \n",
       "45             0.0               10.03               1196.0   \n",
       "61             0.0               10.05               1213.0   \n",
       "78             5.0               10.11               1182.0   \n",
       "75             0.0               10.06               1193.0   \n",
       "14             3.0                9.90               1255.0   \n",
       "43             1.0               10.09               1203.0   \n",
       "83             0.0               10.08               1196.0   \n",
       "30             0.0                9.98               1241.0   \n",
       "20             3.0               10.01               1231.0   \n",
       "12             0.0                9.97               1241.0   \n",
       "8              1.0                9.82               1287.0   \n",
       "32             7.0                9.92               1255.0   \n",
       "19             0.0               10.03               1220.0   \n",
       "36             7.0               10.01               1217.0   \n",
       "\n",
       "    all_time_time_top_3_avg  \n",
       "9                 10.053333  \n",
       "87                10.186666  \n",
       "6                  9.896667  \n",
       "28                 9.896667  \n",
       "86                10.086667  \n",
       "65                10.143333  \n",
       "45                10.153334  \n",
       "61                10.070000  \n",
       "78                10.116667  \n",
       "75                10.113334  \n",
       "14                 9.916667  \n",
       "43                10.066667  \n",
       "83                10.140000  \n",
       "30                10.013333  \n",
       "20                 9.993333  \n",
       "12                10.026667  \n",
       "8                  9.880000  \n",
       "32                 9.936666  \n",
       "19                10.063334  \n",
       "36                10.090000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13.146487 ],\n",
       "       [10.575032 ],\n",
       "       [10.000123 ],\n",
       "       [ 9.998298 ],\n",
       "       [10.754752 ],\n",
       "       [10.801645 ],\n",
       "       [10.450546 ],\n",
       "       [10.665063 ],\n",
       "       [11.228992 ],\n",
       "       [10.3666725],\n",
       "       [10.264056 ],\n",
       "       [ 9.438043 ],\n",
       "       [10.173447 ],\n",
       "       [10.306195 ],\n",
       "       [ 9.937534 ],\n",
       "       [10.281022 ],\n",
       "       [ 8.052893 ],\n",
       "       [10.254697 ],\n",
       "       [ 9.949453 ],\n",
       "       [ 9.816809 ]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - mae: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('athletics-anU3Jvik-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b55a542ebbe94d3c824ae4c9c8ac83ff6882a1b86c1ebe55c470958bb0bb0ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
